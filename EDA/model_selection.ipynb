{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38157fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Gender Religion Branch Section-1 Section-2 Section-3  Roll-1  Math-1 Theory  \\\n",
      "0      M    Hindu     CE         D         D         A     350             47   \n",
      "1      F    Hindu    CST         B         B         D      18             84   \n",
      "2      F    Hindu   AIML         A         A         C      23             74   \n",
      "3      M    Hindu    CST         B         B         D     212             55   \n",
      "4      M    Hindu    CST         B         B         D     208             38   \n",
      "\n",
      "   Physics Theory  Physics Practical  ...  Predicted FSD Theory  \\\n",
      "0              48                 75  ...             72.266535   \n",
      "1              83                 81  ...             87.523458   \n",
      "2              85                 86  ...             89.409752   \n",
      "3              69                 82  ...             79.807055   \n",
      "4              59                 74  ...             56.474296   \n",
      "\n",
      "   Predicted Math-3 Theory  Predicted Python Theory  \\\n",
      "0                56.352210                71.642156   \n",
      "1                82.966865                81.393865   \n",
      "2                76.982002                86.897293   \n",
      "3                67.253716                74.606764   \n",
      "4                51.995650                53.483393   \n",
      "\n",
      "   Predicted Sem 3 Percentage  Sem 1 Percentile  Sem 2 Percentile  \\\n",
      "0                       64.14             26.38             30.66   \n",
      "1                       83.40             95.99             84.39   \n",
      "2                       83.49             92.47             91.16   \n",
      "3                       72.31             66.30             51.59   \n",
      "4                       53.42             15.68             11.53   \n",
      "\n",
      "   Predicted Sem 3 Percentile  Predicted Percentile Drop  Predicted Risk Flag  \\\n",
      "0                       38.26                      -7.60                False   \n",
      "1                       88.54                      -4.15                False   \n",
      "2                       88.81                       2.35                False   \n",
      "3                       61.26                      -9.67                False   \n",
      "4                       15.47                      -3.94                False   \n",
      "\n",
      "   Risk Flag  \n",
      "0      False  \n",
      "1      False  \n",
      "2      False  \n",
      "3      False  \n",
      "4      False  \n",
      "\n",
      "[5 rows x 51 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Ensure the path to the DEModelHandler is correct\n",
    "sys.path.append(os.path.abspath(\"../SubjectModels/de_model\"))\n",
    "from de_handler import DEModelHandler  \n",
    "\n",
    "# Ensure the path to the FSDModelHandler is correct\n",
    "sys.path.append(os.path.abspath(\"../SubjectModels/fsd_model\"))\n",
    "from fsd_handler import FSDModelHandler  \n",
    "\n",
    "# Ensure the path to the Math3ModelHandler is correct\n",
    "sys.path.append(os.path.abspath(\"../SubjectModels/math3_model\"))\n",
    "from math3_handler import Math3ModelHandler  \n",
    "\n",
    "# Ensure the path to the PythonModelHandler is correct\n",
    "sys.path.append(os.path.abspath(\"../SubjectModels/python_model\"))\n",
    "from python_handler import PythonModelHandler  \n",
    "\n",
    "df = pd.read_csv(\"../dataset/train_dataset.csv\")\n",
    "\n",
    "# Drop the irrelevant, data leak columns\n",
    "df_clean = df.drop(\n",
    "    columns=[\n",
    "        \"Student ID\",\n",
    "        \"Mentor-1\",\n",
    "        \"Mentor-2\",\n",
    "        \"Mentor-3\",\n",
    "        \"Roll-2\",\n",
    "        \"Roll-3\",\n",
    "        \"Math-3 Theory\",\n",
    "        \"DE Practical\",\n",
    "        \"FSD Theory\",\n",
    "        \"FSD Practical\",\n",
    "        \"Python Theory\",\n",
    "        \"Python Practical\",\n",
    "        \"Communication Theory\",\n",
    "        \"Law Theory\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "# columns for Semester 1 core subjects\n",
    "sem1_columns = [\n",
    "    \"Math-1 Theory\",\n",
    "    \"Physics Theory\",\n",
    "    \"Java-1 Theory\",\n",
    "    \"Software Engineering Theory\",\n",
    "]\n",
    "\n",
    "# Calculate Semester 1 Percentage as the average of core subject scores\n",
    "# scores are numerical and out of 100\n",
    "df_clean[\"Sem 1 Percentage\"] = df_clean[sem1_columns].mean(axis=1).round(2)\n",
    "\n",
    "# columns for Semester 2 core subjects\n",
    "sem2_columns = [\n",
    "    \"Math-2 Theory\",\n",
    "    \"Data Structures using Java Theory\",\n",
    "    \"DBMS Theory\",\n",
    "    \"Fundamental of Electronics and Electrical Theory\",\n",
    "    \"Java-2 Theory\",\n",
    "]\n",
    "\n",
    "# Calculate Semester 2 Percentage as the average of core subject scores\n",
    "# scores are numerical and out of 100\n",
    "df_clean[\"Sem 2 Percentage\"] = df_clean[sem2_columns].mean(axis=1).round(2)\n",
    "\n",
    "# Rename columns Div-1, Div-2, Div-3 to Section-1, Section-2, Section-3\n",
    "df_clean = df_clean.rename(\n",
    "    columns={\"Div-1\": \"Section-1\", \"Div-2\": \"Section-2\", \"Div-3\": \"Section-3\"}\n",
    ")\n",
    "\n",
    "# Transform values in Section-1, Section-2, Section-3 to keep only the first character\n",
    "# Thus we get Only Department\n",
    "for section in [\"Section-1\", \"Section-2\", \"Section-3\"]:\n",
    "    df_clean[section] = df_clean[section].str[0]\n",
    "\n",
    "# adding DE predicted column\n",
    "preprocessor = DEModelHandler()\n",
    "fe_de = preprocessor.predict_from_model(\n",
    "    df,\n",
    "    model_path=\"../SubjectModels/de_model/de_model.joblib\",\n",
    "    return_type=\"df\"\n",
    ")\n",
    "\n",
    "# Add the predicted DE Theory marks to df_clean\n",
    "df_clean[\"Predicted DE Theory\"] = fe_de[\"Predicted DE Theory\"]\n",
    "\n",
    "\n",
    "# adding FSD predicted column\n",
    "preprocessor = FSDModelHandler()\n",
    "fe_fsd = preprocessor.predict_from_model(\n",
    "    df,\n",
    "    model_path=\"../SubjectModels/fsd_model/fsd_model.joblib\",\n",
    "    return_type=\"df\"\n",
    ")\n",
    "\n",
    "# Add the predicted FSD Theory marks to df_clean\n",
    "df_clean[\"Predicted FSD Theory\"] = fe_fsd[\"Predicted FSD Theory\"]\n",
    "\n",
    "\n",
    "# adding Math3 predicted column\n",
    "preprocessor = Math3ModelHandler()\n",
    "fe_math3 = preprocessor.predict_from_model(\n",
    "    df,\n",
    "    model_path=\"../SubjectModels/math3_model/math3_model.joblib\",\n",
    "    return_type=\"df\"\n",
    ")\n",
    "\n",
    "# Add the predicted Math3 Theory marks to df_clean\n",
    "df_clean[\"Predicted Math-3 Theory\"] = fe_math3[\"Predicted Math-3 Theory\"]\n",
    "\n",
    "\n",
    "# adding Python predicted column\n",
    "preprocessor = PythonModelHandler()\n",
    "fe_python = preprocessor.predict_from_model(\n",
    "    df,\n",
    "    model_path=\"../SubjectModels/python_model/python_model.joblib\",\n",
    "    return_type=\"df\"\n",
    ")\n",
    "\n",
    "# Add the predicted Python Theory marks to df_clean\n",
    "df_clean[\"Predicted Python Theory\"] = fe_python[\"Predicted Python Theory\"]\n",
    "\n",
    "#  Calculate predicted Semester 3 percentage (mean of 4 predicted subject marks)\n",
    "sem3_subjects = [\n",
    "    \"Predicted Math-3 Theory\",\n",
    "    \"Predicted DE Theory\",\n",
    "    \"Predicted FSD Theory\",\n",
    "    \"Predicted Python Theory\",\n",
    "]\n",
    "\n",
    "df_clean[\"Predicted Sem 3 Percentage\"] = df_clean[sem3_subjects].mean(axis=1).round(2)\n",
    "\n",
    "df_clean[\"Sem 1 Percentile\"] = df_clean[\"Sem 1 Percentage\"].rank(pct=True) * 100\n",
    "df_clean[\"Sem 2 Percentile\"] = df_clean[\"Sem 2 Percentage\"].rank(pct=True) * 100\n",
    "df_clean[\"Predicted Sem 3 Percentile\"] = df_clean[\"Predicted Sem 3 Percentage\"].rank(pct=True) * 100\n",
    "\n",
    "# Round for consistency\n",
    "df_clean[[\"Sem 1 Percentile\", \"Sem 2 Percentile\", \"Predicted Sem 3 Percentile\"]] = df_clean[\n",
    "    [\"Sem 1 Percentile\", \"Sem 2 Percentile\", \"Predicted Sem 3 Percentile\"]\n",
    "].round(2)\n",
    "\n",
    "df_clean[\"Predicted Percentile Drop\"] = (\n",
    "    df_clean[\"Sem 2 Percentile\"] - df_clean[\"Predicted Sem 3 Percentile\"]\n",
    ").round(2)\n",
    "\n",
    "df_clean[\"Predicted Risk Flag\"] = df_clean[\"Predicted Percentile Drop\"] > 10\n",
    "\n",
    "# Columns for Semester 3 core theory subjects\n",
    "sem3_columns = [\n",
    "    \"Math-3 Theory\",\n",
    "    \"DE Theory\",\n",
    "    \"FSD Theory\",\n",
    "    \"Python Theory\",\n",
    "]\n",
    "\n",
    "# Calculate Semester 3 Total as the sum of core subject scores\n",
    "df[\"Sem 3 Percentage\"] = (df[sem3_columns].sum(axis=1) / 4).round(2)\n",
    "\n",
    "df_clean[\"Sem 3 Percentile\"] = df[\"Sem 3 Percentage\"].rank(pct=True) * 100\n",
    "\n",
    "df_clean[\"Percentile Drop\"] = (\n",
    "    df_clean[\"Sem 2 Percentile\"] - df_clean[\"Sem 3 Percentile\"]\n",
    ").round(2)\n",
    "\n",
    "df_clean[\"Risk Flag\"] = df_clean[\"Percentile Drop\"] > 10\n",
    "\n",
    "columns_to_drop = [\n",
    "    \"Sem 3 Percentile\",\n",
    "    \"Percentile Drop\"\n",
    "]\n",
    "\n",
    "df_clean.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "# After all operations on df_clean are complete, drop other DataFrames\n",
    "df = None\n",
    "fe_de = None\n",
    "fe_fsd = None\n",
    "fe_math3 = None\n",
    "fe_python = None\n",
    "\n",
    "print(df_clean.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268fddad",
   "metadata": {},
   "source": [
    "# Dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ef56866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.8000, Precision=0.0000, Recall=0.0000, F1=0.0000\n",
      "Fold 2: Accuracy=0.8000, Precision=0.0000, Recall=0.0000, F1=0.0000\n",
      "Fold 3: Accuracy=0.8000, Precision=0.0000, Recall=0.0000, F1=0.0000\n",
      "Fold 4: Accuracy=0.7931, Precision=0.0000, Recall=0.0000, F1=0.0000\n",
      "Fold 5: Accuracy=0.7986, Precision=0.0000, Recall=0.0000, F1=0.0000\n",
      "\n",
      "--- Baseline Model Summary ---\n",
      "Name                          : DummyClassifier-MostFreq\n",
      "Description                   : Baseline-MostFrequent-5Fold\n",
      "Accuracy                      : 0.7983\n",
      "Precision                     : 0.0000\n",
      "Recall                        : 0.0000\n",
      "F1 Score                      : 0.0000\n",
      "\n",
      "CSV Row Format:\n",
      "DummyClassifier-MostFreq,Baseline-MostFrequent-5Fold,0.7983,0.0000,0.0000,0.0000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Target and features\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag', 'Predicted Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# DummyClassifier â€“ always predicts the most frequent class\n",
    "dummy = DummyClassifier(strategy='most_frequent')\n",
    "\n",
    "# CV setup\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Metric storage\n",
    "accuracy_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "\n",
    "# 5-Fold Evaluation\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    dummy.fit(X_train, y_train)\n",
    "    y_pred = dummy.predict(X_val)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# Final metrics\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# Model info\n",
    "model_name = 'DummyClassifier-MostFreq'\n",
    "model_desc = 'Baseline-MostFrequent-5Fold'\n",
    "\n",
    "# Print formatted summary\n",
    "print(\"\\n--- Baseline Model Summary ---\")\n",
    "print(f\"{'Name':<30}: {model_name}\")\n",
    "print(f\"{'Description':<30}: {model_desc}\")\n",
    "print(f\"{'Accuracy':<30}: {mean_acc:.4f}\")\n",
    "print(f\"{'Precision':<30}: {mean_prec:.4f}\")\n",
    "print(f\"{'Recall':<30}: {mean_rec:.4f}\")\n",
    "print(f\"{'F1 Score':<30}: {mean_f1:.4f}\")\n",
    "\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# Save to CSV (append row, create file if not exists)\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "new_row = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "\n",
    "# Append to file (header only if file doesn't exist)\n",
    "new_row.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5ddd4c",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d9afa15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.8207, Precision=0.5385, Recall=0.7241, F1=0.6176\n",
      "Fold 2: Accuracy=0.8552, Precision=0.6176, Recall=0.7241, F1=0.6667\n",
      "Fold 3: Accuracy=0.7931, Precision=0.4889, Recall=0.7586, F1=0.5946\n",
      "Fold 4: Accuracy=0.8069, Precision=0.5217, Recall=0.8000, F1=0.6316\n",
      "Fold 5: Accuracy=0.8125, Precision=0.5250, Recall=0.7241, F1=0.6087\n",
      "\n",
      "--- Average Metrics Summary ---\n",
      "Name                          : LogisticRegression-Balanced\n",
      "Description                   : OneHot+Scaler+5Fold-Stratified\n",
      "Accuracy                      : 0.8177\n",
      "Precision                     : 0.5383\n",
      "Recall                        : 0.7462\n",
      "F1 Score                      : 0.6238\n",
      "\n",
      "CSV Row Format:\n",
      "LogisticRegression-Balanced,OneHot+Scaler+5Fold-Stratified,0.8177,0.5383,0.7462,0.6238\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import warnings\n",
    "import csv\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Step 1: Copy and split data\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag', 'Predicted Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)  # convert bool to 0/1\n",
    "\n",
    "# Step 2: Column categorization\n",
    "categorical_cols = ['Gender', 'Religion', 'Branch', 'Section-1', 'Section-2', 'Section-3']\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Step 3: Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# Step 4: Full pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('model', LogisticRegression(class_weight='balanced', max_iter=1000))\n",
    "])\n",
    "\n",
    "# Step 5: 5-Fold Stratified CV\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Metrics storage\n",
    "accuracy_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "\n",
    "# Step 6: Loop through CV\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_val)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# Step 7: Average metrics\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# Model info\n",
    "model_name = 'LogisticRegression-Balanced'\n",
    "model_desc = 'OneHot+Scaler+5Fold-Stratified'\n",
    "\n",
    "# Print: CSV-style with labels and formatting\n",
    "print(\"\\n--- Average Metrics Summary ---\")\n",
    "print(f\"{'Name':<30}: {model_name}\")\n",
    "print(f\"{'Description':<30}: {model_desc}\")\n",
    "print(f\"{'Accuracy':<30}: {mean_acc:.4f}\")\n",
    "print(f\"{'Precision':<30}: {mean_prec:.4f}\")\n",
    "print(f\"{'Recall':<30}: {mean_rec:.4f}\")\n",
    "print(f\"{'F1 Score':<30}: {mean_f1:.4f}\")\n",
    "\n",
    "# Also print as CSV row\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# Step 8: Write to file if not already present\n",
    "output_path = 'risk_model_metrics.csv'\n",
    "write_header = not os.path.exists(output_path)\n",
    "\n",
    "with open(output_path, mode='a', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    if write_header:\n",
    "        writer.writerow(['Name', 'Desc', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
    "    writer.writerow([model_name, model_desc, f\"{mean_acc:.4f}\", f\"{mean_prec:.4f}\", f\"{mean_rec:.4f}\", f\"{mean_f1:.4f}\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefdbb3e",
   "metadata": {},
   "source": [
    "# DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b37e44c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.8000, Precision=0.5000,  Recall=0.4138, F1=0.4528\n",
      "Fold 2: Accuracy=0.8414, Precision=0.7143,  Recall=0.3448, F1=0.4651\n",
      "Fold 3: Accuracy=0.7517, Precision=0.4103,  Recall=0.5517, F1=0.4706\n",
      "Fold 4: Accuracy=0.7862, Precision=0.4848,  Recall=0.5333, F1=0.5079\n",
      "Fold 5: Accuracy=0.8403, Precision=0.6250,  Recall=0.5172, F1=0.5660\n",
      "\n",
      "--- DecisionTreeClassifier Summary ---\n",
      "Mean Accuracy : 0.8039\n",
      "Mean Precision: 0.5469\n",
      "Mean Recall   : 0.4722\n",
      "Mean F1 Score : 0.4925\n",
      "\n",
      "CSV Row Format:\n",
      "DecisionTreeClassifier-Balanced,OneHot+Scaler+5Fold-Stratified,0.8039,0.5469,0.4722,0.4925\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Step 1: Prepare data\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag', 'Predicted Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# Step 2: Column categories\n",
    "categorical_cols = ['Gender', 'Religion', 'Branch', 'Section-1', 'Section-2', 'Section-3']\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Step 3: Preprocessing\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# Step 4: Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('model', DecisionTreeClassifier(class_weight='balanced', random_state=42))\n",
    "])\n",
    "\n",
    "# Step 5: Cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_val)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f},  Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# Step 6: Averages\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# Step 7: Model description\n",
    "model_name = 'DecisionTreeClassifier-Balanced'\n",
    "model_desc = 'OneHot+Scaler+5Fold-Stratified'\n",
    "\n",
    "# Console summary\n",
    "print(\"\\n--- DecisionTreeClassifier Summary ---\")\n",
    "print(f\"Mean Accuracy : {mean_acc:.4f}\")\n",
    "print(f\"Mean Precision: {mean_prec:.4f}\")\n",
    "print(f\"Mean Recall   : {mean_rec:.4f}\")\n",
    "print(f\"Mean F1 Score : {mean_f1:.4f}\")\n",
    "\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# Step 8: Save to CSV\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "result_df = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "\n",
    "# Append to CSV, add header only if file doesn't exist\n",
    "result_df.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb71471c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.6828, Precision=0.3455,  Recall=0.6552, F1=0.4524\n",
      "Fold 2: Accuracy=0.8138, Precision=0.5357,  Recall=0.5172, F1=0.5263\n",
      "Fold 3: Accuracy=0.7034, Precision=0.3750,  Recall=0.7241, F1=0.4941\n",
      "Fold 4: Accuracy=0.7517, Precision=0.4348,  Recall=0.6667, F1=0.5263\n",
      "Fold 5: Accuracy=0.7222, Precision=0.3878,  Recall=0.6552, F1=0.4872\n",
      "\n",
      "--- DecisionTree_Recall_Tuned Summary ---\n",
      "Mean Accuracy : 0.7348\n",
      "Mean Precision: 0.4157\n",
      "Mean Recall   : 0.6437\n",
      "Mean F1 Score : 0.4973\n",
      "\n",
      "CSV Row Format:\n",
      "DecisionTree-RecallTuned,Thresh=0.35|Depth=6|Split=10|Leaf=5|5Fold,0.7348,0.4157,0.6437,0.4973\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Step 1: Data setup\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag', 'Predicted Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# Step 2: Column types\n",
    "categorical_cols = ['Gender', 'Religion', 'Branch', 'Section-1', 'Section-2', 'Section-3']\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Step 3: Preprocessing\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# Step 4: Recall-tuned DecisionTree\n",
    "pipeline = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('model', DecisionTreeClassifier(\n",
    "        class_weight='balanced',\n",
    "        max_depth=6,\n",
    "        min_samples_split=10,\n",
    "        min_samples_leaf=5,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Step 5: CV setup\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n",
    "\n",
    "# Step 6: Custom threshold\n",
    "threshold = 0.35\n",
    "\n",
    "# Step 7: Cross-validation\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    y_proba = pipeline.predict_proba(X_val)[:, 1]\n",
    "    y_pred = (y_proba >= threshold).astype(int)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f},  Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# Step 8: Mean metrics\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# Step 9: Model info\n",
    "model_name = 'DecisionTree-RecallTuned'\n",
    "model_desc = f'Thresh=0.35|Depth=6|Split=10|Leaf=5|5Fold'\n",
    "\n",
    "# Console output\n",
    "print(\"\\n--- DecisionTree_Recall_Tuned Summary ---\")\n",
    "print(f\"Mean Accuracy : {mean_acc:.4f}\")\n",
    "print(f\"Mean Precision: {mean_prec:.4f}\")\n",
    "print(f\"Mean Recall   : {mean_rec:.4f}\")\n",
    "print(f\"Mean F1 Score : {mean_f1:.4f}\")\n",
    "\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# Step 10: Save to CSV\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "result_df = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "\n",
    "result_df.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee992bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.8000, Precision=0.5000,  Recall=0.4138, F1=0.4528\n",
      "Fold 2: Accuracy=0.8414, Precision=0.7143,  Recall=0.3448, F1=0.4651\n",
      "Fold 3: Accuracy=0.7517, Precision=0.4103,  Recall=0.5517, F1=0.4706\n",
      "Fold 4: Accuracy=0.7862, Precision=0.4848,  Recall=0.5333, F1=0.5079\n",
      "Fold 5: Accuracy=0.8403, Precision=0.6250,  Recall=0.5172, F1=0.5660\n",
      "\n",
      "--- DecisionTree_MaxRecall Summary ---\n",
      "Mean Accuracy : 0.8039\n",
      "Mean Precision: 0.5469\n",
      "Mean Recall   : 0.4722\n",
      "Mean F1 Score : 0.4925\n",
      "\n",
      "CSV Row Format:\n",
      "DecisionTree-MaxRecall,Depth=None|Split=2|Leaf=1|Thresh=0.25|5Fold,0.8039,0.5469,0.4722,0.4925\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Step 1: Data setup\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag', 'Predicted Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "categorical_cols = ['Gender', 'Religion', 'Branch', 'Section-1', 'Section-2', 'Section-3']\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Step 2: Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# Step 3: Flexible (deep) DecisionTreeClassifier\n",
    "pipeline = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('model', DecisionTreeClassifier(\n",
    "        class_weight='balanced',\n",
    "        max_depth=None,             # no limit\n",
    "        min_samples_split=2,        # fine splits\n",
    "        min_samples_leaf=1,         # small leaves allowed\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Step 4: Cross-validation config\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n",
    "\n",
    "# Step 5: Threshold\n",
    "threshold = 0.25  # aggressive threshold to maximize recall\n",
    "\n",
    "# Step 6: CV loop\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_proba = pipeline.predict_proba(X_val)[:, 1]\n",
    "    y_pred = (y_proba >= threshold).astype(int)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f},  Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# Step 7: Aggregate results\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# Step 8: Metadata\n",
    "model_name = 'DecisionTree-MaxRecall'\n",
    "model_desc = 'Depth=None|Split=2|Leaf=1|Thresh=0.25|5Fold'\n",
    "\n",
    "print(\"\\n--- DecisionTree_MaxRecall Summary ---\")\n",
    "print(f\"Mean Accuracy : {mean_acc:.4f}\")\n",
    "print(f\"Mean Precision: {mean_prec:.4f}\")\n",
    "print(f\"Mean Recall   : {mean_rec:.4f}\")\n",
    "print(f\"Mean F1 Score : {mean_f1:.4f}\")\n",
    "\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# Step 9: Save to CSV\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "result_df = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "result_df.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a643a2d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.7586, Precision=0.4400, Recall=0.7586, F1=0.5570\n",
      "Fold 2: Accuracy=0.7517, Precision=0.4255, Recall=0.6897, F1=0.5263\n",
      "Fold 3: Accuracy=0.7241, Precision=0.3922, Recall=0.6897, F1=0.5000\n",
      "Fold 4: Accuracy=0.8069, Precision=0.5200, Recall=0.8667, F1=0.6500\n",
      "Fold 5: Accuracy=0.7500, Precision=0.4340, Recall=0.7931, F1=0.5610\n",
      "\n",
      "--- DecisionTree_SMOTE Summary ---\n",
      "Mean Accuracy : 0.7583\n",
      "Mean Precision: 0.4423\n",
      "Mean Recall   : 0.7595\n",
      "Mean F1 Score : 0.5589\n",
      "\n",
      "CSV Row Format:\n",
      "DecisionTree-SMOTE,Thresh=0.35|Depth=6|Split=10|Leaf=5|5Fold|SMOTE,0.7583,0.4423,0.7595,0.5589\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Step 1: Data setup\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag', 'Predicted Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# Step 2: Column types\n",
    "categorical_cols = ['Gender', 'Religion', 'Branch', 'Section-1', 'Section-2', 'Section-3']\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Step 3: Preprocessing\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# Step 4: SMOTE setup\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "# Step 5: Recall-tuned DecisionTree\n",
    "pipeline = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('model', DecisionTreeClassifier(\n",
    "        max_depth=6,\n",
    "        min_samples_split=10,\n",
    "        min_samples_leaf=5,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Step 6: CV setup\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n",
    "\n",
    "# Step 7: Custom threshold\n",
    "threshold = 0.35\n",
    "\n",
    "# Step 8: Cross-validation with SMOTE\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    # Apply SMOTE to training data\n",
    "    X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "    X_train_smote, y_train_smote = smote.fit_resample(X_train_preprocessed, y_train)\n",
    "\n",
    "    # Fit the model on SMOTE-resampled data\n",
    "    pipeline.named_steps['model'].fit(X_train_smote, y_train_smote)\n",
    "\n",
    "    # Transform validation data\n",
    "    X_val_preprocessed = preprocessor.transform(X_val)\n",
    "    y_proba = pipeline.named_steps['model'].predict_proba(X_val_preprocessed)[:, 1]\n",
    "    y_pred = (y_proba >= threshold).astype(int)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# Step 9: Mean metrics\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# Step 10: Model info\n",
    "model_name = 'DecisionTree-SMOTE'\n",
    "model_desc = f'Thresh=0.35|Depth=6|Split=10|Leaf=5|5Fold|SMOTE'\n",
    "\n",
    "# Console output\n",
    "print(\"\\n--- DecisionTree_SMOTE Summary ---\")\n",
    "print(f\"Mean Accuracy : {mean_acc:.4f}\")\n",
    "print(f\"Mean Precision: {mean_prec:.4f}\")\n",
    "print(f\"Mean Recall   : {mean_rec:.4f}\")\n",
    "print(f\"Mean F1 Score : {mean_f1:.4f}\")\n",
    "\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# Step 11: Save to CSV\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "result_df = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "\n",
    "result_df.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a761db51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.7931, Precision=0.4878, Recall=0.6897, F1=0.5714\n",
      "Fold 2: Accuracy=0.7586, Precision=0.4167, Recall=0.5172, F1=0.4615\n",
      "Fold 3: Accuracy=0.7103, Precision=0.3818, Recall=0.7241, F1=0.5000\n",
      "Fold 4: Accuracy=0.7241, Precision=0.4107, Recall=0.7667, F1=0.5349\n",
      "Fold 5: Accuracy=0.8125, Precision=0.5238, Recall=0.7586, F1=0.6197\n",
      "\n",
      "--- DecisionTree_SMOTE_RecallOptimized Summary ---\n",
      "Mean Accuracy : 0.7597\n",
      "Mean Precision: 0.4442\n",
      "Mean Recall   : 0.6913\n",
      "Mean F1 Score : 0.5375\n",
      "\n",
      "CSV Row Format:\n",
      "DecisionTree-SMOTE-RecallOptimized,Thresh=0.25|Depth=6|Split=10|Leaf=3|5Fold|SMOTE_0.8,0.7597,0.4442,0.6913,0.5375\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Step 1: Data setup\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag', 'Predicted Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# Step 2: Column types\n",
    "categorical_cols = ['Gender', 'Religion', 'Branch', 'Section-1', 'Section-2', 'Section-3']\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Step 3: Preprocessing\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# Step 4: SMOTE setup with adjusted sampling strategy\n",
    "smote = SMOTE(sampling_strategy=0.8, random_state=42)\n",
    "\n",
    "# Step 5: Recall-optimized DecisionTree\n",
    "pipeline = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('model', DecisionTreeClassifier(\n",
    "        max_depth=6,\n",
    "        min_samples_split=10,\n",
    "        min_samples_leaf=3,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Step 6: CV setup\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n",
    "\n",
    "# Step 7: Lowered threshold for higher recall\n",
    "threshold = 0.25\n",
    "\n",
    "# Step 8: Cross-validation with SMOTE\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    # Apply SMOTE to training data\n",
    "    X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "    X_train_smote, y_train_smote = smote.fit_resample(X_train_preprocessed, y_train)\n",
    "\n",
    "    # Fit the model on SMOTE-resampled data\n",
    "    pipeline.named_steps['model'].fit(X_train_smote, y_train_smote)\n",
    "\n",
    "    # Transform validation data\n",
    "    X_val_preprocessed = preprocessor.transform(X_val)\n",
    "    y_proba = pipeline.named_steps['model'].predict_proba(X_val_preprocessed)[:, 1]\n",
    "    y_pred = (y_proba >= threshold).astype(int)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# Step 9: Mean metrics\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# Step 10: Model info\n",
    "model_name = 'DecisionTree-SMOTE-RecallOptimized'\n",
    "model_desc = f'Thresh=0.25|Depth=6|Split=10|Leaf=3|5Fold|SMOTE_0.8'\n",
    "\n",
    "# Console output\n",
    "print(\"\\n--- DecisionTree_SMOTE_RecallOptimized Summary ---\")\n",
    "print(f\"Mean Accuracy : {mean_acc:.4f}\")\n",
    "print(f\"Mean Precision: {mean_prec:.4f}\")\n",
    "print(f\"Mean Recall   : {mean_rec:.4f}\")\n",
    "print(f\"Mean F1 Score : {mean_f1:.4f}\")\n",
    "\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# Step 11: Save to CSV\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "result_df = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "\n",
    "result_df.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58706e3",
   "metadata": {},
   "source": [
    "# RandomForestClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de4e23a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.8138, Precision=0.7500,  Recall=0.1034, F1=0.1818\n",
      "Fold 2: Accuracy=0.8276, Precision=0.8333,  Recall=0.1724, F1=0.2857\n",
      "Fold 3: Accuracy=0.8345, Precision=0.8571,  Recall=0.2069, F1=0.3333\n",
      "Fold 4: Accuracy=0.8345, Precision=0.8000,  Recall=0.2667, F1=0.4000\n",
      "Fold 5: Accuracy=0.8403, Precision=0.8750,  Recall=0.2414, F1=0.3784\n",
      "\n",
      "--- RandomForestClassifier Summary ---\n",
      "Mean Accuracy : 0.8301\n",
      "Mean Precision: 0.8231\n",
      "Mean Recall   : 0.1982\n",
      "Mean F1 Score : 0.3158\n",
      "\n",
      "CSV Row Format:\n",
      "RandomForestClassifier-Balanced,OneHot+Scaler+5Fold-Stratified,0.8301,0.8231,0.1982,0.3158\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Step 1: Prepare data\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag', 'Predicted Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# Step 2: Column categories\n",
    "categorical_cols = ['Gender', 'Religion', 'Branch', 'Section-1', 'Section-2', 'Section-3']\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Step 3: Preprocessing\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# Step 4: Pipeline with Random Forest\n",
    "pipeline = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('model', RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=None,\n",
    "        class_weight='balanced',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Step 5: Cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_val)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f},  Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# Step 6: Averages\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# Step 7: Model description\n",
    "model_name = 'RandomForestClassifier-Balanced'\n",
    "model_desc = 'OneHot+Scaler+5Fold-Stratified'\n",
    "\n",
    "# Console summary\n",
    "print(\"\\n--- RandomForestClassifier Summary ---\")\n",
    "print(f\"Mean Accuracy : {mean_acc:.4f}\")\n",
    "print(f\"Mean Precision: {mean_prec:.4f}\")\n",
    "print(f\"Mean Recall   : {mean_rec:.4f}\")\n",
    "print(f\"Mean F1 Score : {mean_f1:.4f}\")\n",
    "\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# Step 8: Save to CSV\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "result_df = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "\n",
    "# Append to CSV, add header only if file doesn't exist\n",
    "result_df.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8d374e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.7586, Precision=0.4348, Recall=0.6897, F1=0.5333\n",
      "Fold 2: Accuracy=0.7724, Precision=0.4545, Recall=0.6897, F1=0.5479\n",
      "Fold 3: Accuracy=0.6690, Precision=0.3582, Recall=0.8276, F1=0.5000\n",
      "Fold 4: Accuracy=0.6552, Precision=0.3649, Recall=0.9000, F1=0.5192\n",
      "Fold 5: Accuracy=0.6875, Precision=0.3621, Recall=0.7241, F1=0.4828\n",
      "\n",
      "--- Average Metrics Summary ---\n",
      "Name                          : RandomForest-SMOTE-Threshold0.3\n",
      "Description                   : OneHot+Scaler+SMOTE+RF+Threshold=0.3\n",
      "Accuracy                      : 0.7085\n",
      "Precision                     : 0.3949\n",
      "Recall                        : 0.7662\n",
      "F1 Score                      : 0.5167\n",
      "\n",
      "CSV Row Format:\n",
      "RandomForest-SMOTE-Threshold0.3,OneHot+Scaler+SMOTE+RF+Threshold=0.3,0.7085,0.3949,0.7662,0.5167\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "import warnings\n",
    "import csv\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Step 1: Copy and split data\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag', 'Predicted Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)  # convert bool to 0/1\n",
    "\n",
    "# Step 2: Column categorization\n",
    "categorical_cols = ['Gender', 'Religion', 'Branch', 'Section-1', 'Section-2', 'Section-3']\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Step 3: Preprocessing\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# Step 4: Full pipeline with SMOTE + RandomForest\n",
    "pipeline = ImbPipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('model', RandomForestClassifier(\n",
    "        n_estimators=200,\n",
    "        max_depth=None,\n",
    "        class_weight='balanced',\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Step 5: 5-Fold Stratified CV\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Metrics storage\n",
    "accuracy_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "\n",
    "threshold = 0.3  # Custom threshold to maximize recall\n",
    "\n",
    "# Step 6: Loop through CV\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_proba = pipeline.predict_proba(X_val)[:, 1]  # Get probability for class 1\n",
    "\n",
    "    y_pred = (y_proba >= threshold).astype(int)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# Step 7: Average metrics\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# Model info\n",
    "model_name = 'RandomForest-SMOTE-Threshold0.3'\n",
    "model_desc = 'OneHot+Scaler+SMOTE+RF+Threshold=0.3'\n",
    "\n",
    "# Print: CSV-style with labels and formatting\n",
    "print(\"\\n--- Average Metrics Summary ---\")\n",
    "print(f\"{'Name':<30}: {model_name}\")\n",
    "print(f\"{'Description':<30}: {model_desc}\")\n",
    "print(f\"{'Accuracy':<30}: {mean_acc:.4f}\")\n",
    "print(f\"{'Precision':<30}: {mean_prec:.4f}\")\n",
    "print(f\"{'Recall':<30}: {mean_rec:.4f}\")\n",
    "print(f\"{'F1 Score':<30}: {mean_f1:.4f}\")\n",
    "\n",
    "# Also print as CSV row\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# Step 8: Write to file if not already present\n",
    "output_path = 'risk_model_metrics.csv'\n",
    "write_header = not os.path.exists(output_path)\n",
    "\n",
    "with open(output_path, mode='a', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    if write_header:\n",
    "        writer.writerow(['Name', 'Desc', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
    "    writer.writerow([model_name, model_desc, f\"{mean_acc:.4f}\", f\"{mean_prec:.4f}\", f\"{mean_rec:.4f}\", f\"{mean_f1:.4f}\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf804d22",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ba5f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.8414, Precision=0.6500,  Recall=0.4483, F1=0.5306\n",
      "Fold 2: Accuracy=0.8759, Precision=0.7619,  Recall=0.5517, F1=0.6400\n",
      "Fold 3: Accuracy=0.8138, Precision=0.5278,  Recall=0.6552, F1=0.5846\n",
      "Fold 4: Accuracy=0.8414, Precision=0.6061,  Recall=0.6667, F1=0.6349\n",
      "Fold 5: Accuracy=0.8958, Precision=0.7917,  Recall=0.6552, F1=0.7170\n",
      "\n",
      "--- XGBoost Summary ---\n",
      "Mean Accuracy : 0.8536\n",
      "Mean Precision: 0.6675\n",
      "Mean Recall   : 0.5954\n",
      "Mean F1 Score : 0.6214\n",
      "\n",
      "CSV Row Format:\n",
      "XGBoost-Balanced,OneHot+Scaler+5Fold-Stratified,0.8536,0.6675,0.5954,0.6214\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Step 1: Prepare data\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag', 'Predicted Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# Step 2: Column categories\n",
    "categorical_cols = ['Gender', 'Religion', 'Branch', 'Section-1', 'Section-2', 'Section-3']\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Step 3: Preprocessing\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# Step 4: XGBoost Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('model', XGBClassifier(\n",
    "        objective='binary:logistic',\n",
    "        eval_metric='logloss',\n",
    "        scale_pos_weight=np.sum(y == 0) / np.sum(y == 1),  # Handles class imbalance\n",
    "        use_label_encoder=False,\n",
    "        n_estimators=100,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.1,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Step 5: Cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_val)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f},  Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# Step 6: Averages\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# Step 7: Model description\n",
    "model_name = 'XGBoost-Balanced'\n",
    "model_desc = 'OneHot+Scaler+5Fold-Stratified'\n",
    "\n",
    "# Console summary\n",
    "print(\"\\n--- XGBoost Summary ---\")\n",
    "print(f\"Mean Accuracy : {mean_acc:.4f}\")\n",
    "print(f\"Mean Precision: {mean_prec:.4f}\")\n",
    "print(f\"Mean Recall   : {mean_rec:.4f}\")\n",
    "print(f\"Mean F1 Score : {mean_f1:.4f}\")\n",
    "\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# Step 8: Save to CSV\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "result_df = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "\n",
    "# Append to CSV, add header only if file doesn't exist\n",
    "result_df.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b66f051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.8690, Precision=0.6250, Recall=0.8621, F1=0.7246\n",
      "Fold 2: Accuracy=0.8621, Precision=0.6452, Recall=0.6897, F1=0.6667\n",
      "Fold 3: Accuracy=0.7586, Precision=0.4400, Recall=0.7586, F1=0.5570\n",
      "Fold 4: Accuracy=0.8345, Precision=0.5750, Recall=0.7667, F1=0.6571\n",
      "Fold 5: Accuracy=0.8125, Precision=0.5238, Recall=0.7586, F1=0.6197\n",
      "\n",
      "--- Average Metrics Summary ---\n",
      "Name                          : XGBoost-SMOTE-Threshold0.25\n",
      "Description                   : OneHot+Scaler+SMOTE+XGB+Threshold=0.25\n",
      "Accuracy                      : 0.8273\n",
      "Precision                     : 0.5618\n",
      "Recall                        : 0.7671\n",
      "F1 Score                      : 0.6450\n",
      "\n",
      "CSV Row Format:\n",
      "XGBoost-SMOTE-Threshold0.25,OneHot+Scaler+SMOTE+XGB+Threshold=0.25,0.8273,0.5618,0.7671,0.6450\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from xgboost import XGBClassifier\n",
    "import warnings\n",
    "import csv\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Step 1: Copy and split data\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag', 'Predicted Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# Step 2: Column categorization\n",
    "categorical_cols = ['Gender', 'Religion', 'Branch', 'Section-1', 'Section-2', 'Section-3']\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Step 3: Preprocessing\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# Step 4: Pipeline with XGBoost + SMOTE\n",
    "pipeline = ImbPipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('model', XGBClassifier(\n",
    "        use_label_encoder=False,\n",
    "        eval_metric='logloss',\n",
    "        scale_pos_weight=4,  # 80:20 class balance\n",
    "        n_estimators=200,\n",
    "        max_depth=5,\n",
    "        learning_rate=0.1,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Step 5: Stratified 5-Fold CV\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Step 6: Metrics storage\n",
    "accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n",
    "\n",
    "# Threshold for classification\n",
    "threshold = 0.25\n",
    "\n",
    "# Step 7: CV loop\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_proba = pipeline.predict_proba(X_val)[:, 1]\n",
    "    y_pred = (y_proba >= threshold).astype(int)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# Step 8: Average metrics\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# Model info\n",
    "model_name = 'XGBoost-SMOTE-Threshold0.25'\n",
    "model_desc = 'OneHot+Scaler+SMOTE+XGB+Threshold=0.25'\n",
    "\n",
    "# Step 9: Print metrics\n",
    "print(\"\\n--- Average Metrics Summary ---\")\n",
    "print(f\"{'Name':<30}: {model_name}\")\n",
    "print(f\"{'Description':<30}: {model_desc}\")\n",
    "print(f\"{'Accuracy':<30}: {mean_acc:.4f}\")\n",
    "print(f\"{'Precision':<30}: {mean_prec:.4f}\")\n",
    "print(f\"{'Recall':<30}: {mean_rec:.4f}\")\n",
    "print(f\"{'F1 Score':<30}: {mean_f1:.4f}\")\n",
    "\n",
    "# Also print as CSV row\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# Step 10: Write to file if not already present\n",
    "output_path = 'risk_model_metrics.csv'\n",
    "write_header = not os.path.exists(output_path)\n",
    "\n",
    "with open(output_path, mode='a', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    if write_header:\n",
    "        writer.writerow(['Name', 'Desc', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
    "    writer.writerow([model_name, model_desc, f\"{mean_acc:.4f}\", f\"{mean_prec:.4f}\", f\"{mean_rec:.4f}\", f\"{mean_f1:.4f}\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23024535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 324 candidates, totalling 1620 fits\n",
      "Best Parameters: {'model__colsample_bytree': 0.8, 'model__learning_rate': 0.01, 'model__max_depth': 6, 'model__min_child_weight': 3, 'model__n_estimators': 300, 'model__subsample': 0.8}\n",
      "Fold 1: Accuracy=0.6207, Precision=0.3415, Recall=0.9655, F1=0.5045, Best Threshold=0.10\n",
      "Fold 2: Accuracy=0.6138, Precision=0.3333, Recall=0.9310, F1=0.4909, Best Threshold=0.10\n",
      "Fold 3: Accuracy=0.5586, Precision=0.3034, Recall=0.9310, F1=0.4576, Best Threshold=0.10\n",
      "Fold 4: Accuracy=0.5448, Precision=0.3125, Recall=1.0000, F1=0.4762, Best Threshold=0.10\n",
      "Fold 5: Accuracy=0.5000, Precision=0.2828, Recall=0.9655, F1=0.4375, Best Threshold=0.10\n",
      "\n",
      "--- Fine-Tuned XGBoost Summary ---\n",
      "Mean Accuracy : 0.5676\n",
      "Mean Precision: 0.3147\n",
      "Mean Recall   : 0.9586\n",
      "Mean F1 Score : 0.4733\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Step 1: Prepare data\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag', 'Predicted Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "categorical_cols = ['Gender', 'Religion', 'Branch', 'Section-1', 'Section-2', 'Section-3']\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Step 2: Preprocessing\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# Step 3: Pipeline with SMOTE\n",
    "pipeline = ImbPipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('model', XGBClassifier(\n",
    "        objective='binary:logistic',\n",
    "        use_label_encoder=False,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Step 4: Hyperparameter Optimization\n",
    "param_grid = {\n",
    "    'model__n_estimators': [100, 200, 300],\n",
    "    'model__max_depth': [4, 6, 8],\n",
    "    'model__learning_rate': [0.01, 0.1, 0.2],\n",
    "    'model__min_child_weight': [1, 3, 5],\n",
    "    'model__subsample': [0.8, 1.0],\n",
    "    'model__colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    scoring='f1',\n",
    "    cv=cv,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Step 5: Dynamic Threshold Tuning\n",
    "best_model = grid_search.best_estimator_\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "\n",
    "accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n",
    "thresholds = np.linspace(0.1, 0.9, 9)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    best_model.fit(X_train, y_train)\n",
    "    y_proba = best_model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    # Dynamic threshold tuning for recall\n",
    "    recalls = [recall_score(y_val, (y_proba >= t).astype(int)) for t in thresholds]\n",
    "    best_threshold = thresholds[np.argmax(recalls)]\n",
    "\n",
    "    y_pred = (y_proba >= best_threshold).astype(int)\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}, F1={f1:.4f}, Best Threshold={best_threshold:.2f}\")\n",
    "\n",
    "# Step 6: Aggregate Results\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# Step 7: Summary\n",
    "model_name = 'XGBoost-SMOTE-FineTuned'\n",
    "model_desc = f'OptimizedParams|DynamicThresh={best_threshold:.2f}|OneHot+Scaler'\n",
    "\n",
    "print(\"\\n--- Fine-Tuned XGBoost Summary ---\")\n",
    "print(f\"Mean Accuracy : {mean_acc:.4f}\")\n",
    "print(f\"Mean Precision: {mean_prec:.4f}\")\n",
    "print(f\"Mean Recall   : {mean_rec:.4f}\")\n",
    "print(f\"Mean F1 Score : {mean_f1:.4f}\")\n",
    "\n",
    "# Step 8: Save to CSV\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "result_df = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "result_df.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc6f567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 972 candidates, totalling 4860 fits\n",
      "Best Parameters: {'model__colsample_bytree': 0.8, 'model__learning_rate': 0.05, 'model__max_depth': 8, 'model__min_child_weight': 5, 'model__n_estimators': 300, 'model__scale_pos_weight': 4, 'model__subsample': 0.8}\n",
      "Fold 1: Accuracy=0.9241, Precision=0.8462, Recall=0.7586, F1=0.8000, Best Threshold=0.60\n",
      "Fold 2: Accuracy=0.8759, Precision=0.6897, Recall=0.6897, F1=0.6897, Best Threshold=0.40\n",
      "Fold 3: Accuracy=0.8207, Precision=0.5405, Recall=0.6897, F1=0.6061, Best Threshold=0.60\n",
      "Fold 4: Accuracy=0.8552, Precision=0.6452, Recall=0.6667, F1=0.6557, Best Threshold=0.70\n",
      "Fold 5: Accuracy=0.8681, Precision=0.6786, Recall=0.6552, F1=0.6667, Best Threshold=0.70\n",
      "\n",
      "--- Fine-Tuned XGBoost Summary ---\n",
      "Mean Accuracy : 0.8688\n",
      "Mean Precision: 0.6800\n",
      "Mean Recall   : 0.6920\n",
      "Mean F1 Score : 0.6836\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Step 1: Prepare data\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag', 'Predicted Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "categorical_cols = ['Gender', 'Religion', 'Branch', 'Section-1', 'Section-2', 'Section-3']\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Step 2: Preprocessing\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# Step 3: Pipeline with SMOTE\n",
    "pipeline = ImbPipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('model', XGBClassifier(\n",
    "        objective='binary:logistic',\n",
    "        use_label_encoder=False,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Step 4: Hyperparameter Optimization\n",
    "param_grid = {\n",
    "    'model__n_estimators': [200, 300, 400],\n",
    "    'model__max_depth': [4, 6, 8],\n",
    "    'model__learning_rate': [0.01, 0.05, 0.1],\n",
    "    'model__min_child_weight': [1, 3, 5],\n",
    "    'model__subsample': [0.8, 1.0],\n",
    "    'model__colsample_bytree': [0.8, 1.0],\n",
    "    'model__scale_pos_weight': [4, 5, 6]  # Adjusted for imbalance\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    scoring='balanced_accuracy',  # Balances true positive/negative rates\n",
    "    cv=cv,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Step 5: Dynamic Threshold Tuning\n",
    "best_model = grid_search.best_estimator_\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "\n",
    "accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n",
    "thresholds = np.linspace(0.1, 0.9, 9)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    best_model.fit(X_train, y_train)\n",
    "    y_proba = best_model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    # Dynamic threshold tuning for F1\n",
    "    f1_scores = [f1_score(y_val, (y_proba >= t).astype(int)) for t in thresholds]\n",
    "    best_threshold = thresholds[np.argmax(f1_scores)]\n",
    "\n",
    "    y_pred = (y_proba >= best_threshold).astype(int)\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}, F1={f1:.4f}, Best Threshold={best_threshold:.2f}\")\n",
    "\n",
    "# Step 6: Aggregate Results\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# Step 7: Summary\n",
    "model_name = 'XGBoost-SMOTE-FineTuned-Balanced'\n",
    "model_desc = f'OptimizedParams|DynamicThresh={best_threshold:.2f}|OneHot+Scaler'\n",
    "\n",
    "print(\"\\n--- Fine-Tuned XGBoost Summary ---\")\n",
    "print(f\"Mean Accuracy : {mean_acc:.4f}\")\n",
    "print(f\"Mean Precision: {mean_prec:.4f}\")\n",
    "print(f\"Mean Recall   : {mean_rec:.4f}\")\n",
    "print(f\"Mean F1 Score : {mean_f1:.4f}\")\n",
    "\n",
    "# Step 8: Save to CSV\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "result_df = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "result_df.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b84066a",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a727782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.8828, Precision=0.8000,  Recall=0.5517, F1=0.6531\n",
      "Fold 2: Accuracy=0.8690, Precision=0.7273,  Recall=0.5517, F1=0.6275\n",
      "Fold 3: Accuracy=0.8138, Precision=0.5294,  Recall=0.6207, F1=0.5714\n",
      "Fold 4: Accuracy=0.8483, Precision=0.6333,  Recall=0.6333, F1=0.6333\n",
      "Fold 5: Accuracy=0.8681, Precision=0.6786,  Recall=0.6552, F1=0.6667\n",
      "\n",
      "--- LightGBM Summary ---\n",
      "Mean Accuracy : 0.8564\n",
      "Mean Precision: 0.6737\n",
      "Mean Recall   : 0.6025\n",
      "Mean F1 Score : 0.6304\n",
      "\n",
      "CSV Row Format:\n",
      "LightGBM-Balanced,OneHot+Scaler+5Fold-Stratified+VerboseOff,0.8564,0.6737,0.6025,0.6304\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Step 1: Prepare data\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag', 'Predicted Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# Optional: Check constant columns\n",
    "constant_cols = [col for col in X.columns if X[col].nunique() <= 1]\n",
    "if constant_cols:\n",
    "    print(\"Warning: Constant columns detected:\", constant_cols)\n",
    "\n",
    "# Step 2: Column categories\n",
    "categorical_cols = ['Gender', 'Religion', 'Branch', 'Section-1', 'Section-2', 'Section-3']\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Step 3: Preprocessing\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', drop='if_binary', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# Step 4: LightGBM Pipeline (optimized to suppress warnings)\n",
    "pipeline = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('model', LGBMClassifier(\n",
    "        objective='binary',\n",
    "        class_weight='balanced',\n",
    "        n_estimators=100,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.1,\n",
    "        min_split_gain=0.01,\n",
    "        min_child_samples=20,\n",
    "        min_data_in_leaf=20,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        verbose=-1,              # suppress LightGBM internal logs\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Step 5: Cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_val)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f},  Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# Step 6: Averages\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# Step 7: Model description\n",
    "model_name = 'LightGBM-Balanced'\n",
    "model_desc = 'OneHot+Scaler+5Fold-Stratified+VerboseOff'\n",
    "\n",
    "# Console summary\n",
    "print(\"\\n--- LightGBM Summary ---\")\n",
    "print(f\"Mean Accuracy : {mean_acc:.4f}\")\n",
    "print(f\"Mean Precision: {mean_prec:.4f}\")\n",
    "print(f\"Mean Recall   : {mean_rec:.4f}\")\n",
    "print(f\"Mean F1 Score : {mean_f1:.4f}\")\n",
    "\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# Step 8: Save to CSV\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "result_df = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "\n",
    "result_df.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ba0076c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Tuned LightGBM Model Scores:\n",
      "Accuracy : 0.7459\n",
      "Precision: 0.4328\n",
      "Recall   : 0.8283\n",
      "F1 Score : 0.5676\n",
      "Best Parameters: OrderedDict({'model__colsample_bytree': 1.0, 'model__learning_rate': 0.01, 'model__max_depth': 12, 'model__min_child_samples': 100, 'model__min_split_gain': 0.2, 'model__n_estimators': 100, 'model__subsample': 0.8664183933116096})\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Integer, Real\n",
    "\n",
    "# Load your real df_clean before this step\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag', 'Predicted Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "categorical_cols = ['Gender', 'Religion', 'Branch', 'Section-1', 'Section-2', 'Section-3']\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', drop='if_binary', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('model', LGBMClassifier(objective='binary', class_weight='balanced', verbose=-1, random_state=42))\n",
    "])\n",
    "\n",
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision': make_scorer(precision_score, zero_division=0),\n",
    "    'recall': make_scorer(recall_score),\n",
    "    'f1': make_scorer(f1_score)\n",
    "}\n",
    "\n",
    "param_space = {\n",
    "    'model__n_estimators': Integer(100, 500),\n",
    "    'model__max_depth': Integer(3, 12),\n",
    "    'model__learning_rate': Real(0.01, 0.3, prior='log-uniform'),\n",
    "    'model__min_child_samples': Integer(10, 100),\n",
    "    'model__min_split_gain': Real(0.0, 0.2),\n",
    "    'model__subsample': Real(0.6, 1.0),\n",
    "    'model__colsample_bytree': Real(0.6, 1.0)\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "opt = BayesSearchCV(\n",
    "    estimator=pipeline,\n",
    "    search_spaces=param_space,\n",
    "    scoring=scoring,\n",
    "    refit='recall',\n",
    "    n_iter=40,\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=0,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "opt.fit(X, y)\n",
    "\n",
    "best_model = opt.best_estimator_\n",
    "cv_results = cross_validate(best_model, X, y, cv=cv, scoring=scoring)\n",
    "\n",
    "print(\"Final Tuned LightGBM Model Scores:\")\n",
    "print(f\"Accuracy : {np.mean(cv_results['test_accuracy']):.4f}\")\n",
    "print(f\"Precision: {np.mean(cv_results['test_precision']):.4f}\")\n",
    "print(f\"Recall   : {np.mean(cv_results['test_recall']):.4f}\")\n",
    "print(f\"F1 Score : {np.mean(cv_results['test_f1']):.4f}\")\n",
    "print(\"Best Parameters:\", opt.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2340a2b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5: Accuracy=0.8819, Precision=0.7308, Recall=0.6552, F1=0.6909, Threshold=0.5000\n",
      "No threshold met all conditions. Using default 0.5.\n",
      "\n",
      "--- Threshold-Tuned LightGBM Results ---\n",
      "Threshold   : 0.5000\n",
      "Accuracy    : 0.7459\n",
      "Precision   : 0.4321\n",
      "Recall      : 0.8288\n",
      "F1 Score    : 0.5681\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    precision_recall_curve\n",
    ")\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Step 1: Prepare data\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag', 'Predicted Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# Step 2: Column categories\n",
    "categorical_cols = ['Gender', 'Religion', 'Branch', 'Section-1', 'Section-2', 'Section-3']\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Step 3: Preprocessing\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', drop='if_binary', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# Step 4: LightGBM Pipeline with best tuned params\n",
    "pipeline = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('model', LGBMClassifier(\n",
    "        objective='binary',\n",
    "        class_weight='balanced',\n",
    "        learning_rate=0.01,\n",
    "        max_depth=12,\n",
    "        min_child_samples=100,\n",
    "        min_split_gain=0.2,\n",
    "        n_estimators=100,\n",
    "        subsample=0.8664183933116096,\n",
    "        colsample_bytree=1.0,\n",
    "        verbose=-1,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Step 5: Cross-val predicted probabilities\n",
    "# Step 5 (Modified): Threshold tuning with all constraints\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_val, y_prob)\n",
    "best_thresh, best_f1 = 0.5, 0\n",
    "final_pred = (y_prob >= 0.5).astype(int)\n",
    "\n",
    "for p, r, t in zip(precisions, recalls, thresholds):\n",
    "    pred = (y_prob >= t).astype(int)\n",
    "    a = accuracy_score(y_val, pred)\n",
    "    f1 = f1_score(y_val, pred)\n",
    "    if r >= 0.85 and p > 0.50 and f1 > 0.60 and a > 0.70 and f1 > best_f1:\n",
    "        best_thresh = t\n",
    "        final_pred = pred\n",
    "        best_f1 = f1\n",
    "\n",
    "# Final metrics\n",
    "acc = accuracy_score(y_val, final_pred)\n",
    "prec = precision_score(y_val, final_pred, zero_division=0)\n",
    "rec = recall_score(y_val, final_pred)\n",
    "f1 = f1_score(y_val, final_pred)\n",
    "\n",
    "accuracy_list.append(acc)\n",
    "precision_list.append(prec)\n",
    "recall_list.append(rec)\n",
    "f1_list.append(f1)\n",
    "\n",
    "print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}, F1={f1:.4f}, Threshold={best_thresh:.4f}\")\n",
    "\n",
    "\n",
    "# Step 6: Find optimal threshold\n",
    "precisions, recalls, thresholds = precision_recall_curve(y, y_probs)\n",
    "valid = [(p, r, t) for p, r, t in zip(precisions, recalls, thresholds) if r >= 0.85 and p > 0.50]\n",
    "\n",
    "if valid:\n",
    "    best_prec, best_rec, best_thresh = max(valid, key=lambda x: 2*x[0]*x[1]/(x[0]+x[1]))\n",
    "else:\n",
    "    best_thresh = 0.5  # fallback\n",
    "    best_prec = precision_score(y, y_probs >= best_thresh, zero_division=0)\n",
    "    best_rec = recall_score(y, y_probs >= best_thresh)\n",
    "    best_f1 = f1_score(y, y_probs >= best_thresh)\n",
    "    print(\"No threshold met all conditions. Using default 0.5.\")\n",
    "\n",
    "# Step 7: Final metrics at optimal threshold\n",
    "y_pred_final = (y_probs >= best_thresh).astype(int)\n",
    "final_acc = accuracy_score(y, y_pred_final)\n",
    "final_prec = precision_score(y, y_pred_final, zero_division=0)\n",
    "final_rec = recall_score(y, y_pred_final)\n",
    "final_f1 = f1_score(y, y_pred_final)\n",
    "\n",
    "# Step 8: Print results\n",
    "print(\"\\n--- Threshold-Tuned LightGBM Results ---\")\n",
    "print(f\"Threshold   : {best_thresh:.4f}\")\n",
    "print(f\"Accuracy    : {final_acc:.4f}\")\n",
    "print(f\"Precision   : {final_prec:.4f}\")\n",
    "print(f\"Recall      : {final_rec:.4f}\")\n",
    "print(f\"F1 Score    : {final_f1:.4f}\")\n",
    "\n",
    "# Step 9: Save to CSV\n",
    "model_name = 'LightGBM-Tuned-Threshold'\n",
    "model_desc = 'BayesOpt+Threshold@{:.4f}'.format(best_thresh)\n",
    "\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "result_df = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(final_acc, 4),\n",
    "    'Precision': round(final_prec, 4),\n",
    "    'Recall': round(final_rec, 4),\n",
    "    'F1 Score': round(final_f1, 4)\n",
    "}])\n",
    "result_df.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "675c6094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.2000, Precision=0.2000, Recall=1.0000, F1=0.3333, Threshold=0.0000\n",
      "Fold 2: Accuracy=0.2000, Precision=0.2000, Recall=1.0000, F1=0.3333, Threshold=0.0000\n",
      "Fold 3: Accuracy=0.2000, Precision=0.2000, Recall=1.0000, F1=0.3333, Threshold=0.0000\n",
      "Fold 4: Accuracy=0.2069, Precision=0.2069, Recall=1.0000, F1=0.3429, Threshold=0.0001\n",
      "Fold 5: Accuracy=0.2014, Precision=0.2014, Recall=1.0000, F1=0.3353, Threshold=0.0000\n",
      "\n",
      "--- LightGBM Tuned Summary ---\n",
      "Mean Accuracy : 0.2017\n",
      "Mean Precision: 0.2017\n",
      "Mean Recall   : 1.0000\n",
      "Mean F1 Score : 0.3356\n",
      "\n",
      "CSV Row Format:\n",
      "LightGBM-Tuned-HighRecall,OneHot+Scaler+5Fold-Stratified+ThresholdTuned+VerboseOff,0.2017,0.2017,1.0000,0.3356\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "# Step 1: Prepare data\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag', 'Predicted Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# Optional: Check constant columns\n",
    "constant_cols = [col for col in X.columns if X[col].nunique() <= 1]\n",
    "if constant_cols:\n",
    "    print(\"Warning: Constant columns detected:\", constant_cols)\n",
    "\n",
    "# Step 2: Column categories\n",
    "categorical_cols = ['Gender', 'Religion', 'Branch', 'Section-1', 'Section-2', 'Section-3']\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Step 3: Preprocessing\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', drop='if_binary', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# Step 4: LightGBM Pipeline with tuned parameters\n",
    "pipeline = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('model', LGBMClassifier(\n",
    "        objective='binary',\n",
    "        class_weight='balanced',\n",
    "        n_estimators=200,           # Increased to allow more learning\n",
    "        max_depth=8,                # Slightly deeper trees\n",
    "        learning_rate=0.05,         # Lower for better convergence\n",
    "        min_split_gain=0.01,\n",
    "        min_child_samples=10,       # Lowered to capture smaller patterns\n",
    "        min_data_in_leaf=10,        # Lowered to reduce overfitting\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.7,      # Slightly reduced to increase diversity\n",
    "        scale_pos_weight=3,         # Increase to prioritize positive class (tune based on imbalance)\n",
    "        verbose=-1,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Step 5: Cross-validation with threshold tuning\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    # Fit the pipeline\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # Get probability scores for threshold tuning\n",
    "    y_prob = pipeline.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    # Find optimal threshold for recall >= 0.85\n",
    "    precisions, recalls, thresholds = precision_recall_curve(y_val, y_prob)\n",
    "    threshold = thresholds[np.argmax(recalls >= 0.85)] if np.any(recalls >= 0.85) else 0.5\n",
    "\n",
    "    # Apply threshold to predictions\n",
    "    y_pred = (y_prob >= threshold).astype(int)\n",
    "\n",
    "    # Calculate metrics\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}, F1={f1:.4f}, Threshold={threshold:.4f}\")\n",
    "\n",
    "# Step 6: Averages\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# Step 7: Model description\n",
    "model_name = 'LightGBM-Tuned-HighRecall'\n",
    "model_desc = 'OneHot+Scaler+5Fold-Stratified+ThresholdTuned+VerboseOff'\n",
    "\n",
    "# Console summary\n",
    "print(\"\\n--- LightGBM Tuned Summary ---\")\n",
    "print(f\"Mean Accuracy : {mean_acc:.4f}\")\n",
    "print(f\"Mean Precision: {mean_prec:.4f}\")\n",
    "print(f\"Mean Recall   : {mean_rec:.4f}\")\n",
    "print(f\"Mean F1 Score : {mean_f1:.4f}\")\n",
    "\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# Step 8: Save to CSV\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "result_df = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "\n",
    "result_df.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "262e550f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 05:09:00,066] A new study created in memory with name: no-name-c48d41ea-eb14-4108-ae75-11e17b819aac\n",
      "Best trial: 0. Best value: 0.629195:   2%|â–         | 1/50 [00:02<02:19,  2.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 05:09:02,917] Trial 0 finished with value: 0.6291954022988506 and parameters: {'n_estimators': 128, 'learning_rate': 0.03776545153747731, 'max_depth': 12, 'num_leaves': 56, 'min_child_samples': 10, 'subsample': 0.6797151887864643, 'colsample_bytree': 0.9726666766437326}. Best is trial 0 with value: 0.6291954022988506.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.855632:   4%|â–         | 2/50 [00:04<01:38,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 05:09:04,407] Trial 1 finished with value: 0.8556321839080461 and parameters: {'n_estimators': 220, 'learning_rate': 0.01515917719006464, 'max_depth': 8, 'num_leaves': 72, 'min_child_samples': 38, 'subsample': 0.8869344835853608, 'colsample_bytree': 0.6894328510243152}. Best is trial 1 with value: 0.8556321839080461.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.855632:   6%|â–Œ         | 3/50 [00:06<01:37,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 05:09:06,519] Trial 2 finished with value: 0.5956321839080461 and parameters: {'n_estimators': 258, 'learning_rate': 0.07828428468323015, 'max_depth': 9, 'num_leaves': 53, 'min_child_samples': 18, 'subsample': 0.66243541441678, 'colsample_bytree': 0.7890728599838094}. Best is trial 1 with value: 0.8556321839080461.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.855632:   8%|â–Š         | 4/50 [00:08<01:33,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 05:09:08,506] Trial 3 finished with value: 0.5744827586206895 and parameters: {'n_estimators': 153, 'learning_rate': 0.07961652575559582, 'max_depth': 12, 'num_leaves': 57, 'min_child_samples': 11, 'subsample': 0.6899152521677238, 'colsample_bytree': 0.7060759649880425}. Best is trial 1 with value: 0.8556321839080461.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.855632:  10%|â–ˆ         | 5/50 [00:09<01:19,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 05:09:09,785] Trial 4 finished with value: 0.6912643678160919 and parameters: {'n_estimators': 216, 'learning_rate': 0.035066117641882125, 'max_depth': 12, 'num_leaves': 45, 'min_child_samples': 34, 'subsample': 0.9581957080437951, 'colsample_bytree': 0.8581737811615229}. Best is trial 1 with value: 0.8556321839080461.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.855632:  12%|â–ˆâ–        | 6/50 [00:10<01:10,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 05:09:11,041] Trial 5 finished with value: 0.7117241379310345 and parameters: {'n_estimators': 288, 'learning_rate': 0.058908920513606064, 'max_depth': 3, 'num_leaves': 59, 'min_child_samples': 41, 'subsample': 0.8276717555398595, 'colsample_bytree': 0.6119590093341611}. Best is trial 1 with value: 0.8556321839080461.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.855632:  14%|â–ˆâ–        | 7/50 [00:12<01:02,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 05:09:12,174] Trial 6 finished with value: 0.8422988505747127 and parameters: {'n_estimators': 145, 'learning_rate': 0.020027728843667776, 'max_depth': 9, 'num_leaves': 38, 'min_child_samples': 32, 'subsample': 0.8161878452787625, 'colsample_bytree': 0.7647461096847645}. Best is trial 1 with value: 0.8556321839080461.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.855632:  16%|â–ˆâ–Œ        | 8/50 [00:12<00:52,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 05:09:12,980] Trial 7 finished with value: 0.6503448275862068 and parameters: {'n_estimators': 187, 'learning_rate': 0.12409588708599914, 'max_depth': 3, 'num_leaves': 30, 'min_child_samples': 29, 'subsample': 0.9466140942009941, 'colsample_bytree': 0.6691447296779649}. Best is trial 1 with value: 0.8556321839080461.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.855632:  18%|â–ˆâ–Š        | 9/50 [00:14<00:50,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 05:09:14,176] Trial 8 finished with value: 0.6022988505747126 and parameters: {'n_estimators': 177, 'learning_rate': 0.12655146444971932, 'max_depth': 12, 'num_leaves': 75, 'min_child_samples': 31, 'subsample': 0.8463003927517372, 'colsample_bytree': 0.7327360768221782}. Best is trial 1 with value: 0.8556321839080461.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.855632:  20%|â–ˆâ–ˆ        | 10/50 [00:15<00:50,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 05:09:15,495] Trial 9 finished with value: 0.6367816091954023 and parameters: {'n_estimators': 268, 'learning_rate': 0.1454777266352102, 'max_depth': 8, 'num_leaves': 43, 'min_child_samples': 48, 'subsample': 0.9610068594373843, 'colsample_bytree': 0.9758773445151506}. Best is trial 1 with value: 0.8556321839080461.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.951724:  22%|â–ˆâ–ˆâ–       | 11/50 [00:16<00:44,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 05:09:16,367] Trial 10 finished with value: 0.9517241379310345 and parameters: {'n_estimators': 100, 'learning_rate': 0.010846831452193811, 'max_depth': 6, 'num_leaves': 75, 'min_child_samples': 50, 'subsample': 0.7498808268079575, 'colsample_bytree': 0.8889084088320774}. Best is trial 10 with value: 0.9517241379310345.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.951724:  24%|â–ˆâ–ˆâ–       | 12/50 [00:17<00:43,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 05:09:17,526] Trial 11 finished with value: 0.8898850574712645 and parameters: {'n_estimators': 225, 'learning_rate': 0.011287629080143627, 'max_depth': 6, 'num_leaves': 79, 'min_child_samples': 50, 'subsample': 0.7414237504989598, 'colsample_bytree': 0.8730079552686579}. Best is trial 10 with value: 0.9517241379310345.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.951724:  26%|â–ˆâ–ˆâ–Œ       | 13/50 [00:18<00:38,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 05:09:18,372] Trial 12 finished with value: 0.9517241379310345 and parameters: {'n_estimators': 100, 'learning_rate': 0.010224727401565112, 'max_depth': 5, 'num_leaves': 79, 'min_child_samples': 50, 'subsample': 0.7344573466105763, 'colsample_bytree': 0.8815827007641857}. Best is trial 10 with value: 0.9517241379310345.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.951724:  28%|â–ˆâ–ˆâ–Š       | 14/50 [00:19<00:36,  1.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 05:09:19,265] Trial 13 finished with value: 0.8282758620689655 and parameters: {'n_estimators': 103, 'learning_rate': 0.04704378358158536, 'max_depth': 5, 'num_leaves': 67, 'min_child_samples': 45, 'subsample': 0.6009461906519354, 'colsample_bytree': 0.8975010479548778}. Best is trial 10 with value: 0.9517241379310345.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.951724:  30%|â–ˆâ–ˆâ–ˆ       | 15/50 [00:20<00:34,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 05:09:20,192] Trial 14 finished with value: 0.7733333333333332 and parameters: {'n_estimators': 101, 'learning_rate': 0.059678619405680665, 'max_depth': 5, 'num_leaves': 68, 'min_child_samples': 44, 'subsample': 0.7562732295873451, 'colsample_bytree': 0.9195805392233071}. Best is trial 10 with value: 0.9517241379310345.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.951724:  32%|â–ˆâ–ˆâ–ˆâ–      | 16/50 [00:21<00:33,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 05:09:21,204] Trial 15 finished with value: 0.6639080459770115 and parameters: {'n_estimators': 123, 'learning_rate': 0.10015836216042864, 'max_depth': 6, 'num_leaves': 22, 'min_child_samples': 23, 'subsample': 0.7551142669459798, 'colsample_bytree': 0.8296311911973553}. Best is trial 10 with value: 0.9517241379310345.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.951724:  34%|â–ˆâ–ˆâ–ˆâ–      | 17/50 [00:22<00:34,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 05:09:22,349] Trial 16 finished with value: 0.8489655172413793 and parameters: {'n_estimators': 149, 'learning_rate': 0.029263119056792394, 'max_depth': 5, 'num_leaves': 80, 'min_child_samples': 37, 'subsample': 0.7187782045209624, 'colsample_bytree': 0.9323223059546191}. Best is trial 10 with value: 0.9517241379310345.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.951724:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 18/50 [00:23<00:32,  1.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 05:09:23,269] Trial 17 finished with value: 0.7255172413793103 and parameters: {'n_estimators': 168, 'learning_rate': 0.05579666979857561, 'max_depth': 7, 'num_leaves': 64, 'min_child_samples': 50, 'subsample': 0.6352440536060159, 'colsample_bytree': 0.8378563661451135}. Best is trial 10 with value: 0.9517241379310345.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.951724:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 19/50 [00:24<00:29,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 05:09:24,114] Trial 18 finished with value: 0.7255172413793105 and parameters: {'n_estimators': 122, 'learning_rate': 0.10007784035383992, 'max_depth': 4, 'num_leaves': 72, 'min_child_samples': 44, 'subsample': 0.7806943849897323, 'colsample_bytree': 0.9943507334366697}. Best is trial 10 with value: 0.9517241379310345.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.951724:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 20/50 [00:25<00:29,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 05:09:25,202] Trial 19 finished with value: 0.8282758620689655 and parameters: {'n_estimators': 103, 'learning_rate': 0.02405228790605149, 'max_depth': 10, 'num_leaves': 62, 'min_child_samples': 26, 'subsample': 0.8827458733608705, 'colsample_bytree': 0.9380399539121217}. Best is trial 10 with value: 0.9517241379310345.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.951724:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/50 [00:26<00:29,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 05:09:26,254] Trial 20 finished with value: 0.7871264367816092 and parameters: {'n_estimators': 131, 'learning_rate': 0.0439603969531188, 'max_depth': 7, 'num_leaves': 80, 'min_child_samples': 41, 'subsample': 0.7195268080632596, 'colsample_bytree': 0.7972989192455759}. Best is trial 10 with value: 0.9517241379310345.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.951724:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 22/50 [00:27<00:29,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 05:09:27,441] Trial 21 finished with value: 0.8967816091954024 and parameters: {'n_estimators': 226, 'learning_rate': 0.01037528849905573, 'max_depth': 6, 'num_leaves': 76, 'min_child_samples': 49, 'subsample': 0.7390810822435588, 'colsample_bytree': 0.8768983604715099}. Best is trial 10 with value: 0.9517241379310345.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.951724:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 23/50 [00:28<00:30,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 05:09:28,716] Trial 22 finished with value: 0.8967816091954024 and parameters: {'n_estimators': 236, 'learning_rate': 0.011007248615682306, 'max_depth': 6, 'num_leaves': 74, 'min_child_samples': 47, 'subsample': 0.7869216700868891, 'colsample_bytree': 0.8865150673793363}. Best is trial 10 with value: 0.9517241379310345.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.951724:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 24/50 [00:29<00:28,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 05:09:29,748] Trial 23 finished with value: 0.8147126436781609 and parameters: {'n_estimators': 199, 'learning_rate': 0.030906387944571075, 'max_depth': 4, 'num_leaves': 68, 'min_child_samples': 41, 'subsample': 0.7060381837782608, 'colsample_bytree': 0.8210247653181326}. Best is trial 10 with value: 0.9517241379310345.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.951724:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 25/50 [00:30<00:27,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 05:09:30,823] Trial 24 finished with value: 0.8285057471264368 and parameters: {'n_estimators': 245, 'learning_rate': 0.023045639398731263, 'max_depth': 4, 'num_leaves': 75, 'min_child_samples': 46, 'subsample': 0.6536449940697424, 'colsample_bytree': 0.9041894404710098}. Best is trial 10 with value: 0.9517241379310345.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.951724:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/50 [00:32<00:28,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 05:09:32,196] Trial 25 finished with value: 0.8556321839080461 and parameters: {'n_estimators': 297, 'learning_rate': 0.011474715808528919, 'max_depth': 6, 'num_leaves': 70, 'min_child_samples': 50, 'subsample': 0.7726291860917229, 'colsample_bytree': 0.8587917231507504}. Best is trial 10 with value: 0.9517241379310345.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.951724:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 27/50 [00:33<00:26,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 05:09:33,361] Trial 26 finished with value: 0.6641379310344828 and parameters: {'n_estimators': 197, 'learning_rate': 0.06820888918498764, 'max_depth': 7, 'num_leaves': 49, 'min_child_samples': 36, 'subsample': 0.7308240028346595, 'colsample_bytree': 0.9531499455692264}. Best is trial 10 with value: 0.9517241379310345.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.951724:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 28/50 [00:34<00:24,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 05:09:34,335] Trial 27 finished with value: 0.7457471264367815 and parameters: {'n_estimators': 164, 'learning_rate': 0.04620710487340524, 'max_depth': 5, 'num_leaves': 65, 'min_child_samples': 42, 'subsample': 0.8044646989020551, 'colsample_bytree': 0.7711526860115611}. Best is trial 10 with value: 0.9517241379310345.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.951724:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 29/50 [00:35<00:21,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 05:09:35,210] Trial 28 finished with value: 0.8967816091954024 and parameters: {'n_estimators': 117, 'learning_rate': 0.02432855997973176, 'max_depth': 4, 'num_leaves': 76, 'min_child_samples': 47, 'subsample': 0.8519064068973364, 'colsample_bytree': 0.8522363175598463}. Best is trial 10 with value: 0.9517241379310345.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.951724:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 30/50 [00:36<00:20,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 05:09:36,227] Trial 29 finished with value: 0.8078160919540232 and parameters: {'n_estimators': 135, 'learning_rate': 0.029869354427433298, 'max_depth': 6, 'num_leaves': 60, 'min_child_samples': 39, 'subsample': 0.6837340022116123, 'colsample_bytree': 0.962105385255174}. Best is trial 10 with value: 0.9517241379310345.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.951724:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/50 [00:37<00:20,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 05:09:37,466] Trial 30 finished with value: 0.684367816091954 and parameters: {'n_estimators': 114, 'learning_rate': 0.04115242987748787, 'max_depth': 8, 'num_leaves': 77, 'min_child_samples': 18, 'subsample': 0.6250207732260842, 'colsample_bytree': 0.8897642913381976}. Best is trial 10 with value: 0.9517241379310345.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.951724:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 32/50 [00:38<00:20,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 05:09:38,635] Trial 31 finished with value: 0.8967816091954024 and parameters: {'n_estimators': 239, 'learning_rate': 0.011106695601456587, 'max_depth': 6, 'num_leaves': 73, 'min_child_samples': 48, 'subsample': 0.7867866157603952, 'colsample_bytree': 0.8899075035349885}. Best is trial 10 with value: 0.9517241379310345.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.951724:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 33/50 [00:39<00:19,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 05:09:39,824] Trial 32 finished with value: 0.8489655172413793 and parameters: {'n_estimators': 211, 'learning_rate': 0.018862451704580917, 'max_depth': 7, 'num_leaves': 71, 'min_child_samples': 46, 'subsample': 0.7624874045342221, 'colsample_bytree': 0.9153053705024481}. Best is trial 10 with value: 0.9517241379310345.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.951724:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 34/50 [00:40<00:17,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 05:09:40,900] Trial 33 finished with value: 0.8556321839080461 and parameters: {'n_estimators': 233, 'learning_rate': 0.018220733426403637, 'max_depth': 5, 'num_leaves': 75, 'min_child_samples': 50, 'subsample': 0.7029017813552011, 'colsample_bytree': 0.8788076264736664}. Best is trial 10 with value: 0.9517241379310345.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.951724:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 35/50 [00:42<00:17,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 05:09:42,082] Trial 34 finished with value: 0.7050574712643678 and parameters: {'n_estimators': 250, 'learning_rate': 0.035149376106872646, 'max_depth': 6, 'num_leaves': 80, 'min_child_samples': 43, 'subsample': 0.7987377969076876, 'colsample_bytree': 0.8117581655719849}. Best is trial 10 with value: 0.9517241379310345.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.951724:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 36/50 [00:43<00:16,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 05:09:43,321] Trial 35 finished with value: 0.8213793103448275 and parameters: {'n_estimators': 263, 'learning_rate': 0.016237062072846423, 'max_depth': 7, 'num_leaves': 71, 'min_child_samples': 47, 'subsample': 0.6716335774585689, 'colsample_bytree': 0.8477009821405823}. Best is trial 10 with value: 0.9517241379310345.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.951724:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 37/50 [00:44<00:14,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 05:09:44,353] Trial 36 finished with value: 0.8967816091954024 and parameters: {'n_estimators': 209, 'learning_rate': 0.010209488495447649, 'max_depth': 9, 'num_leaves': 65, 'min_child_samples': 47, 'subsample': 0.735802892225231, 'colsample_bytree': 0.8653466017617061}. Best is trial 10 with value: 0.9517241379310345.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.951724:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 38/50 [00:45<00:14,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 05:09:45,600] Trial 37 finished with value: 0.6298850574712643 and parameters: {'n_estimators': 277, 'learning_rate': 0.09468699595133678, 'max_depth': 5, 'num_leaves': 57, 'min_child_samples': 39, 'subsample': 0.8318048649502692, 'colsample_bytree': 0.9397086554872351}. Best is trial 10 with value: 0.9517241379310345.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.951724:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 39/50 [00:46<00:12,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 05:09:46,662] Trial 38 finished with value: 0.8149425287356322 and parameters: {'n_estimators': 223, 'learning_rate': 0.037374936322662144, 'max_depth': 3, 'num_leaves': 73, 'min_child_samples': 12, 'subsample': 0.8768792251534108, 'colsample_bytree': 0.776078461610752}. Best is trial 10 with value: 0.9517241379310345.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.951724:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 40/50 [00:47<00:11,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 05:09:47,868] Trial 39 finished with value: 0.8285057471264368 and parameters: {'n_estimators': 185, 'learning_rate': 0.02491091476835732, 'max_depth': 8, 'num_leaves': 54, 'min_child_samples': 48, 'subsample': 0.9221694618987195, 'colsample_bytree': 0.9139007478444008}. Best is trial 10 with value: 0.9517241379310345.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.951724:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 41/50 [00:48<00:10,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 05:09:48,922] Trial 40 finished with value: 0.6641379310344827 and parameters: {'n_estimators': 142, 'learning_rate': 0.08897428618663465, 'max_depth': 10, 'num_leaves': 77, 'min_child_samples': 34, 'subsample': 0.6962596419270926, 'colsample_bytree': 0.7488255532473076}. Best is trial 10 with value: 0.9517241379310345.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.951724:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 42/50 [00:49<00:08,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 05:09:49,799] Trial 41 finished with value: 0.9174712643678161 and parameters: {'n_estimators': 114, 'learning_rate': 0.019164896408901823, 'max_depth': 4, 'num_leaves': 77, 'min_child_samples': 45, 'subsample': 0.8251403034166988, 'colsample_bytree': 0.8466864679702043}. Best is trial 10 with value: 0.9517241379310345.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.951724:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 43/50 [00:50<00:06,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 05:09:50,657] Trial 42 finished with value: 0.9174712643678161 and parameters: {'n_estimators': 113, 'learning_rate': 0.018583469151776725, 'max_depth': 4, 'num_leaves': 78, 'min_child_samples': 45, 'subsample': 0.8156153745216101, 'colsample_bytree': 0.8789255404048535}. Best is trial 10 with value: 0.9517241379310345.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.951724:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 44/50 [00:51<00:05,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 05:09:51,469] Trial 43 finished with value: 0.9448275862068964 and parameters: {'n_estimators': 112, 'learning_rate': 0.018618279300258726, 'max_depth': 3, 'num_leaves': 78, 'min_child_samples': 44, 'subsample': 0.8598547098729525, 'colsample_bytree': 0.8119986338395975}. Best is trial 10 with value: 0.9517241379310345.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.951724:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 45/50 [00:52<00:04,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 05:09:52,429] Trial 44 finished with value: 0.8967816091954024 and parameters: {'n_estimators': 107, 'learning_rate': 0.03071062565970814, 'max_depth': 3, 'num_leaves': 36, 'min_child_samples': 44, 'subsample': 0.8619744456042926, 'colsample_bytree': 0.8113438752303485}. Best is trial 10 with value: 0.9517241379310345.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.951724:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 46/50 [00:53<00:03,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 05:09:53,356] Trial 45 finished with value: 0.9448275862068964 and parameters: {'n_estimators': 115, 'learning_rate': 0.017312648754869767, 'max_depth': 3, 'num_leaves': 77, 'min_child_samples': 45, 'subsample': 0.9138153608664417, 'colsample_bytree': 0.795237556732132}. Best is trial 10 with value: 0.9517241379310345.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.951724:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 47/50 [00:54<00:02,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 05:09:54,160] Trial 46 finished with value: 0.8489655172413793 and parameters: {'n_estimators': 128, 'learning_rate': 0.05341266900058069, 'max_depth': 3, 'num_leaves': 68, 'min_child_samples': 39, 'subsample': 0.9257856314291424, 'colsample_bytree': 0.7365534124782015}. Best is trial 10 with value: 0.9517241379310345.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.951724:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 48/50 [00:54<00:01,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 05:09:55,042] Trial 47 finished with value: 0.8970114942528736 and parameters: {'n_estimators': 141, 'learning_rate': 0.037661595052264574, 'max_depth': 3, 'num_leaves': 70, 'min_child_samples': 42, 'subsample': 0.9834707804100716, 'colsample_bytree': 0.708487696816511}. Best is trial 10 with value: 0.9517241379310345.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.951724:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 49/50 [00:55<00:00,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 05:09:55,980] Trial 48 finished with value: 0.7324137931034483 and parameters: {'n_estimators': 155, 'learning_rate': 0.0697816054263257, 'max_depth': 4, 'num_leaves': 78, 'min_child_samples': 35, 'subsample': 0.9122810385839624, 'colsample_bytree': 0.7884019519564875}. Best is trial 10 with value: 0.9517241379310345.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.951724: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:56<00:00,  1.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 05:09:56,711] Trial 49 finished with value: 0.7457471264367815 and parameters: {'n_estimators': 113, 'learning_rate': 0.12523752096680826, 'max_depth': 3, 'num_leaves': 23, 'min_child_samples': 45, 'subsample': 0.9055562812309266, 'colsample_bytree': 0.8340747245825457}. Best is trial 10 with value: 0.9517241379310345.\n",
      "Fold 1: Accuracy=0.8345, Precision=1.0000, Recall=0.1724, F1=0.2941, Threshold=0.50\n",
      "Fold 2: Accuracy=0.8552, Precision=1.0000, Recall=0.2759, F1=0.4324, Threshold=0.50\n",
      "Fold 3: Accuracy=0.8621, Precision=0.9091, Recall=0.3448, F1=0.5000, Threshold=0.50\n",
      "Fold 4: Accuracy=0.8621, Precision=0.8571, Recall=0.4000, F1=0.5455, Threshold=0.50\n",
      "Fold 5: Accuracy=0.8333, Precision=1.0000, Recall=0.1724, F1=0.2941, Threshold=0.50\n",
      "\n",
      "--- Final LightGBM Optimized ---\n",
      "Mean Accuracy : 0.8494\n",
      "Mean Precision: 0.9532\n",
      "Mean Recall   : 0.2731\n",
      "Mean F1 Score : 0.4132\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import optuna\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "# Step 1: Prepare data\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag', 'Predicted Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# Check constant columns\n",
    "constant_cols = [col for col in X.columns if X[col].nunique() <= 1]\n",
    "if constant_cols:\n",
    "    print(\"Warning: Constant columns detected:\", constant_cols)\n",
    "\n",
    "# Step 2: Column types\n",
    "categorical_cols = ['Gender', 'Religion', 'Branch', 'Section-1', 'Section-2', 'Section-3']\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Step 3: Preprocessor\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', drop='if_binary', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# Step 4: Classifier wrapper for threshold tuning\n",
    "class ThresholdLGBMClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, **params):\n",
    "        self.model = LGBMClassifier(**params)\n",
    "        self.threshold = 0.5\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.model.fit(X, y)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        probas = self.model.predict_proba(X)[:, 1]\n",
    "        return (probas >= self.threshold).astype(int)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return self.model.predict_proba(X)\n",
    "\n",
    "# Step 5: Objective function for Optuna\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 300),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.15),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 20, 80),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 10, 50),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 1.0),\n",
    "        \"class_weight\": \"balanced\",\n",
    "        \"random_state\": 42,\n",
    "        \"verbose\": -1\n",
    "    }\n",
    "\n",
    "    model = ThresholdLGBMClassifier(**params)\n",
    "    pipeline = Pipeline([('prep', preprocessor), ('clf', model)])\n",
    "    \n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    recalls = []\n",
    "\n",
    "    for train_idx, val_idx in cv.split(X, y):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        probas = pipeline.predict_proba(X_val)[:, 1]\n",
    "\n",
    "        # Find best threshold to maximize recall >= 0.85\n",
    "        best_recall, best_thresh = 0, 0.5\n",
    "        for thresh in np.arange(0.3, 0.8, 0.02):\n",
    "            preds = (probas >= thresh).astype(int)\n",
    "            rec = recall_score(y_val, preds)\n",
    "            if rec > best_recall:\n",
    "                best_recall, best_thresh = rec, thresh\n",
    "\n",
    "        model.threshold = best_thresh\n",
    "        preds = (probas >= best_thresh).astype(int)\n",
    "\n",
    "        recalls.append(recall_score(y_val, preds))\n",
    "\n",
    "    return np.mean(recalls)\n",
    "\n",
    "# Step 6: Tune with Optuna\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=50, show_progress_bar=True)\n",
    "best_params = study.best_trial.params\n",
    "\n",
    "# Step 7: Final Evaluation\n",
    "model = ThresholdLGBMClassifier(**best_params)\n",
    "pipeline = Pipeline([('prep', preprocessor), ('clf', model)])\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    probas = pipeline.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    # Best threshold for this fold\n",
    "    best_thresh, best_f1 = 0.5, 0\n",
    "    for thresh in np.arange(0.3, 0.8, 0.01):\n",
    "        preds = (probas >= thresh).astype(int)\n",
    "        rec = recall_score(y_val, preds)\n",
    "        prec = precision_score(y_val, preds, zero_division=0)\n",
    "        f1_val = f1_score(y_val, preds)\n",
    "        if rec >= 0.85 and prec > 0.5 and f1_val > best_f1:\n",
    "            best_f1, best_thresh = f1_val, thresh\n",
    "\n",
    "    model.threshold = best_thresh\n",
    "    y_pred = pipeline.predict(X_val)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}, F1={f1:.4f}, Threshold={best_thresh:.2f}\")\n",
    "\n",
    "# Final metrics\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "print(\"\\n--- Final LightGBM Optimized ---\")\n",
    "print(f\"Mean Accuracy : {mean_acc:.4f}\")\n",
    "print(f\"Mean Precision: {mean_prec:.4f}\")\n",
    "print(f\"Mean Recall   : {mean_rec:.4f}\")\n",
    "print(f\"Mean F1 Score : {mean_f1:.4f}\")\n",
    "\n",
    "# CSV logging\n",
    "model_name = 'LightGBM-Optuna-Threshold'\n",
    "model_desc = 'Optuna+ThresholdTuning+5Fold'\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "result_df = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "result_df.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec73b938",
   "metadata": {},
   "source": [
    "# CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e8057ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.8690, Precision=0.7083,  Recall=0.5862, F1=0.6415\n",
      "Fold 2: Accuracy=0.8483, Precision=0.7059,  Recall=0.4138, F1=0.5217\n",
      "Fold 3: Accuracy=0.8414, Precision=0.5938,  Recall=0.6552, F1=0.6230\n",
      "Fold 4: Accuracy=0.8483, Precision=0.6250,  Recall=0.6667, F1=0.6452\n",
      "Fold 5: Accuracy=0.8750, Precision=0.6774,  Recall=0.7241, F1=0.7000\n",
      "\n",
      "--- CatBoost Summary ---\n",
      "Mean Accuracy : 0.8564\n",
      "Mean Precision: 0.6621\n",
      "Mean Recall   : 0.6092\n",
      "Mean F1 Score : 0.6263\n",
      "\n",
      "CSV Row Format:\n",
      "CatBoost-Balanced,OneHot+Scaler+5Fold-Stratified+VerboseOff,0.8564,0.6621,0.6092,0.6263\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Step 1: Prepare data\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag', 'Predicted Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# Optional: Check constant columns\n",
    "constant_cols = [col for col in X.columns if X[col].nunique() <= 1]\n",
    "if constant_cols:\n",
    "    print(\"Warning: Constant columns detected:\", constant_cols)\n",
    "\n",
    "# Step 2: Column categories\n",
    "categorical_cols = ['Gender', 'Religion', 'Branch', 'Section-1', 'Section-2', 'Section-3']\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Step 3: Preprocessing\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', drop='if_binary', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# Step 4: CatBoost Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('model', CatBoostClassifier(\n",
    "        iterations=100,\n",
    "        learning_rate=0.1,\n",
    "        depth=6,\n",
    "        auto_class_weights='Balanced',\n",
    "        verbose=0,  # suppress CatBoost internal logs\n",
    "        random_seed=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Step 5: Cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_val)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f},  Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# Step 6: Averages\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# Step 7: Model description\n",
    "model_name = 'CatBoost-Balanced'\n",
    "model_desc = 'OneHot+Scaler+5Fold-Stratified+VerboseOff'\n",
    "\n",
    "# Console summary\n",
    "print(\"\\n--- CatBoost Summary ---\")\n",
    "print(f\"Mean Accuracy : {mean_acc:.4f}\")\n",
    "print(f\"Mean Precision: {mean_prec:.4f}\")\n",
    "print(f\"Mean Recall   : {mean_rec:.4f}\")\n",
    "print(f\"Mean F1 Score : {mean_f1:.4f}\")\n",
    "\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# Step 8: Save to CSV\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "result_df = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "\n",
    "result_df.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "73991d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.8759, Precision=0.7895,  Recall=0.5172, F1=0.6250\n",
      "Fold 2: Accuracy=0.8483, Precision=0.7059,  Recall=0.4138, F1=0.5217\n",
      "Fold 3: Accuracy=0.8345, Precision=0.5806,  Recall=0.6207, F1=0.6000\n",
      "Fold 4: Accuracy=0.8414, Precision=0.6207,  Recall=0.6000, F1=0.6102\n",
      "Fold 5: Accuracy=0.8681, Precision=0.7273,  Recall=0.5517, F1=0.6275\n",
      "\n",
      "--- CatBoost Tuned Summary ---\n",
      "Mean Accuracy : 0.8536\n",
      "Mean Precision: 0.6848\n",
      "Mean Recall   : 0.5407\n",
      "Mean F1 Score : 0.5969\n",
      "\n",
      "CSV Row Format:\n",
      "CatBoost-Tuned,OneHot+Scaler+5Fold+Depth8+LR0.05+BagTemp1.0,0.8536,0.6848,0.5407,0.5969\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Step 1: Prepare data\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag', 'Predicted Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# Optional: Check constant columns\n",
    "constant_cols = [col for col in X.columns if X[col].nunique() <= 1]\n",
    "if constant_cols:\n",
    "    print(\"Warning: Constant columns detected:\", constant_cols)\n",
    "\n",
    "# Step 2: Column categories\n",
    "categorical_cols = ['Gender', 'Religion', 'Branch', 'Section-1', 'Section-2', 'Section-3']\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Step 3: Preprocessing\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', drop='if_binary', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# Step 4: Tuned CatBoost Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('model', CatBoostClassifier(\n",
    "        iterations=300,\n",
    "        learning_rate=0.05,\n",
    "        depth=8,\n",
    "        l2_leaf_reg=5,\n",
    "        border_count=128,\n",
    "        bagging_temperature=1.0,\n",
    "        auto_class_weights='Balanced',\n",
    "        random_seed=42,\n",
    "        verbose=0\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Step 5: Cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_val)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f},  Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# Step 6: Averages\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# Step 7: Model description\n",
    "model_name = 'CatBoost-Tuned'\n",
    "model_desc = 'OneHot+Scaler+5Fold+Depth8+LR0.05+BagTemp1.0'\n",
    "\n",
    "# Console summary\n",
    "print(\"\\n--- CatBoost Tuned Summary ---\")\n",
    "print(f\"Mean Accuracy : {mean_acc:.4f}\")\n",
    "print(f\"Mean Precision: {mean_prec:.4f}\")\n",
    "print(f\"Mean Recall   : {mean_rec:.4f}\")\n",
    "print(f\"Mean F1 Score : {mean_f1:.4f}\")\n",
    "\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# Step 8: Save to CSV\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "result_df = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "\n",
    "result_df.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "507c491c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.8828, Precision=0.8750,  Recall=0.4828, F1=0.6222\n",
      "Fold 2: Accuracy=0.8414, Precision=0.6875,  Recall=0.3793, F1=0.4889\n",
      "Fold 3: Accuracy=0.8483, Precision=0.6296,  Recall=0.5862, F1=0.6071\n",
      "Fold 4: Accuracy=0.8552, Precision=0.6667,  Recall=0.6000, F1=0.6316\n",
      "Fold 5: Accuracy=0.8472, Precision=0.6667,  Recall=0.4828, F1=0.5600\n",
      "\n",
      "--- CatBoost Aggressive Summary ---\n",
      "Mean Accuracy : 0.8550\n",
      "Mean Precision: 0.7051\n",
      "Mean Recall   : 0.5062\n",
      "Mean F1 Score : 0.5820\n",
      "\n",
      "CSV Row Format:\n",
      "CatBoost-Aggressive,OneHot+Scaler+500Iter+LR0.03+Depth10+Bag0.25,0.8550,0.7051,0.5062,0.5820\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Prepare data\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag', 'Predicted Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# Optional: Check constant columns\n",
    "constant_cols = [col for col in X.columns if X[col].nunique() <= 1]\n",
    "if constant_cols:\n",
    "    print(\"Warning: Constant columns detected:\", constant_cols)\n",
    "\n",
    "# Define column types\n",
    "categorical_cols = ['Gender', 'Religion', 'Branch', 'Section-1', 'Section-2', 'Section-3']\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Preprocessing\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', drop='if_binary', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# Aggressively Tuned CatBoost\n",
    "pipeline = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('model', CatBoostClassifier(\n",
    "        iterations=500,\n",
    "        learning_rate=0.03,\n",
    "        depth=10,\n",
    "        l2_leaf_reg=3,\n",
    "        border_count=128,\n",
    "        bagging_temperature=0.25,\n",
    "        auto_class_weights='Balanced',\n",
    "        random_seed=42,\n",
    "        verbose=0\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_val)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f},  Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# Averages\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# Description\n",
    "model_name = 'CatBoost-Aggressive'\n",
    "model_desc = 'OneHot+Scaler+500Iter+LR0.03+Depth10+Bag0.25'\n",
    "\n",
    "print(\"\\n--- CatBoost Aggressive Summary ---\")\n",
    "print(f\"Mean Accuracy : {mean_acc:.4f}\")\n",
    "print(f\"Mean Precision: {mean_prec:.4f}\")\n",
    "print(f\"Mean Recall   : {mean_rec:.4f}\")\n",
    "print(f\"Mean F1 Score : {mean_f1:.4f}\")\n",
    "\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# Save to CSV\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "result_df = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "\n",
    "result_df.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a769b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.8897, Precision=0.7826, Recall=0.6207, F1=0.6923\n",
      "Fold 2: Accuracy=0.8621, Precision=0.7143, Recall=0.5172, F1=0.6000\n",
      "Fold 3: Accuracy=0.8138, Precision=0.5263, Recall=0.6897, F1=0.5970\n",
      "Fold 4: Accuracy=0.8621, Precision=0.6471, Recall=0.7333, F1=0.6875\n",
      "Fold 5: Accuracy=0.8819, Precision=0.7000, Recall=0.7241, F1=0.7119\n",
      "\n",
      "--- CatBoost Bayesian Tuning Summary ---\n",
      "Mean Accuracy : 0.8619\n",
      "Mean Precision: 0.6741\n",
      "Mean Recall   : 0.6570\n",
      "Mean F1 Score : 0.6577\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer\n",
    "\n",
    "# Prepare data\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag', 'Predicted Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# Constant column check\n",
    "constant_cols = [col for col in X.columns if X[col].nunique() <= 1]\n",
    "if constant_cols:\n",
    "    print(\"Warning: Constant columns detected:\", constant_cols)\n",
    "\n",
    "# Categorical and numerical columns\n",
    "categorical_cols = ['Gender', 'Religion', 'Branch', 'Section-1', 'Section-2', 'Section-3']\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Preprocessing\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', drop='if_binary', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# Define CatBoost with default settings (will be tuned)\n",
    "cat_model = CatBoostClassifier(\n",
    "    auto_class_weights='Balanced',\n",
    "    random_seed=42,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Create pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('model', cat_model)\n",
    "])\n",
    "\n",
    "# Define parameter search space\n",
    "param_space = {\n",
    "    'model__iterations': Integer(300, 800),\n",
    "    'model__learning_rate': Real(0.01, 0.2, prior='log-uniform'),\n",
    "    'model__depth': Integer(4, 10),\n",
    "    'model__l2_leaf_reg': Real(1, 10),\n",
    "    'model__bagging_temperature': Real(0, 1.0),\n",
    "    'model__border_count': Integer(32, 254)\n",
    "}\n",
    "\n",
    "# Setup Bayesian optimization with 5-fold stratified CV\n",
    "opt = BayesSearchCV(\n",
    "    estimator=pipeline,\n",
    "    search_spaces=param_space,\n",
    "    scoring='accuracy',\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    n_iter=32,\n",
    "    n_jobs=-1,\n",
    "    verbose=0,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the search\n",
    "opt.fit(X, y)\n",
    "\n",
    "# Extract best pipeline and evaluate manually\n",
    "best_pipeline = opt.best_estimator_\n",
    "\n",
    "# Manual 5-Fold Eval\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "acc_list, prec_list, rec_list, f1_list = [], [], [], []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    best_pipeline.fit(X_train, y_train)\n",
    "    y_pred = best_pipeline.predict(X_val)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    acc_list.append(acc)\n",
    "    prec_list.append(prec)\n",
    "    rec_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# Averages\n",
    "mean_acc = np.mean(acc_list)\n",
    "mean_prec = np.mean(prec_list)\n",
    "mean_rec = np.mean(rec_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "model_name = 'CatBoost-BayesTuned'\n",
    "model_desc = 'OneHot+Scaler+BayesSearch+5Fold'\n",
    "\n",
    "print(\"\\n--- CatBoost Bayesian Tuning Summary ---\")\n",
    "print(f\"Mean Accuracy : {mean_acc:.4f}\")\n",
    "print(f\"Mean Precision: {mean_prec:.4f}\")\n",
    "print(f\"Mean Recall   : {mean_rec:.4f}\")\n",
    "print(f\"Mean F1 Score : {mean_f1:.4f}\")\n",
    "\n",
    "# Save to CSV\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "result_df = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "result_df.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395d5dd5",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "686a2696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.8069, Precision=0.5143, Recall=0.6207, F1=0.5625\n",
      "Fold 2: Accuracy=0.8207, Precision=0.5556, Recall=0.5172, F1=0.5357\n",
      "Fold 3: Accuracy=0.7655, Precision=0.4444, Recall=0.6897, F1=0.5405\n",
      "Fold 4: Accuracy=0.7793, Precision=0.4783, Recall=0.7333, F1=0.5789\n",
      "Fold 5: Accuracy=0.7222, Precision=0.3878, Recall=0.6552, F1=0.4872\n",
      "\n",
      "--- SVM (RBF) Summary ---\n",
      "Name                          : SVC-RBF-Pipeline\n",
      "Description                   : OneHot+Scaler+5Fold+Balanced\n",
      "Accuracy                      : 0.7789\n",
      "Precision                     : 0.4761\n",
      "Recall                        : 0.6432\n",
      "F1 Score                      : 0.5410\n",
      "\n",
      "CSV Row Format:\n",
      "SVC-RBF-Pipeline,OneHot+Scaler+5Fold+Balanced,0.7789,0.4761,0.6432,0.5410\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Data setup\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag', 'Predicted Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# Identify column types\n",
    "categorical_cols = ['Gender', 'Religion', 'Branch', 'Section-1', 'Section-2', 'Section-3']\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Preprocessing\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', drop='if_binary', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# SVM model inside pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('model', SVC(kernel='rbf', class_weight='balanced', probability=True, random_state=42))\n",
    "])\n",
    "\n",
    "# CV setup\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n",
    "\n",
    "# Cross-validation loop\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_val)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# Mean scores\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# Model info\n",
    "model_name = 'SVC-RBF-Pipeline'\n",
    "model_desc = 'OneHot+Scaler+5Fold+Balanced'\n",
    "\n",
    "print(\"\\n--- SVM (RBF) Summary ---\")\n",
    "print(f\"{'Name':<30}: {model_name}\")\n",
    "print(f\"{'Description':<30}: {model_desc}\")\n",
    "print(f\"{'Accuracy':<30}: {mean_acc:.4f}\")\n",
    "print(f\"{'Precision':<30}: {mean_prec:.4f}\")\n",
    "print(f\"{'Recall':<30}: {mean_rec:.4f}\")\n",
    "print(f\"{'F1 Score':<30}: {mean_f1:.4f}\")\n",
    "\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# Save to CSV\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "new_row = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "\n",
    "new_row.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac3d4ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.8414, Precision=0.6000, Recall=0.6207, F1=0.6102\n",
      "Fold 2: Accuracy=0.8414, Precision=0.6364, Recall=0.4828, F1=0.5490\n",
      "Fold 3: Accuracy=0.8552, Precision=0.6429, Recall=0.6207, F1=0.6316\n",
      "Fold 4: Accuracy=0.8069, Precision=0.5357, Recall=0.5000, F1=0.5172\n",
      "Fold 5: Accuracy=0.8333, Precision=0.5862, Recall=0.5862, F1=0.5862\n",
      "\n",
      "--- Tuned SVM (RBF) Summary ---\n",
      "Mean Accuracy : 0.8356\n",
      "Mean Precision: 0.6002\n",
      "Mean Recall   : 0.5621\n",
      "Mean F1 Score : 0.5788\n",
      "\n",
      "CSV Row Format:\n",
      "SVC-BayesTuned,OneHot+Scaler+BayesSearch+RBF+Balanced,0.8356,0.6002,0.5621,0.5788\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Step 1: Data setup\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag', 'Predicted Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# Step 2: Column types\n",
    "categorical_cols = ['Gender', 'Religion', 'Branch', 'Section-1', 'Section-2', 'Section-3']\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Step 3: Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', drop='if_binary', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# Step 4: SVC pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('model', SVC(probability=True, random_state=42))\n",
    "])\n",
    "\n",
    "# Step 5: Define search space\n",
    "param_space = {\n",
    "    'model__C': Real(0.1, 100, prior='log-uniform'),\n",
    "    'model__gamma': Real(1e-4, 1.0, prior='log-uniform'),\n",
    "    'model__kernel': ['rbf'],\n",
    "    'model__class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "# Step 6: Bayesian optimization\n",
    "opt = BayesSearchCV(\n",
    "    estimator=pipeline,\n",
    "    search_spaces=param_space,\n",
    "    scoring='accuracy',\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    n_iter=32,\n",
    "    n_jobs=-1,\n",
    "    verbose=0,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Step 7: Fit optimizer\n",
    "opt.fit(X, y)\n",
    "best_pipeline = opt.best_estimator_\n",
    "\n",
    "# Step 8: Manual evaluation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "acc_list, prec_list, rec_list, f1_list = [], [], [], []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    best_pipeline.fit(X_train, y_train)\n",
    "    y_pred = best_pipeline.predict(X_val)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    acc_list.append(acc)\n",
    "    prec_list.append(prec)\n",
    "    rec_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# Step 9: Aggregate metrics\n",
    "mean_acc = np.mean(acc_list)\n",
    "mean_prec = np.mean(prec_list)\n",
    "mean_rec = np.mean(rec_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "model_name = 'SVC-BayesTuned'\n",
    "model_desc = 'OneHot+Scaler+BayesSearch+RBF+Balanced'\n",
    "\n",
    "print(\"\\n--- Tuned SVM (RBF) Summary ---\")\n",
    "print(f\"Mean Accuracy : {mean_acc:.4f}\")\n",
    "print(f\"Mean Precision: {mean_prec:.4f}\")\n",
    "print(f\"Mean Recall   : {mean_rec:.4f}\")\n",
    "print(f\"Mean F1 Score : {mean_f1:.4f}\")\n",
    "\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# Step 10: Save to CSV\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "result_df = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "\n",
    "result_df.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51a6935a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.8414, Precision=0.6000, Recall=0.6207, F1=0.6102\n",
      "Fold 2: Accuracy=0.8414, Precision=0.6364, Recall=0.4828, F1=0.5490\n",
      "Fold 3: Accuracy=0.8552, Precision=0.6429, Recall=0.6207, F1=0.6316\n",
      "Fold 4: Accuracy=0.8069, Precision=0.5357, Recall=0.5000, F1=0.5172\n",
      "Fold 5: Accuracy=0.8333, Precision=0.5862, Recall=0.5862, F1=0.5862\n",
      "\n",
      "--- Tuned SVM (RBF) Summary ---\n",
      "Mean Accuracy : 0.8356\n",
      "Mean Precision: 0.6002\n",
      "Mean Recall   : 0.5621\n",
      "Mean F1 Score : 0.5788\n",
      "\n",
      "CSV Row Format:\n",
      "SVC-BayesTuned,OneHot+Scaler+BayesSearch+RBF+Balanced,0.8356,0.6002,0.5621,0.5788\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Step 1: Data setup\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag', 'Predicted Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# Step 2: Column types\n",
    "categorical_cols = ['Gender', 'Religion', 'Branch', 'Section-1', 'Section-2', 'Section-3']\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Step 3: Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', drop='if_binary', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# Step 4: SVC pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('model', SVC(probability=True, random_state=42))\n",
    "])\n",
    "\n",
    "# Step 5: Define search space\n",
    "param_space = {\n",
    "    'model__C': Real(0.1, 100, prior='log-uniform'),\n",
    "    'model__gamma': Real(1e-4, 1.0, prior='log-uniform'),\n",
    "    'model__kernel': ['rbf'],\n",
    "    'model__class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "# Step 6: Bayesian optimization\n",
    "opt = BayesSearchCV(\n",
    "    estimator=pipeline,\n",
    "    search_spaces=param_space,\n",
    "    scoring='accuracy',\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    n_iter=32,\n",
    "    n_jobs=-1,\n",
    "    verbose=0,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Step 7: Fit optimizer\n",
    "opt.fit(X, y)\n",
    "best_pipeline = opt.best_estimator_\n",
    "\n",
    "# Step 8: Manual evaluation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "acc_list, prec_list, rec_list, f1_list = [], [], [], []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    best_pipeline.fit(X_train, y_train)\n",
    "    y_pred = best_pipeline.predict(X_val)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    acc_list.append(acc)\n",
    "    prec_list.append(prec)\n",
    "    rec_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# Step 9: Aggregate metrics\n",
    "mean_acc = np.mean(acc_list)\n",
    "mean_prec = np.mean(prec_list)\n",
    "mean_rec = np.mean(rec_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "model_name = 'SVC-BayesTuned'\n",
    "model_desc = 'OneHot+Scaler+BayesSearch+RBF+Balanced'\n",
    "\n",
    "print(\"\\n--- Tuned SVM (RBF) Summary ---\")\n",
    "print(f\"Mean Accuracy : {mean_acc:.4f}\")\n",
    "print(f\"Mean Precision: {mean_prec:.4f}\")\n",
    "print(f\"Mean Recall   : {mean_rec:.4f}\")\n",
    "print(f\"Mean F1 Score : {mean_f1:.4f}\")\n",
    "\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# Step 10: Save to CSV\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "result_df = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "\n",
    "result_df.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b53f9c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.2000, Precision=0.2000, Recall=1.0000, F1=0.3333\n",
      "Fold 2: Accuracy=0.2000, Precision=0.2000, Recall=1.0000, F1=0.3333\n",
      "Fold 3: Accuracy=0.2000, Precision=0.2000, Recall=1.0000, F1=0.3333\n",
      "Fold 4: Accuracy=0.2069, Precision=0.2069, Recall=1.0000, F1=0.3429\n",
      "Fold 5: Accuracy=0.2014, Precision=0.2014, Recall=1.0000, F1=0.3353\n",
      "\n",
      "--- Tuned SVM (RBF) Summary ---\n",
      "Mean Accuracy : 0.2017\n",
      "Mean Precision: 0.2017\n",
      "Mean Recall   : 1.0000\n",
      "Mean F1 Score : 0.3356\n",
      "\n",
      "CSV Row Format:\n",
      "SVC-BayesTuned-Recall,OneHot+Scaler+BayesSearch+RBF+Balanced+RecallOpt,0.2017,0.2017,1.0000,0.3356\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Step 1: Data setup\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag', 'Predicted Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# Step 2: Column types\n",
    "categorical_cols = ['Gender', 'Religion', 'Branch', 'Section-1', 'Section-2', 'Section-3']\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Step 3: Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', drop='if_binary', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# Step 4: SVC pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('model', SVC(probability=True, random_state=42))\n",
    "])\n",
    "\n",
    "# Step 5: Define search space for BayesSearchCV\n",
    "param_space = {\n",
    "    'model__C': Real(0.1, 100, prior='log-uniform'),\n",
    "    'model__gamma': Real(1e-4, 1.0, prior='log-uniform'),\n",
    "    'model__kernel': ['rbf'],\n",
    "    'model__class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "# Step 6: Bayesian optimization focused on RECALL\n",
    "opt = BayesSearchCV(\n",
    "    estimator=pipeline,\n",
    "    search_spaces=param_space,\n",
    "    scoring='recall',  # prioritize recall\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    n_iter=32,\n",
    "    n_jobs=-1,\n",
    "    verbose=0,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Step 7: Fit optimizer\n",
    "opt.fit(X, y)\n",
    "best_pipeline = opt.best_estimator_\n",
    "\n",
    "# Step 8: Manual evaluation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "acc_list, prec_list, rec_list, f1_list = [], [], [], []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    best_pipeline.fit(X_train, y_train)\n",
    "    y_pred = best_pipeline.predict(X_val)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    acc_list.append(acc)\n",
    "    prec_list.append(prec)\n",
    "    rec_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# Step 9: Aggregate metrics\n",
    "mean_acc = np.mean(acc_list)\n",
    "mean_prec = np.mean(prec_list)\n",
    "mean_rec = np.mean(rec_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "model_name = 'SVC-BayesTuned-Recall'\n",
    "model_desc = 'OneHot+Scaler+BayesSearch+RBF+Balanced+RecallOpt'\n",
    "\n",
    "print(\"\\n--- Tuned SVM (RBF) Summary ---\")\n",
    "print(f\"Mean Accuracy : {mean_acc:.4f}\")\n",
    "print(f\"Mean Precision: {mean_prec:.4f}\")\n",
    "print(f\"Mean Recall   : {mean_rec:.4f}\")\n",
    "print(f\"Mean F1 Score : {mean_f1:.4f}\")\n",
    "\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# Step 10: Save to CSV\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "result_df = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "\n",
    "result_df.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09e7176",
   "metadata": {},
   "source": [
    "# Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ebbca60a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.8828, Precision=0.8750, Recall=0.4828, F1=0.6222\n",
      "Fold 2: Accuracy=0.8552, Precision=0.7857, Recall=0.3793, F1=0.5116\n",
      "Fold 3: Accuracy=0.8759, Precision=0.7391, Recall=0.5862, F1=0.6538\n",
      "Fold 4: Accuracy=0.8759, Precision=0.8000, Recall=0.5333, F1=0.6400\n",
      "Fold 5: Accuracy=0.8472, Precision=0.7333, Recall=0.3793, F1=0.5000\n",
      "\n",
      "--- Model Summary ---\n",
      "Name                          : Bagging-DecisionTree\n",
      "Description                   : Bagging-with-Preprocessing-5Fold\n",
      "Accuracy                      : 0.8674\n",
      "Precision                     : 0.7866\n",
      "Recall                        : 0.4722\n",
      "F1 Score                      : 0.5855\n",
      "\n",
      "CSV Row Format:\n",
      "Bagging-DecisionTree,Bagging-with-Preprocessing-5Fold,0.8674,0.7866,0.4722,0.5855\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Data\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag', 'Predicted Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# Identify columns\n",
    "categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "# Preprocessor\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# Bagging Classifier pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocess', preprocessor),\n",
    "    ('model', BaggingClassifier(\n",
    "        estimator=DecisionTreeClassifier(),\n",
    "        n_estimators=50,\n",
    "        max_samples=0.8,\n",
    "        max_features=1.0,\n",
    "        bootstrap=True,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "# CV setup\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Metric storage\n",
    "accuracy_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "\n",
    "# 5-Fold Evaluation\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_val)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# Final metrics\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# Model info\n",
    "model_name = 'Bagging-DecisionTree'\n",
    "model_desc = 'Bagging-with-Preprocessing-5Fold'\n",
    "\n",
    "print(\"\\n--- Model Summary ---\")\n",
    "print(f\"{'Name':<30}: {model_name}\")\n",
    "print(f\"{'Description':<30}: {model_desc}\")\n",
    "print(f\"{'Accuracy':<30}: {mean_acc:.4f}\")\n",
    "print(f\"{'Precision':<30}: {mean_prec:.4f}\")\n",
    "print(f\"{'Recall':<30}: {mean_rec:.4f}\")\n",
    "print(f\"{'F1 Score':<30}: {mean_f1:.4f}\")\n",
    "\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# Save to CSV\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "new_row = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "new_row.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc1f299b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.8690, Precision=0.7778, Recall=0.4828, F1=0.5957\n",
      "Fold 2: Accuracy=0.8552, Precision=0.7857, Recall=0.3793, F1=0.5116\n",
      "Fold 3: Accuracy=0.8621, Precision=0.6800, Recall=0.5862, F1=0.6296\n",
      "Fold 4: Accuracy=0.8828, Precision=0.7600, Recall=0.6333, F1=0.6909\n",
      "Fold 5: Accuracy=0.8750, Precision=0.8235, Recall=0.4828, F1=0.6087\n",
      "\n",
      "--- Final Tuned Model Summary ---\n",
      "Name                          : Bagging+DT-Tuned\n",
      "Description                   : BayesCV-Tuned-Recall-Max-5Fold\n",
      "Accuracy                      : 0.8688\n",
      "Precision                     : 0.7654\n",
      "Recall                        : 0.5129\n",
      "F1 Score                      : 0.6073\n",
      "\n",
      "CSV Row Format:\n",
      "Bagging+DT-Tuned,BayesCV-Tuned-Recall-Max-5Fold,0.8688,0.7654,0.5129,0.6073\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Data\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag', 'Predicted Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# Columns\n",
    "categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "# Preprocessor\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# Full pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocess', preprocessor),\n",
    "    ('model', BaggingClassifier(\n",
    "        estimator=DecisionTreeClassifier(),\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Parameter search space for Bagging + Decision Tree\n",
    "search_space = {\n",
    "    'model__n_estimators': Integer(10, 100),\n",
    "    'model__max_samples': Real(0.5, 1.0),\n",
    "    'model__max_features': Real(0.5, 1.0),\n",
    "    'model__estimator__max_depth': Integer(2, 20),\n",
    "    'model__estimator__min_samples_split': Integer(2, 10),\n",
    "    'model__estimator__min_samples_leaf': Integer(1, 10)\n",
    "}\n",
    "\n",
    "# BayesSearchCV setup (recall as scoring metric)\n",
    "bayes_search = BayesSearchCV(\n",
    "    estimator=pipeline,\n",
    "    search_spaces=search_space,\n",
    "    scoring=make_scorer(recall_score),\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    n_iter=30,\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Fit\n",
    "bayes_search.fit(X, y)\n",
    "\n",
    "# Best model\n",
    "best_model = bayes_search.best_estimator_\n",
    "\n",
    "# 5-Fold Evaluation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    best_model.fit(X_train, y_train)\n",
    "    y_pred = best_model.predict(X_val)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# Final metrics\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# Metadata\n",
    "model_name = 'Bagging+DT-Tuned'\n",
    "model_desc = 'BayesCV-Tuned-Recall-Max-5Fold'\n",
    "\n",
    "print(\"\\n--- Final Tuned Model Summary ---\")\n",
    "print(f\"{'Name':<30}: {model_name}\")\n",
    "print(f\"{'Description':<30}: {model_desc}\")\n",
    "print(f\"{'Accuracy':<30}: {mean_acc:.4f}\")\n",
    "print(f\"{'Precision':<30}: {mean_prec:.4f}\")\n",
    "print(f\"{'Recall':<30}: {mean_rec:.4f}\")\n",
    "print(f\"{'F1 Score':<30}: {mean_f1:.4f}\")\n",
    "\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# Save to CSV\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "new_row = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "new_row.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83dd842e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.8690, Precision=0.7778, Recall=0.4828, F1=0.5957\n",
      "Fold 2: Accuracy=0.8552, Precision=0.7857, Recall=0.3793, F1=0.5116\n",
      "Fold 3: Accuracy=0.8621, Precision=0.6800, Recall=0.5862, F1=0.6296\n",
      "Fold 4: Accuracy=0.8828, Precision=0.7600, Recall=0.6333, F1=0.6909\n",
      "Fold 5: Accuracy=0.8750, Precision=0.8235, Recall=0.4828, F1=0.6087\n",
      "\n",
      "--- Final Tuned Model Summary ---\n",
      "Name                          : Bagging+DT-Tuned\n",
      "Description                   : BayesCV-Tuned-Recall-Max-5Fold\n",
      "Accuracy                      : 0.8688\n",
      "Precision                     : 0.7654\n",
      "Recall                        : 0.5129\n",
      "F1 Score                      : 0.6073\n",
      "\n",
      "CSV Row Format:\n",
      "Bagging+DT-Tuned,BayesCV-Tuned-Recall-Max-5Fold,0.8688,0.7654,0.5129,0.6073\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Data\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag', 'Predicted Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# Columns\n",
    "categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "# Preprocessor\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# Full pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocess', preprocessor),\n",
    "    ('model', BaggingClassifier(\n",
    "        estimator=DecisionTreeClassifier(),\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Parameter search space for Bagging + Decision Tree\n",
    "search_space = {\n",
    "    'model__n_estimators': Integer(10, 100),\n",
    "    'model__max_samples': Real(0.5, 1.0),\n",
    "    'model__max_features': Real(0.5, 1.0),\n",
    "    'model__estimator__max_depth': Integer(2, 20),\n",
    "    'model__estimator__min_samples_split': Integer(2, 10),\n",
    "    'model__estimator__min_samples_leaf': Integer(1, 10)\n",
    "}\n",
    "\n",
    "# BayesSearchCV setup (recall as scoring metric)\n",
    "bayes_search = BayesSearchCV(\n",
    "    estimator=pipeline,\n",
    "    search_spaces=search_space,\n",
    "    scoring=make_scorer(recall_score),\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    n_iter=30,\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Fit\n",
    "bayes_search.fit(X, y)\n",
    "\n",
    "# Best model\n",
    "best_model = bayes_search.best_estimator_\n",
    "\n",
    "# 5-Fold Evaluation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    best_model.fit(X_train, y_train)\n",
    "    y_pred = best_model.predict(X_val)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# Final metrics\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# Metadata\n",
    "model_name = 'Bagging+DT-Tuned'\n",
    "model_desc = 'BayesCV-Tuned-Recall-Max-5Fold'\n",
    "\n",
    "print(\"\\n--- Final Tuned Model Summary ---\")\n",
    "print(f\"{'Name':<30}: {model_name}\")\n",
    "print(f\"{'Description':<30}: {model_desc}\")\n",
    "print(f\"{'Accuracy':<30}: {mean_acc:.4f}\")\n",
    "print(f\"{'Precision':<30}: {mean_prec:.4f}\")\n",
    "print(f\"{'Recall':<30}: {mean_rec:.4f}\")\n",
    "print(f\"{'F1 Score':<30}: {mean_f1:.4f}\")\n",
    "\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# Save to CSV\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "new_row = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "new_row.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62fa9965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.8345, Precision=0.5610, Recall=0.7931, F1=0.6571\n",
      "Fold 2: Accuracy=0.8000, Precision=0.5000, Recall=0.7241, F1=0.5915\n",
      "Fold 3: Accuracy=0.7379, Precision=0.4211, Recall=0.8276, F1=0.5581\n",
      "Fold 4: Accuracy=0.7586, Precision=0.4576, Recall=0.9000, F1=0.6067\n",
      "Fold 5: Accuracy=0.7431, Precision=0.4231, Recall=0.7586, F1=0.5432\n",
      "\n",
      "--- Final Tuned Bagging Model Summary ---\n",
      "Name                          : Bagging+DT-Balanced-Tuned\n",
      "Description                   : BaggingDT+Balanced+BayesCV-Recall\n",
      "Accuracy                      : 0.7748\n",
      "Precision                     : 0.4725\n",
      "Recall                        : 0.8007\n",
      "F1 Score                      : 0.5914\n",
      "\n",
      "CSV Row Format:\n",
      "Bagging+DT-Balanced-Tuned,BaggingDT+Balanced+BayesCV-Recall,0.7748,0.4725,0.8007,0.5914\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- Data Setup ---\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag', 'Predicted Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "# --- Preprocessing ---\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# --- Pipeline ---\n",
    "pipeline = Pipeline([\n",
    "    ('preprocess', preprocessor),\n",
    "    ('model', BaggingClassifier(\n",
    "        estimator=DecisionTreeClassifier(class_weight='balanced'),\n",
    "        n_estimators=50,\n",
    "        max_samples=0.8,\n",
    "        max_features=1.0,\n",
    "        bootstrap=True,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "# --- Search Space ---\n",
    "search_space = {\n",
    "    'model__n_estimators': Integer(20, 100),\n",
    "    'model__max_samples': Real(0.4, 1.0),\n",
    "    'model__max_features': Real(0.4, 1.0),\n",
    "    'model__estimator__max_depth': Integer(3, 20),\n",
    "    'model__estimator__min_samples_split': Integer(2, 15),\n",
    "    'model__estimator__min_samples_leaf': Integer(1, 10)\n",
    "}\n",
    "\n",
    "# --- Tuning ---\n",
    "bayes_search = BayesSearchCV(\n",
    "    estimator=pipeline,\n",
    "    search_spaces=search_space,\n",
    "    scoring=make_scorer(recall_score),\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    n_iter=30,\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# --- Fit ---\n",
    "bayes_search.fit(X, y)\n",
    "best_model = bayes_search.best_estimator_\n",
    "\n",
    "# --- Cross-Validation Evaluation ---\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    best_model.fit(X_train, y_train)\n",
    "    y_pred = best_model.predict(X_val)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# --- Final Metrics ---\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# --- Output ---\n",
    "model_name = 'Bagging+DT-Balanced-Tuned'\n",
    "model_desc = 'BaggingDT+Balanced+BayesCV-Recall'\n",
    "\n",
    "print(\"\\n--- Final Tuned Bagging Model Summary ---\")\n",
    "print(f\"{'Name':<30}: {model_name}\")\n",
    "print(f\"{'Description':<30}: {model_desc}\")\n",
    "print(f\"{'Accuracy':<30}: {mean_acc:.4f}\")\n",
    "print(f\"{'Precision':<30}: {mean_prec:.4f}\")\n",
    "print(f\"{'Recall':<30}: {mean_rec:.4f}\")\n",
    "print(f\"{'F1 Score':<30}: {mean_f1:.4f}\")\n",
    "\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# --- Save to CSV ---\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "new_row = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "new_row.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65502245",
   "metadata": {},
   "source": [
    "# AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4dab5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.8690, Precision=0.8125, Recall=0.4483, F1=0.5778\n",
      "Fold 2: Accuracy=0.8690, Precision=0.9167, Recall=0.3793, F1=0.5366\n",
      "Fold 3: Accuracy=0.8690, Precision=0.7273, Recall=0.5517, F1=0.6275\n",
      "Fold 4: Accuracy=0.8552, Precision=0.6957, Recall=0.5333, F1=0.6038\n",
      "Fold 5: Accuracy=0.8819, Precision=0.7500, Recall=0.6207, F1=0.6792\n",
      "\n",
      "--- Model Summary ---\n",
      "Name                          : AdaBoostClassifier\n",
      "Description                   : AdaBoost-5Fold-Preprocessed\n",
      "Accuracy                      : 0.8688\n",
      "Precision                     : 0.7804\n",
      "Recall                        : 0.5067\n",
      "F1 Score                      : 0.6050\n",
      "\n",
      "CSV Row Format:\n",
      "AdaBoostClassifier,AdaBoost-5Fold-Preprocessed,0.8688,0.7804,0.5067,0.6050\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Data setup\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag', 'Predicted Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# Identify categorical and numerical columns\n",
    "categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "# Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols),\n",
    "        ('num', StandardScaler(), numerical_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# AdaBoost model pipeline\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocess', preprocessor),\n",
    "    ('classifier', AdaBoostClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# CV setup\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Metric storage\n",
    "accuracy_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "\n",
    "# 5-Fold Evaluation\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# Final metrics\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# Model info\n",
    "model_name = 'AdaBoostClassifier'\n",
    "model_desc = 'AdaBoost-5Fold-Preprocessed'\n",
    "\n",
    "# Print formatted summary\n",
    "print(\"\\n--- Model Summary ---\")\n",
    "print(f\"{'Name':<30}: {model_name}\")\n",
    "print(f\"{'Description':<30}: {model_desc}\")\n",
    "print(f\"{'Accuracy':<30}: {mean_acc:.4f}\")\n",
    "print(f\"{'Precision':<30}: {mean_prec:.4f}\")\n",
    "print(f\"{'Recall':<30}: {mean_rec:.4f}\")\n",
    "print(f\"{'F1 Score':<30}: {mean_f1:.4f}\")\n",
    "\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# Save to CSV (append row, create file if not exists)\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "new_row = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "new_row.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17154eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.8828, Precision=0.8000, Recall=0.5517, F1=0.6531\n",
      "Fold 2: Accuracy=0.8621, Precision=0.8000, Recall=0.4138, F1=0.5455\n",
      "Fold 3: Accuracy=0.8621, Precision=0.7143, Recall=0.5172, F1=0.6000\n",
      "Fold 4: Accuracy=0.8483, Precision=0.6538, Recall=0.5667, F1=0.6071\n",
      "Fold 5: Accuracy=0.8542, Precision=0.6538, Recall=0.5862, F1=0.6182\n",
      "\n",
      "--- Tuned AdaBoost Summary ---\n",
      "Name                          : AdaBoostClassifier-Tuned\n",
      "Description                   : AdaBoost-Tuned-SAMME-OrderedDict({'classifier__learning_rate': 1.0, 'classifier__n_estimators': 180})\n",
      "Accuracy                      : 0.8619\n",
      "Precision                     : 0.7244\n",
      "Recall                        : 0.5271\n",
      "F1 Score                      : 0.6048\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Integer, Real\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Data setup\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag', 'Predicted Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# Categorical and numerical columns\n",
    "categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "# Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# AdaBoost pipeline\n",
    "pipe = Pipeline([\n",
    "    ('preprocess', preprocessor),\n",
    "    ('classifier', AdaBoostClassifier(algorithm='SAMME', random_state=42))\n",
    "])\n",
    "\n",
    "# Hyperparameter search space (no 'SAMME.R')\n",
    "search_space = {\n",
    "    'classifier__n_estimators': Integer(50, 300),\n",
    "    'classifier__learning_rate': Real(0.01, 1.0, prior='log-uniform')\n",
    "}\n",
    "\n",
    "# CV and tuner\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "opt = BayesSearchCV(\n",
    "    pipe,\n",
    "    search_spaces=search_space,\n",
    "    scoring='recall',\n",
    "    n_iter=25,\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=0,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the tuner\n",
    "opt.fit(X, y)\n",
    "\n",
    "# Final best model\n",
    "best_model = opt.best_estimator_\n",
    "\n",
    "# CV metric evaluation using best model\n",
    "accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    best_model.fit(X_train, y_train)\n",
    "    y_pred = best_model.predict(X_val)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# Final averages\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# Model info\n",
    "model_name = 'AdaBoostClassifier-Tuned'\n",
    "model_desc = f\"AdaBoost-Tuned-SAMME-{opt.best_params_}\"\n",
    "\n",
    "# Print summary\n",
    "print(\"\\n--- Tuned AdaBoost Summary ---\")\n",
    "print(f\"{'Name':<30}: {model_name}\")\n",
    "print(f\"{'Description':<30}: {model_desc}\")\n",
    "print(f\"{'Accuracy':<30}: {mean_acc:.4f}\")\n",
    "print(f\"{'Precision':<30}: {mean_prec:.4f}\")\n",
    "print(f\"{'Recall':<30}: {mean_rec:.4f}\")\n",
    "print(f\"{'F1 Score':<30}: {mean_f1:.4f}\")\n",
    "\n",
    "# CSV write\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "new_row = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "new_row.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae354fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
