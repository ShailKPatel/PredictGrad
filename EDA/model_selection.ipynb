{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38157fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Gender Religion Branch Section-1 Section-2 Section-3  Roll-1  Math-1 Theory  \\\n",
      "0      M    Hindu     CE         D         D         A     350             47   \n",
      "1      F    Hindu    CST         B         B         D      18             84   \n",
      "2      F    Hindu   AIML         A         A         C      23             74   \n",
      "3      M    Hindu    CST         B         B         D     212             55   \n",
      "4      M    Hindu    CST         B         B         D     208             38   \n",
      "\n",
      "   Physics Theory  Physics Practical  ...  Predicted FSD Theory  \\\n",
      "0              48                 75  ...             72.266535   \n",
      "1              83                 81  ...             87.523458   \n",
      "2              85                 86  ...             89.409752   \n",
      "3              69                 82  ...             79.807055   \n",
      "4              59                 74  ...             56.474296   \n",
      "\n",
      "   Predicted Math-3 Theory  Predicted Python Theory  \\\n",
      "0                56.352210                71.642156   \n",
      "1                82.966865                81.393865   \n",
      "2                76.982002                86.897293   \n",
      "3                67.253716                74.606764   \n",
      "4                51.995650                53.483393   \n",
      "\n",
      "   Predicted Sem 3 Percentage  Sem 1 Percentile  Sem 2 Percentile  \\\n",
      "0                       64.14             26.38             30.66   \n",
      "1                       83.40             95.99             84.39   \n",
      "2                       83.49             92.47             91.16   \n",
      "3                       72.31             66.30             51.59   \n",
      "4                       53.42             15.68             11.53   \n",
      "\n",
      "   Predicted Sem 3 Percentile  Predicted Percentile Drop  Predicted Risk Flag  \\\n",
      "0                       38.26                      -7.60                False   \n",
      "1                       88.54                      -4.15                False   \n",
      "2                       88.81                       2.35                False   \n",
      "3                       61.26                      -9.67                False   \n",
      "4                       15.47                      -3.94                False   \n",
      "\n",
      "   Risk Flag  \n",
      "0      False  \n",
      "1      False  \n",
      "2      False  \n",
      "3      False  \n",
      "4      False  \n",
      "\n",
      "[5 rows x 51 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Ensure the path to the DEModelHandler is correct\n",
    "sys.path.append(os.path.abspath(\"../SubjectModels/de_model\"))\n",
    "from de_handler import DEModelHandler  \n",
    "\n",
    "# Ensure the path to the FSDModelHandler is correct\n",
    "sys.path.append(os.path.abspath(\"../SubjectModels/fsd_model\"))\n",
    "from fsd_handler import FSDModelHandler  \n",
    "\n",
    "# Ensure the path to the Math3ModelHandler is correct\n",
    "sys.path.append(os.path.abspath(\"../SubjectModels/math3_model\"))\n",
    "from math3_handler import Math3ModelHandler  \n",
    "\n",
    "# Ensure the path to the PythonModelHandler is correct\n",
    "sys.path.append(os.path.abspath(\"../SubjectModels/python_model\"))\n",
    "from python_handler import PythonModelHandler  \n",
    "\n",
    "df = pd.read_csv(\"../dataset/train_dataset.csv\")\n",
    "\n",
    "# Drop the irrelevant, data leak columns\n",
    "df_clean = df.drop(\n",
    "    columns=[\n",
    "        \"Student ID\",\n",
    "        \"Mentor-1\",\n",
    "        \"Mentor-2\",\n",
    "        \"Mentor-3\",\n",
    "        \"Roll-2\",\n",
    "        \"Roll-3\",\n",
    "        \"Math-3 Theory\",\n",
    "        \"DE Practical\",\n",
    "        \"FSD Theory\",\n",
    "        \"FSD Practical\",\n",
    "        \"Python Theory\",\n",
    "        \"Python Practical\",\n",
    "        \"Communication Theory\",\n",
    "        \"Law Theory\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "# columns for Semester 1 core subjects\n",
    "sem1_columns = [\n",
    "    \"Math-1 Theory\",\n",
    "    \"Physics Theory\",\n",
    "    \"Java-1 Theory\",\n",
    "    \"Software Engineering Theory\",\n",
    "]\n",
    "\n",
    "# Calculate Semester 1 Percentage as the average of core subject scores\n",
    "# scores are numerical and out of 100\n",
    "df_clean[\"Sem 1 Percentage\"] = df_clean[sem1_columns].mean(axis=1).round(2)\n",
    "\n",
    "# columns for Semester 2 core subjects\n",
    "sem2_columns = [\n",
    "    \"Math-2 Theory\",\n",
    "    \"Data Structures using Java Theory\",\n",
    "    \"DBMS Theory\",\n",
    "    \"Fundamental of Electronics and Electrical Theory\",\n",
    "    \"Java-2 Theory\",\n",
    "]\n",
    "\n",
    "# Calculate Semester 2 Percentage as the average of core subject scores\n",
    "# scores are numerical and out of 100\n",
    "df_clean[\"Sem 2 Percentage\"] = df_clean[sem2_columns].mean(axis=1).round(2)\n",
    "\n",
    "# Rename columns Div-1, Div-2, Div-3 to Section-1, Section-2, Section-3\n",
    "df_clean = df_clean.rename(\n",
    "    columns={\"Div-1\": \"Section-1\", \"Div-2\": \"Section-2\", \"Div-3\": \"Section-3\"}\n",
    ")\n",
    "\n",
    "# Transform values in Section-1, Section-2, Section-3 to keep only the first character\n",
    "# Thus we get Only Department\n",
    "for section in [\"Section-1\", \"Section-2\", \"Section-3\"]:\n",
    "    df_clean[section] = df_clean[section].str[0]\n",
    "\n",
    "# adding DE predicted column\n",
    "preprocessor = DEModelHandler()\n",
    "fe_de = preprocessor.predict_from_model(\n",
    "    df,\n",
    "    model_path=\"../SubjectModels/de_model/de_model.joblib\",\n",
    "    return_type=\"df\"\n",
    ")\n",
    "\n",
    "# Add the predicted DE Theory marks to df_clean\n",
    "df_clean[\"Predicted DE Theory\"] = fe_de[\"Predicted DE Theory\"]\n",
    "\n",
    "\n",
    "# adding FSD predicted column\n",
    "preprocessor = FSDModelHandler()\n",
    "fe_fsd = preprocessor.predict_from_model(\n",
    "    df,\n",
    "    model_path=\"../SubjectModels/fsd_model/fsd_model.joblib\",\n",
    "    return_type=\"df\"\n",
    ")\n",
    "\n",
    "# Add the predicted FSD Theory marks to df_clean\n",
    "df_clean[\"Predicted FSD Theory\"] = fe_fsd[\"Predicted FSD Theory\"]\n",
    "\n",
    "\n",
    "# adding Math3 predicted column\n",
    "preprocessor = Math3ModelHandler()\n",
    "fe_math3 = preprocessor.predict_from_model(\n",
    "    df,\n",
    "    model_path=\"../SubjectModels/math3_model/math3_model.joblib\",\n",
    "    return_type=\"df\"\n",
    ")\n",
    "\n",
    "# Add the predicted Math3 Theory marks to df_clean\n",
    "df_clean[\"Predicted Math-3 Theory\"] = fe_math3[\"Predicted Math-3 Theory\"]\n",
    "\n",
    "\n",
    "# adding Python predicted column\n",
    "preprocessor = PythonModelHandler()\n",
    "fe_python = preprocessor.predict_from_model(\n",
    "    df,\n",
    "    model_path=\"../SubjectModels/python_model/python_model.joblib\",\n",
    "    return_type=\"df\"\n",
    ")\n",
    "\n",
    "# Add the predicted Python Theory marks to df_clean\n",
    "df_clean[\"Predicted Python Theory\"] = fe_python[\"Predicted Python Theory\"]\n",
    "\n",
    "#  Calculate predicted Semester 3 percentage (mean of 4 predicted subject marks)\n",
    "sem3_subjects = [\n",
    "    \"Predicted Math-3 Theory\",\n",
    "    \"Predicted DE Theory\",\n",
    "    \"Predicted FSD Theory\",\n",
    "    \"Predicted Python Theory\",\n",
    "]\n",
    "\n",
    "df_clean[\"Predicted Sem 3 Percentage\"] = df_clean[sem3_subjects].mean(axis=1).round(2)\n",
    "\n",
    "df_clean[\"Sem 1 Percentile\"] = df_clean[\"Sem 1 Percentage\"].rank(pct=True) * 100\n",
    "df_clean[\"Sem 2 Percentile\"] = df_clean[\"Sem 2 Percentage\"].rank(pct=True) * 100\n",
    "df_clean[\"Predicted Sem 3 Percentile\"] = df_clean[\"Predicted Sem 3 Percentage\"].rank(pct=True) * 100\n",
    "\n",
    "# Round for consistency\n",
    "df_clean[[\"Sem 1 Percentile\", \"Sem 2 Percentile\", \"Predicted Sem 3 Percentile\"]] = df_clean[\n",
    "    [\"Sem 1 Percentile\", \"Sem 2 Percentile\", \"Predicted Sem 3 Percentile\"]\n",
    "].round(2)\n",
    "\n",
    "df_clean[\"Predicted Percentile Drop\"] = (\n",
    "    df_clean[\"Sem 2 Percentile\"] - df_clean[\"Predicted Sem 3 Percentile\"]\n",
    ").round(2)\n",
    "\n",
    "df_clean[\"Predicted Risk Flag\"] = df_clean[\"Predicted Percentile Drop\"] > 10\n",
    "\n",
    "# Columns for Semester 3 core theory subjects\n",
    "sem3_columns = [\n",
    "    \"Math-3 Theory\",\n",
    "    \"DE Theory\",\n",
    "    \"FSD Theory\",\n",
    "    \"Python Theory\",\n",
    "]\n",
    "\n",
    "# Calculate Semester 3 Total as the sum of core subject scores\n",
    "df[\"Sem 3 Percentage\"] = (df[sem3_columns].sum(axis=1) / 4).round(2)\n",
    "\n",
    "df_clean[\"Sem 3 Percentile\"] = df[\"Sem 3 Percentage\"].rank(pct=True) * 100\n",
    "\n",
    "df_clean[\"Percentile Drop\"] = (\n",
    "    df_clean[\"Sem 2 Percentile\"] - df_clean[\"Sem 3 Percentile\"]\n",
    ").round(2)\n",
    "\n",
    "df_clean[\"Risk Flag\"] = df_clean[\"Percentile Drop\"] > 10\n",
    "\n",
    "columns_to_drop = [\n",
    "    \"Sem 3 Percentile\",\n",
    "    \"Percentile Drop\"\n",
    "]\n",
    "\n",
    "df_clean.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "# After all operations on df_clean are complete, drop other DataFrames\n",
    "df = None\n",
    "fe_de = None\n",
    "fe_fsd = None\n",
    "fe_math3 = None\n",
    "fe_python = None\n",
    "\n",
    "print(df_clean.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268fddad",
   "metadata": {},
   "source": [
    "# Dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ef56866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.8000, Precision=0.0000, Recall=0.0000, F1=0.0000\n",
      "Fold 2: Accuracy=0.8000, Precision=0.0000, Recall=0.0000, F1=0.0000\n",
      "Fold 3: Accuracy=0.8000, Precision=0.0000, Recall=0.0000, F1=0.0000\n",
      "Fold 4: Accuracy=0.7931, Precision=0.0000, Recall=0.0000, F1=0.0000\n",
      "Fold 5: Accuracy=0.7986, Precision=0.0000, Recall=0.0000, F1=0.0000\n",
      "\n",
      "--- Baseline Model Summary ---\n",
      "Name                          : DummyClassifier-MostFreq\n",
      "Description                   : Baseline-MostFrequent-5Fold\n",
      "Accuracy                      : 0.7983\n",
      "Precision                     : 0.0000\n",
      "Recall                        : 0.0000\n",
      "F1 Score                      : 0.0000\n",
      "\n",
      "CSV Row Format:\n",
      "DummyClassifier-MostFreq,Baseline-MostFrequent-5Fold,0.7983,0.0000,0.0000,0.0000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Target and features\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag', 'Predicted Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# DummyClassifier â€“ always predicts the most frequent class\n",
    "dummy = DummyClassifier(strategy='most_frequent')\n",
    "\n",
    "# CV setup\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Metric storage\n",
    "accuracy_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "\n",
    "# 5-Fold Evaluation\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    dummy.fit(X_train, y_train)\n",
    "    y_pred = dummy.predict(X_val)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# Final metrics\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# Model info\n",
    "model_name = 'DummyClassifier-MostFreq'\n",
    "model_desc = 'Baseline-MostFrequent-5Fold'\n",
    "\n",
    "# Print formatted summary\n",
    "print(\"\\n--- Baseline Model Summary ---\")\n",
    "print(f\"{'Name':<30}: {model_name}\")\n",
    "print(f\"{'Description':<30}: {model_desc}\")\n",
    "print(f\"{'Accuracy':<30}: {mean_acc:.4f}\")\n",
    "print(f\"{'Precision':<30}: {mean_prec:.4f}\")\n",
    "print(f\"{'Recall':<30}: {mean_rec:.4f}\")\n",
    "print(f\"{'F1 Score':<30}: {mean_f1:.4f}\")\n",
    "\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# Save to CSV (append row, create file if not exists)\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "new_row = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "\n",
    "# Append to file (header only if file doesn't exist)\n",
    "new_row.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5ddd4c",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d9afa15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.8207, Precision=0.5385, Recall=0.7241, F1=0.6176\n",
      "Fold 2: Accuracy=0.8552, Precision=0.6176, Recall=0.7241, F1=0.6667\n",
      "Fold 3: Accuracy=0.7931, Precision=0.4889, Recall=0.7586, F1=0.5946\n",
      "Fold 4: Accuracy=0.8069, Precision=0.5217, Recall=0.8000, F1=0.6316\n",
      "Fold 5: Accuracy=0.8125, Precision=0.5250, Recall=0.7241, F1=0.6087\n",
      "\n",
      "--- Average Metrics Summary ---\n",
      "Name                          : LogisticRegression-Balanced\n",
      "Description                   : OneHot+Scaler+5Fold-Stratified\n",
      "Accuracy                      : 0.8177\n",
      "Precision                     : 0.5383\n",
      "Recall                        : 0.7462\n",
      "F1 Score                      : 0.6238\n",
      "\n",
      "CSV Row Format:\n",
      "LogisticRegression-Balanced,OneHot+Scaler+5Fold-Stratified,0.8177,0.5383,0.7462,0.6238\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import warnings\n",
    "import csv\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Step 1: Copy and split data\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag', 'Predicted Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)  # convert bool to 0/1\n",
    "\n",
    "# Step 2: Column categorization\n",
    "categorical_cols = ['Gender', 'Religion', 'Branch', 'Section-1', 'Section-2', 'Section-3']\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Step 3: Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# Step 4: Full pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('model', LogisticRegression(class_weight='balanced', max_iter=1000))\n",
    "])\n",
    "\n",
    "# Step 5: 5-Fold Stratified CV\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Metrics storage\n",
    "accuracy_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "\n",
    "# Step 6: Loop through CV\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_val)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# Step 7: Average metrics\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# Model info\n",
    "model_name = 'LogisticRegression-Balanced'\n",
    "model_desc = 'OneHot+Scaler+5Fold-Stratified'\n",
    "\n",
    "# Print: CSV-style with labels and formatting\n",
    "print(\"\\n--- Average Metrics Summary ---\")\n",
    "print(f\"{'Name':<30}: {model_name}\")\n",
    "print(f\"{'Description':<30}: {model_desc}\")\n",
    "print(f\"{'Accuracy':<30}: {mean_acc:.4f}\")\n",
    "print(f\"{'Precision':<30}: {mean_prec:.4f}\")\n",
    "print(f\"{'Recall':<30}: {mean_rec:.4f}\")\n",
    "print(f\"{'F1 Score':<30}: {mean_f1:.4f}\")\n",
    "\n",
    "# Also print as CSV row\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# Step 8: Write to file if not already present\n",
    "output_path = 'risk_model_metrics.csv'\n",
    "write_header = not os.path.exists(output_path)\n",
    "\n",
    "with open(output_path, mode='a', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    if write_header:\n",
    "        writer.writerow(['Name', 'Desc', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
    "    writer.writerow([model_name, model_desc, f\"{mean_acc:.4f}\", f\"{mean_prec:.4f}\", f\"{mean_rec:.4f}\", f\"{mean_f1:.4f}\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefdbb3e",
   "metadata": {},
   "source": [
    "# DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b37e44c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.8000, Precision=0.5000,  Recall=0.4138, F1=0.4528\n",
      "Fold 2: Accuracy=0.8414, Precision=0.7143,  Recall=0.3448, F1=0.4651\n",
      "Fold 3: Accuracy=0.7517, Precision=0.4103,  Recall=0.5517, F1=0.4706\n",
      "Fold 4: Accuracy=0.7862, Precision=0.4848,  Recall=0.5333, F1=0.5079\n",
      "Fold 5: Accuracy=0.8403, Precision=0.6250,  Recall=0.5172, F1=0.5660\n",
      "\n",
      "--- DecisionTreeClassifier Summary ---\n",
      "Mean Accuracy : 0.8039\n",
      "Mean Precision: 0.5469\n",
      "Mean Recall   : 0.4722\n",
      "Mean F1 Score : 0.4925\n",
      "\n",
      "CSV Row Format:\n",
      "DecisionTreeClassifier-Balanced,OneHot+Scaler+5Fold-Stratified,0.8039,0.5469,0.4722,0.4925\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Step 1: Prepare data\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag', 'Predicted Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# Step 2: Column categories\n",
    "categorical_cols = ['Gender', 'Religion', 'Branch', 'Section-1', 'Section-2', 'Section-3']\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Step 3: Preprocessing\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# Step 4: Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('model', DecisionTreeClassifier(class_weight='balanced', random_state=42))\n",
    "])\n",
    "\n",
    "# Step 5: Cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_val)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f},  Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# Step 6: Averages\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# Step 7: Model description\n",
    "model_name = 'DecisionTreeClassifier-Balanced'\n",
    "model_desc = 'OneHot+Scaler+5Fold-Stratified'\n",
    "\n",
    "# Console summary\n",
    "print(\"\\n--- DecisionTreeClassifier Summary ---\")\n",
    "print(f\"Mean Accuracy : {mean_acc:.4f}\")\n",
    "print(f\"Mean Precision: {mean_prec:.4f}\")\n",
    "print(f\"Mean Recall   : {mean_rec:.4f}\")\n",
    "print(f\"Mean F1 Score : {mean_f1:.4f}\")\n",
    "\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# Step 8: Save to CSV\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "result_df = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "\n",
    "# Append to CSV, add header only if file doesn't exist\n",
    "result_df.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb71471c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.6828, Precision=0.3455,  Recall=0.6552, F1=0.4524\n",
      "Fold 2: Accuracy=0.8138, Precision=0.5357,  Recall=0.5172, F1=0.5263\n",
      "Fold 3: Accuracy=0.7034, Precision=0.3750,  Recall=0.7241, F1=0.4941\n",
      "Fold 4: Accuracy=0.7517, Precision=0.4348,  Recall=0.6667, F1=0.5263\n",
      "Fold 5: Accuracy=0.7222, Precision=0.3878,  Recall=0.6552, F1=0.4872\n",
      "\n",
      "--- DecisionTree_Recall_Tuned Summary ---\n",
      "Mean Accuracy : 0.7348\n",
      "Mean Precision: 0.4157\n",
      "Mean Recall   : 0.6437\n",
      "Mean F1 Score : 0.4973\n",
      "\n",
      "CSV Row Format:\n",
      "DecisionTree-RecallTuned,Thresh=0.35|Depth=6|Split=10|Leaf=5|5Fold,0.7348,0.4157,0.6437,0.4973\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Step 1: Data setup\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag', 'Predicted Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# Step 2: Column types\n",
    "categorical_cols = ['Gender', 'Religion', 'Branch', 'Section-1', 'Section-2', 'Section-3']\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Step 3: Preprocessing\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# Step 4: Recall-tuned DecisionTree\n",
    "pipeline = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('model', DecisionTreeClassifier(\n",
    "        class_weight='balanced',\n",
    "        max_depth=6,\n",
    "        min_samples_split=10,\n",
    "        min_samples_leaf=5,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Step 5: CV setup\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n",
    "\n",
    "# Step 6: Custom threshold\n",
    "threshold = 0.35\n",
    "\n",
    "# Step 7: Cross-validation\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    y_proba = pipeline.predict_proba(X_val)[:, 1]\n",
    "    y_pred = (y_proba >= threshold).astype(int)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f},  Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# Step 8: Mean metrics\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# Step 9: Model info\n",
    "model_name = 'DecisionTree-RecallTuned'\n",
    "model_desc = f'Thresh=0.35|Depth=6|Split=10|Leaf=5|5Fold'\n",
    "\n",
    "# Console output\n",
    "print(\"\\n--- DecisionTree_Recall_Tuned Summary ---\")\n",
    "print(f\"Mean Accuracy : {mean_acc:.4f}\")\n",
    "print(f\"Mean Precision: {mean_prec:.4f}\")\n",
    "print(f\"Mean Recall   : {mean_rec:.4f}\")\n",
    "print(f\"Mean F1 Score : {mean_f1:.4f}\")\n",
    "\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# Step 10: Save to CSV\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "result_df = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "\n",
    "result_df.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee992bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.8000, Precision=0.5000,  Recall=0.4138, F1=0.4528\n",
      "Fold 2: Accuracy=0.8414, Precision=0.7143,  Recall=0.3448, F1=0.4651\n",
      "Fold 3: Accuracy=0.7517, Precision=0.4103,  Recall=0.5517, F1=0.4706\n",
      "Fold 4: Accuracy=0.7862, Precision=0.4848,  Recall=0.5333, F1=0.5079\n",
      "Fold 5: Accuracy=0.8403, Precision=0.6250,  Recall=0.5172, F1=0.5660\n",
      "\n",
      "--- DecisionTree_MaxRecall Summary ---\n",
      "Mean Accuracy : 0.8039\n",
      "Mean Precision: 0.5469\n",
      "Mean Recall   : 0.4722\n",
      "Mean F1 Score : 0.4925\n",
      "\n",
      "CSV Row Format:\n",
      "DecisionTree-MaxRecall,Depth=None|Split=2|Leaf=1|Thresh=0.25|5Fold,0.8039,0.5469,0.4722,0.4925\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Step 1: Data setup\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag', 'Predicted Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "categorical_cols = ['Gender', 'Religion', 'Branch', 'Section-1', 'Section-2', 'Section-3']\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Step 2: Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# Step 3: Flexible (deep) DecisionTreeClassifier\n",
    "pipeline = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('model', DecisionTreeClassifier(\n",
    "        class_weight='balanced',\n",
    "        max_depth=None,             # no limit\n",
    "        min_samples_split=2,        # fine splits\n",
    "        min_samples_leaf=1,         # small leaves allowed\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Step 4: Cross-validation config\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n",
    "\n",
    "# Step 5: Threshold\n",
    "threshold = 0.25  # aggressive threshold to maximize recall\n",
    "\n",
    "# Step 6: CV loop\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_proba = pipeline.predict_proba(X_val)[:, 1]\n",
    "    y_pred = (y_proba >= threshold).astype(int)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f},  Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# Step 7: Aggregate results\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# Step 8: Metadata\n",
    "model_name = 'DecisionTree-MaxRecall'\n",
    "model_desc = 'Depth=None|Split=2|Leaf=1|Thresh=0.25|5Fold'\n",
    "\n",
    "print(\"\\n--- DecisionTree_MaxRecall Summary ---\")\n",
    "print(f\"Mean Accuracy : {mean_acc:.4f}\")\n",
    "print(f\"Mean Precision: {mean_prec:.4f}\")\n",
    "print(f\"Mean Recall   : {mean_rec:.4f}\")\n",
    "print(f\"Mean F1 Score : {mean_f1:.4f}\")\n",
    "\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# Step 9: Save to CSV\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "result_df = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "result_df.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a643a2d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.7586, Precision=0.4400, Recall=0.7586, F1=0.5570\n",
      "Fold 2: Accuracy=0.7517, Precision=0.4255, Recall=0.6897, F1=0.5263\n",
      "Fold 3: Accuracy=0.7241, Precision=0.3922, Recall=0.6897, F1=0.5000\n",
      "Fold 4: Accuracy=0.8069, Precision=0.5200, Recall=0.8667, F1=0.6500\n",
      "Fold 5: Accuracy=0.7500, Precision=0.4340, Recall=0.7931, F1=0.5610\n",
      "\n",
      "--- DecisionTree_SMOTE Summary ---\n",
      "Mean Accuracy : 0.7583\n",
      "Mean Precision: 0.4423\n",
      "Mean Recall   : 0.7595\n",
      "Mean F1 Score : 0.5589\n",
      "\n",
      "CSV Row Format:\n",
      "DecisionTree-SMOTE,Thresh=0.35|Depth=6|Split=10|Leaf=5|5Fold|SMOTE,0.7583,0.4423,0.7595,0.5589\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Step 1: Data setup\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag', 'Predicted Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# Step 2: Column types\n",
    "categorical_cols = ['Gender', 'Religion', 'Branch', 'Section-1', 'Section-2', 'Section-3']\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Step 3: Preprocessing\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# Step 4: SMOTE setup\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "# Step 5: Recall-tuned DecisionTree\n",
    "pipeline = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('model', DecisionTreeClassifier(\n",
    "        max_depth=6,\n",
    "        min_samples_split=10,\n",
    "        min_samples_leaf=5,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Step 6: CV setup\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n",
    "\n",
    "# Step 7: Custom threshold\n",
    "threshold = 0.35\n",
    "\n",
    "# Step 8: Cross-validation with SMOTE\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    # Apply SMOTE to training data\n",
    "    X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "    X_train_smote, y_train_smote = smote.fit_resample(X_train_preprocessed, y_train)\n",
    "\n",
    "    # Fit the model on SMOTE-resampled data\n",
    "    pipeline.named_steps['model'].fit(X_train_smote, y_train_smote)\n",
    "\n",
    "    # Transform validation data\n",
    "    X_val_preprocessed = preprocessor.transform(X_val)\n",
    "    y_proba = pipeline.named_steps['model'].predict_proba(X_val_preprocessed)[:, 1]\n",
    "    y_pred = (y_proba >= threshold).astype(int)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# Step 9: Mean metrics\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# Step 10: Model info\n",
    "model_name = 'DecisionTree-SMOTE'\n",
    "model_desc = f'Thresh=0.35|Depth=6|Split=10|Leaf=5|5Fold|SMOTE'\n",
    "\n",
    "# Console output\n",
    "print(\"\\n--- DecisionTree_SMOTE Summary ---\")\n",
    "print(f\"Mean Accuracy : {mean_acc:.4f}\")\n",
    "print(f\"Mean Precision: {mean_prec:.4f}\")\n",
    "print(f\"Mean Recall   : {mean_rec:.4f}\")\n",
    "print(f\"Mean F1 Score : {mean_f1:.4f}\")\n",
    "\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# Step 11: Save to CSV\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "result_df = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "\n",
    "result_df.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a761db51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.7931, Precision=0.4878, Recall=0.6897, F1=0.5714\n",
      "Fold 2: Accuracy=0.7586, Precision=0.4167, Recall=0.5172, F1=0.4615\n",
      "Fold 3: Accuracy=0.7103, Precision=0.3818, Recall=0.7241, F1=0.5000\n",
      "Fold 4: Accuracy=0.7241, Precision=0.4107, Recall=0.7667, F1=0.5349\n",
      "Fold 5: Accuracy=0.8125, Precision=0.5238, Recall=0.7586, F1=0.6197\n",
      "\n",
      "--- DecisionTree_SMOTE_RecallOptimized Summary ---\n",
      "Mean Accuracy : 0.7597\n",
      "Mean Precision: 0.4442\n",
      "Mean Recall   : 0.6913\n",
      "Mean F1 Score : 0.5375\n",
      "\n",
      "CSV Row Format:\n",
      "DecisionTree-SMOTE-RecallOptimized,Thresh=0.25|Depth=6|Split=10|Leaf=3|5Fold|SMOTE_0.8,0.7597,0.4442,0.6913,0.5375\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Step 1: Data setup\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag', 'Predicted Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# Step 2: Column types\n",
    "categorical_cols = ['Gender', 'Religion', 'Branch', 'Section-1', 'Section-2', 'Section-3']\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Step 3: Preprocessing\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# Step 4: SMOTE setup with adjusted sampling strategy\n",
    "smote = SMOTE(sampling_strategy=0.8, random_state=42)\n",
    "\n",
    "# Step 5: Recall-optimized DecisionTree\n",
    "pipeline = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('model', DecisionTreeClassifier(\n",
    "        max_depth=6,\n",
    "        min_samples_split=10,\n",
    "        min_samples_leaf=3,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Step 6: CV setup\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n",
    "\n",
    "# Step 7: Lowered threshold for higher recall\n",
    "threshold = 0.25\n",
    "\n",
    "# Step 8: Cross-validation with SMOTE\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    # Apply SMOTE to training data\n",
    "    X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "    X_train_smote, y_train_smote = smote.fit_resample(X_train_preprocessed, y_train)\n",
    "\n",
    "    # Fit the model on SMOTE-resampled data\n",
    "    pipeline.named_steps['model'].fit(X_train_smote, y_train_smote)\n",
    "\n",
    "    # Transform validation data\n",
    "    X_val_preprocessed = preprocessor.transform(X_val)\n",
    "    y_proba = pipeline.named_steps['model'].predict_proba(X_val_preprocessed)[:, 1]\n",
    "    y_pred = (y_proba >= threshold).astype(int)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# Step 9: Mean metrics\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# Step 10: Model info\n",
    "model_name = 'DecisionTree-SMOTE-RecallOptimized'\n",
    "model_desc = f'Thresh=0.25|Depth=6|Split=10|Leaf=3|5Fold|SMOTE_0.8'\n",
    "\n",
    "# Console output\n",
    "print(\"\\n--- DecisionTree_SMOTE_RecallOptimized Summary ---\")\n",
    "print(f\"Mean Accuracy : {mean_acc:.4f}\")\n",
    "print(f\"Mean Precision: {mean_prec:.4f}\")\n",
    "print(f\"Mean Recall   : {mean_rec:.4f}\")\n",
    "print(f\"Mean F1 Score : {mean_f1:.4f}\")\n",
    "\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# Step 11: Save to CSV\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "result_df = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "\n",
    "result_df.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58706e3",
   "metadata": {},
   "source": [
    "# RandomForestClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9de4e23a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.8138, Precision=0.7500,  Recall=0.1034, F1=0.1818\n",
      "Fold 2: Accuracy=0.8276, Precision=0.8333,  Recall=0.1724, F1=0.2857\n",
      "Fold 3: Accuracy=0.8345, Precision=0.8571,  Recall=0.2069, F1=0.3333\n",
      "Fold 4: Accuracy=0.8345, Precision=0.8000,  Recall=0.2667, F1=0.4000\n",
      "Fold 5: Accuracy=0.8403, Precision=0.8750,  Recall=0.2414, F1=0.3784\n",
      "\n",
      "--- RandomForestClassifier Summary ---\n",
      "Mean Accuracy : 0.8301\n",
      "Mean Precision: 0.8231\n",
      "Mean Recall   : 0.1982\n",
      "Mean F1 Score : 0.3158\n",
      "\n",
      "CSV Row Format:\n",
      "RandomForestClassifier-Balanced,OneHot+Scaler+5Fold-Stratified,0.8301,0.8231,0.1982,0.3158\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Step 1: Prepare data\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag', 'Predicted Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# Step 2: Column categories\n",
    "categorical_cols = ['Gender', 'Religion', 'Branch', 'Section-1', 'Section-2', 'Section-3']\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Step 3: Preprocessing\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# Step 4: Pipeline with Random Forest\n",
    "pipeline = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('model', RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=None,\n",
    "        class_weight='balanced',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Step 5: Cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_val)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f},  Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# Step 6: Averages\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# Step 7: Model description\n",
    "model_name = 'RandomForestClassifier-Balanced'\n",
    "model_desc = 'OneHot+Scaler+5Fold-Stratified'\n",
    "\n",
    "# Console summary\n",
    "print(\"\\n--- RandomForestClassifier Summary ---\")\n",
    "print(f\"Mean Accuracy : {mean_acc:.4f}\")\n",
    "print(f\"Mean Precision: {mean_prec:.4f}\")\n",
    "print(f\"Mean Recall   : {mean_rec:.4f}\")\n",
    "print(f\"Mean F1 Score : {mean_f1:.4f}\")\n",
    "\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# Step 8: Save to CSV\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "result_df = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "\n",
    "# Append to CSV, add header only if file doesn't exist\n",
    "result_df.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8d374e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.7586, Precision=0.4348, Recall=0.6897, F1=0.5333\n",
      "Fold 2: Accuracy=0.7724, Precision=0.4545, Recall=0.6897, F1=0.5479\n",
      "Fold 3: Accuracy=0.6690, Precision=0.3582, Recall=0.8276, F1=0.5000\n",
      "Fold 4: Accuracy=0.6552, Precision=0.3649, Recall=0.9000, F1=0.5192\n",
      "Fold 5: Accuracy=0.6875, Precision=0.3621, Recall=0.7241, F1=0.4828\n",
      "\n",
      "--- Average Metrics Summary ---\n",
      "Name                          : RandomForest-SMOTE-Threshold0.3\n",
      "Description                   : OneHot+Scaler+SMOTE+RF+Threshold=0.3\n",
      "Accuracy                      : 0.7085\n",
      "Precision                     : 0.3949\n",
      "Recall                        : 0.7662\n",
      "F1 Score                      : 0.5167\n",
      "\n",
      "CSV Row Format:\n",
      "RandomForest-SMOTE-Threshold0.3,OneHot+Scaler+SMOTE+RF+Threshold=0.3,0.7085,0.3949,0.7662,0.5167\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "import warnings\n",
    "import csv\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Step 1: Copy and split data\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag', 'Predicted Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)  # convert bool to 0/1\n",
    "\n",
    "# Step 2: Column categorization\n",
    "categorical_cols = ['Gender', 'Religion', 'Branch', 'Section-1', 'Section-2', 'Section-3']\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Step 3: Preprocessing\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# Step 4: Full pipeline with SMOTE + RandomForest\n",
    "pipeline = ImbPipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('model', RandomForestClassifier(\n",
    "        n_estimators=200,\n",
    "        max_depth=None,\n",
    "        class_weight='balanced',\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Step 5: 5-Fold Stratified CV\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Metrics storage\n",
    "accuracy_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "\n",
    "threshold = 0.3  # Custom threshold to maximize recall\n",
    "\n",
    "# Step 6: Loop through CV\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_proba = pipeline.predict_proba(X_val)[:, 1]  # Get probability for class 1\n",
    "\n",
    "    y_pred = (y_proba >= threshold).astype(int)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# Step 7: Average metrics\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# Model info\n",
    "model_name = 'RandomForest-SMOTE-Threshold0.3'\n",
    "model_desc = 'OneHot+Scaler+SMOTE+RF+Threshold=0.3'\n",
    "\n",
    "# Print: CSV-style with labels and formatting\n",
    "print(\"\\n--- Average Metrics Summary ---\")\n",
    "print(f\"{'Name':<30}: {model_name}\")\n",
    "print(f\"{'Description':<30}: {model_desc}\")\n",
    "print(f\"{'Accuracy':<30}: {mean_acc:.4f}\")\n",
    "print(f\"{'Precision':<30}: {mean_prec:.4f}\")\n",
    "print(f\"{'Recall':<30}: {mean_rec:.4f}\")\n",
    "print(f\"{'F1 Score':<30}: {mean_f1:.4f}\")\n",
    "\n",
    "# Also print as CSV row\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# Step 8: Write to file if not already present\n",
    "output_path = 'risk_model_metrics.csv'\n",
    "write_header = not os.path.exists(output_path)\n",
    "\n",
    "with open(output_path, mode='a', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    if write_header:\n",
    "        writer.writerow(['Name', 'Desc', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
    "    writer.writerow([model_name, model_desc, f\"{mean_acc:.4f}\", f\"{mean_prec:.4f}\", f\"{mean_rec:.4f}\", f\"{mean_f1:.4f}\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf804d22",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66ba5f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.8414, Precision=0.6500,  Recall=0.4483, F1=0.5306\n",
      "Fold 2: Accuracy=0.8759, Precision=0.7619,  Recall=0.5517, F1=0.6400\n",
      "Fold 3: Accuracy=0.8138, Precision=0.5278,  Recall=0.6552, F1=0.5846\n",
      "Fold 4: Accuracy=0.8414, Precision=0.6061,  Recall=0.6667, F1=0.6349\n",
      "Fold 5: Accuracy=0.8958, Precision=0.7917,  Recall=0.6552, F1=0.7170\n",
      "\n",
      "--- XGBoost Summary ---\n",
      "Mean Accuracy : 0.8536\n",
      "Mean Precision: 0.6675\n",
      "Mean Recall   : 0.5954\n",
      "Mean F1 Score : 0.6214\n",
      "\n",
      "CSV Row Format:\n",
      "XGBoost-Balanced,OneHot+Scaler+5Fold-Stratified,0.8536,0.6675,0.5954,0.6214\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Step 1: Prepare data\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag', 'Predicted Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# Step 2: Column categories\n",
    "categorical_cols = ['Gender', 'Religion', 'Branch', 'Section-1', 'Section-2', 'Section-3']\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Step 3: Preprocessing\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# Step 4: XGBoost Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('model', XGBClassifier(\n",
    "        objective='binary:logistic',\n",
    "        eval_metric='logloss',\n",
    "        scale_pos_weight=np.sum(y == 0) / np.sum(y == 1),  # Handles class imbalance\n",
    "        use_label_encoder=False,\n",
    "        n_estimators=100,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.1,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Step 5: Cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_val)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f},  Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# Step 6: Averages\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# Step 7: Model description\n",
    "model_name = 'XGBoost-Balanced'\n",
    "model_desc = 'OneHot+Scaler+5Fold-Stratified'\n",
    "\n",
    "# Console summary\n",
    "print(\"\\n--- XGBoost Summary ---\")\n",
    "print(f\"Mean Accuracy : {mean_acc:.4f}\")\n",
    "print(f\"Mean Precision: {mean_prec:.4f}\")\n",
    "print(f\"Mean Recall   : {mean_rec:.4f}\")\n",
    "print(f\"Mean F1 Score : {mean_f1:.4f}\")\n",
    "\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# Step 8: Save to CSV\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "result_df = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "\n",
    "# Append to CSV, add header only if file doesn't exist\n",
    "result_df.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b66f051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.8690, Precision=0.6250, Recall=0.8621, F1=0.7246\n",
      "Fold 2: Accuracy=0.8621, Precision=0.6452, Recall=0.6897, F1=0.6667\n",
      "Fold 3: Accuracy=0.7586, Precision=0.4400, Recall=0.7586, F1=0.5570\n",
      "Fold 4: Accuracy=0.8345, Precision=0.5750, Recall=0.7667, F1=0.6571\n",
      "Fold 5: Accuracy=0.8125, Precision=0.5238, Recall=0.7586, F1=0.6197\n",
      "\n",
      "--- Average Metrics Summary ---\n",
      "Name                          : XGBoost-SMOTE-Threshold0.25\n",
      "Description                   : OneHot+Scaler+SMOTE+XGB+Threshold=0.25\n",
      "Accuracy                      : 0.8273\n",
      "Precision                     : 0.5618\n",
      "Recall                        : 0.7671\n",
      "F1 Score                      : 0.6450\n",
      "\n",
      "CSV Row Format:\n",
      "XGBoost-SMOTE-Threshold0.25,OneHot+Scaler+SMOTE+XGB+Threshold=0.25,0.8273,0.5618,0.7671,0.6450\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from xgboost import XGBClassifier\n",
    "import warnings\n",
    "import csv\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Step 1: Copy and split data\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag', 'Predicted Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# Step 2: Column categorization\n",
    "categorical_cols = ['Gender', 'Religion', 'Branch', 'Section-1', 'Section-2', 'Section-3']\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Step 3: Preprocessing\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# Step 4: Pipeline with XGBoost + SMOTE\n",
    "pipeline = ImbPipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('model', XGBClassifier(\n",
    "        use_label_encoder=False,\n",
    "        eval_metric='logloss',\n",
    "        scale_pos_weight=4,  # 80:20 class balance\n",
    "        n_estimators=200,\n",
    "        max_depth=5,\n",
    "        learning_rate=0.1,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Step 5: Stratified 5-Fold CV\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Step 6: Metrics storage\n",
    "accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n",
    "\n",
    "# Threshold for classification\n",
    "threshold = 0.25\n",
    "\n",
    "# Step 7: CV loop\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_proba = pipeline.predict_proba(X_val)[:, 1]\n",
    "    y_pred = (y_proba >= threshold).astype(int)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# Step 8: Average metrics\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# Model info\n",
    "model_name = 'XGBoost-SMOTE-Threshold0.25'\n",
    "model_desc = 'OneHot+Scaler+SMOTE+XGB+Threshold=0.25'\n",
    "\n",
    "# Step 9: Print metrics\n",
    "print(\"\\n--- Average Metrics Summary ---\")\n",
    "print(f\"{'Name':<30}: {model_name}\")\n",
    "print(f\"{'Description':<30}: {model_desc}\")\n",
    "print(f\"{'Accuracy':<30}: {mean_acc:.4f}\")\n",
    "print(f\"{'Precision':<30}: {mean_prec:.4f}\")\n",
    "print(f\"{'Recall':<30}: {mean_rec:.4f}\")\n",
    "print(f\"{'F1 Score':<30}: {mean_f1:.4f}\")\n",
    "\n",
    "# Also print as CSV row\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# Step 10: Write to file if not already present\n",
    "output_path = 'risk_model_metrics.csv'\n",
    "write_header = not os.path.exists(output_path)\n",
    "\n",
    "with open(output_path, mode='a', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    if write_header:\n",
    "        writer.writerow(['Name', 'Desc', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
    "    writer.writerow([model_name, model_desc, f\"{mean_acc:.4f}\", f\"{mean_prec:.4f}\", f\"{mean_rec:.4f}\", f\"{mean_f1:.4f}\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23024535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 324 candidates, totalling 1620 fits\n",
      "Best Parameters: {'model__colsample_bytree': 0.8, 'model__learning_rate': 0.01, 'model__max_depth': 6, 'model__min_child_weight': 3, 'model__n_estimators': 300, 'model__subsample': 0.8}\n",
      "Fold 1: Accuracy=0.6207, Precision=0.3415, Recall=0.9655, F1=0.5045, Best Threshold=0.10\n",
      "Fold 2: Accuracy=0.6138, Precision=0.3333, Recall=0.9310, F1=0.4909, Best Threshold=0.10\n",
      "Fold 3: Accuracy=0.5586, Precision=0.3034, Recall=0.9310, F1=0.4576, Best Threshold=0.10\n",
      "Fold 4: Accuracy=0.5448, Precision=0.3125, Recall=1.0000, F1=0.4762, Best Threshold=0.10\n",
      "Fold 5: Accuracy=0.5000, Precision=0.2828, Recall=0.9655, F1=0.4375, Best Threshold=0.10\n",
      "\n",
      "--- Fine-Tuned XGBoost Summary ---\n",
      "Mean Accuracy : 0.5676\n",
      "Mean Precision: 0.3147\n",
      "Mean Recall   : 0.9586\n",
      "Mean F1 Score : 0.4733\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Step 1: Prepare data\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag', 'Predicted Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "categorical_cols = ['Gender', 'Religion', 'Branch', 'Section-1', 'Section-2', 'Section-3']\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Step 2: Preprocessing\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# Step 3: Pipeline with SMOTE\n",
    "pipeline = ImbPipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('model', XGBClassifier(\n",
    "        objective='binary:logistic',\n",
    "        use_label_encoder=False,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Step 4: Hyperparameter Optimization\n",
    "param_grid = {\n",
    "    'model__n_estimators': [100, 200, 300],\n",
    "    'model__max_depth': [4, 6, 8],\n",
    "    'model__learning_rate': [0.01, 0.1, 0.2],\n",
    "    'model__min_child_weight': [1, 3, 5],\n",
    "    'model__subsample': [0.8, 1.0],\n",
    "    'model__colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    scoring='f1',\n",
    "    cv=cv,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Step 5: Dynamic Threshold Tuning\n",
    "best_model = grid_search.best_estimator_\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "\n",
    "accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n",
    "thresholds = np.linspace(0.1, 0.9, 9)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    best_model.fit(X_train, y_train)\n",
    "    y_proba = best_model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    # Dynamic threshold tuning for recall\n",
    "    recalls = [recall_score(y_val, (y_proba >= t).astype(int)) for t in thresholds]\n",
    "    best_threshold = thresholds[np.argmax(recalls)]\n",
    "\n",
    "    y_pred = (y_proba >= best_threshold).astype(int)\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}, F1={f1:.4f}, Best Threshold={best_threshold:.2f}\")\n",
    "\n",
    "# Step 6: Aggregate Results\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# Step 7: Summary\n",
    "model_name = 'XGBoost-SMOTE-FineTuned'\n",
    "model_desc = f'OptimizedParams|DynamicThresh={best_threshold:.2f}|OneHot+Scaler'\n",
    "\n",
    "print(\"\\n--- Fine-Tuned XGBoost Summary ---\")\n",
    "print(f\"Mean Accuracy : {mean_acc:.4f}\")\n",
    "print(f\"Mean Precision: {mean_prec:.4f}\")\n",
    "print(f\"Mean Recall   : {mean_rec:.4f}\")\n",
    "print(f\"Mean F1 Score : {mean_f1:.4f}\")\n",
    "\n",
    "# Step 8: Save to CSV\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "result_df = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "result_df.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9cc6f567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 972 candidates, totalling 4860 fits\n",
      "Best Parameters: {'model__colsample_bytree': 0.8, 'model__learning_rate': 0.05, 'model__max_depth': 8, 'model__min_child_weight': 5, 'model__n_estimators': 300, 'model__scale_pos_weight': 4, 'model__subsample': 0.8}\n",
      "Fold 1: Accuracy=0.9241, Precision=0.8462, Recall=0.7586, F1=0.8000, Best Threshold=0.60\n",
      "Fold 2: Accuracy=0.8759, Precision=0.6897, Recall=0.6897, F1=0.6897, Best Threshold=0.40\n",
      "Fold 3: Accuracy=0.8207, Precision=0.5405, Recall=0.6897, F1=0.6061, Best Threshold=0.60\n",
      "Fold 4: Accuracy=0.8552, Precision=0.6452, Recall=0.6667, F1=0.6557, Best Threshold=0.70\n",
      "Fold 5: Accuracy=0.8681, Precision=0.6786, Recall=0.6552, F1=0.6667, Best Threshold=0.70\n",
      "\n",
      "--- Fine-Tuned XGBoost Summary ---\n",
      "Mean Accuracy : 0.8688\n",
      "Mean Precision: 0.6800\n",
      "Mean Recall   : 0.6920\n",
      "Mean F1 Score : 0.6836\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Step 1: Prepare data\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag', 'Predicted Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "categorical_cols = ['Gender', 'Religion', 'Branch', 'Section-1', 'Section-2', 'Section-3']\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Step 2: Preprocessing\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# Step 3: Pipeline with SMOTE\n",
    "pipeline = ImbPipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('model', XGBClassifier(\n",
    "        objective='binary:logistic',\n",
    "        use_label_encoder=False,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Step 4: Hyperparameter Optimization\n",
    "param_grid = {\n",
    "    'model__n_estimators': [200, 300, 400],\n",
    "    'model__max_depth': [4, 6, 8],\n",
    "    'model__learning_rate': [0.01, 0.05, 0.1],\n",
    "    'model__min_child_weight': [1, 3, 5],\n",
    "    'model__subsample': [0.8, 1.0],\n",
    "    'model__colsample_bytree': [0.8, 1.0],\n",
    "    'model__scale_pos_weight': [4, 5, 6]  # Adjusted for imbalance\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    scoring='balanced_accuracy',  # Balances true positive/negative rates\n",
    "    cv=cv,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Step 5: Dynamic Threshold Tuning\n",
    "best_model = grid_search.best_estimator_\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "\n",
    "accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n",
    "thresholds = np.linspace(0.1, 0.9, 9)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    best_model.fit(X_train, y_train)\n",
    "    y_proba = best_model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    # Dynamic threshold tuning for F1\n",
    "    f1_scores = [f1_score(y_val, (y_proba >= t).astype(int)) for t in thresholds]\n",
    "    best_threshold = thresholds[np.argmax(f1_scores)]\n",
    "\n",
    "    y_pred = (y_proba >= best_threshold).astype(int)\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}, F1={f1:.4f}, Best Threshold={best_threshold:.2f}\")\n",
    "\n",
    "# Step 6: Aggregate Results\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# Step 7: Summary\n",
    "model_name = 'XGBoost-SMOTE-FineTuned-Balanced'\n",
    "model_desc = f'OptimizedParams|DynamicThresh={best_threshold:.2f}|OneHot+Scaler'\n",
    "\n",
    "print(\"\\n--- Fine-Tuned XGBoost Summary ---\")\n",
    "print(f\"Mean Accuracy : {mean_acc:.4f}\")\n",
    "print(f\"Mean Precision: {mean_prec:.4f}\")\n",
    "print(f\"Mean Recall   : {mean_rec:.4f}\")\n",
    "print(f\"Mean F1 Score : {mean_f1:.4f}\")\n",
    "\n",
    "# Step 8: Save to CSV\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "result_df = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "result_df.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b84066a",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a727782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.8828, Precision=0.8000,  Recall=0.5517, F1=0.6531\n",
      "Fold 2: Accuracy=0.8690, Precision=0.7273,  Recall=0.5517, F1=0.6275\n",
      "Fold 3: Accuracy=0.8138, Precision=0.5294,  Recall=0.6207, F1=0.5714\n",
      "Fold 4: Accuracy=0.8483, Precision=0.6333,  Recall=0.6333, F1=0.6333\n",
      "Fold 5: Accuracy=0.8681, Precision=0.6786,  Recall=0.6552, F1=0.6667\n",
      "\n",
      "--- LightGBM Summary ---\n",
      "Mean Accuracy : 0.8564\n",
      "Mean Precision: 0.6737\n",
      "Mean Recall   : 0.6025\n",
      "Mean F1 Score : 0.6304\n",
      "\n",
      "CSV Row Format:\n",
      "LightGBM-Balanced,OneHot+Scaler+5Fold-Stratified+VerboseOff,0.8564,0.6737,0.6025,0.6304\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Step 1: Prepare data\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag', 'Predicted Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# Optional: Check constant columns\n",
    "constant_cols = [col for col in X.columns if X[col].nunique() <= 1]\n",
    "if constant_cols:\n",
    "    print(\"Warning: Constant columns detected:\", constant_cols)\n",
    "\n",
    "# Step 2: Column categories\n",
    "categorical_cols = ['Gender', 'Religion', 'Branch', 'Section-1', 'Section-2', 'Section-3']\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Step 3: Preprocessing\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', drop='if_binary', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# Step 4: LightGBM Pipeline (optimized to suppress warnings)\n",
    "pipeline = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('model', LGBMClassifier(\n",
    "        objective='binary',\n",
    "        class_weight='balanced',\n",
    "        n_estimators=100,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.1,\n",
    "        min_split_gain=0.01,\n",
    "        min_child_samples=20,\n",
    "        min_data_in_leaf=20,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        verbose=-1,              # suppress LightGBM internal logs\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Step 5: Cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_val)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f},  Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# Step 6: Averages\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# Step 7: Model description\n",
    "model_name = 'LightGBM-Balanced'\n",
    "model_desc = 'OneHot+Scaler+5Fold-Stratified+VerboseOff'\n",
    "\n",
    "# Console summary\n",
    "print(\"\\n--- LightGBM Summary ---\")\n",
    "print(f\"Mean Accuracy : {mean_acc:.4f}\")\n",
    "print(f\"Mean Precision: {mean_prec:.4f}\")\n",
    "print(f\"Mean Recall   : {mean_rec:.4f}\")\n",
    "print(f\"Mean F1 Score : {mean_f1:.4f}\")\n",
    "\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# Step 8: Save to CSV\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "result_df = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "\n",
    "result_df.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ba0076c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Tuned LightGBM Model Scores:\n",
      "Accuracy : 0.7459\n",
      "Precision: 0.4328\n",
      "Recall   : 0.8283\n",
      "F1 Score : 0.5676\n",
      "Best Parameters: OrderedDict({'model__colsample_bytree': 1.0, 'model__learning_rate': 0.01, 'model__max_depth': 12, 'model__min_child_samples': 100, 'model__min_split_gain': 0.2, 'model__n_estimators': 100, 'model__subsample': 0.8664183933116096})\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Integer, Real\n",
    "\n",
    "# Load your real df_clean before this step\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag', 'Predicted Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "categorical_cols = ['Gender', 'Religion', 'Branch', 'Section-1', 'Section-2', 'Section-3']\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', drop='if_binary', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('model', LGBMClassifier(objective='binary', class_weight='balanced', verbose=-1, random_state=42))\n",
    "])\n",
    "\n",
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision': make_scorer(precision_score, zero_division=0),\n",
    "    'recall': make_scorer(recall_score),\n",
    "    'f1': make_scorer(f1_score)\n",
    "}\n",
    "\n",
    "param_space = {\n",
    "    'model__n_estimators': Integer(100, 500),\n",
    "    'model__max_depth': Integer(3, 12),\n",
    "    'model__learning_rate': Real(0.01, 0.3, prior='log-uniform'),\n",
    "    'model__min_child_samples': Integer(10, 100),\n",
    "    'model__min_split_gain': Real(0.0, 0.2),\n",
    "    'model__subsample': Real(0.6, 1.0),\n",
    "    'model__colsample_bytree': Real(0.6, 1.0)\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "opt = BayesSearchCV(\n",
    "    estimator=pipeline,\n",
    "    search_spaces=param_space,\n",
    "    scoring=scoring,\n",
    "    refit='recall',\n",
    "    n_iter=40,\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=0,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "opt.fit(X, y)\n",
    "\n",
    "best_model = opt.best_estimator_\n",
    "cv_results = cross_validate(best_model, X, y, cv=cv, scoring=scoring)\n",
    "\n",
    "print(\"Final Tuned LightGBM Model Scores:\")\n",
    "print(f\"Accuracy : {np.mean(cv_results['test_accuracy']):.4f}\")\n",
    "print(f\"Precision: {np.mean(cv_results['test_precision']):.4f}\")\n",
    "print(f\"Recall   : {np.mean(cv_results['test_recall']):.4f}\")\n",
    "print(f\"F1 Score : {np.mean(cv_results['test_f1']):.4f}\")\n",
    "print(\"Best Parameters:\", opt.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2340a2b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No threshold met all conditions. Using default 0.5.\n",
      "\n",
      "--- Threshold-Tuned LightGBM Results ---\n",
      "Threshold   : 0.5000\n",
      "Accuracy    : 0.7459\n",
      "Precision   : 0.4321\n",
      "Recall      : 0.8288\n",
      "F1 Score    : 0.5681\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    precision_recall_curve\n",
    ")\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Step 1: Prepare data\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag', 'Predicted Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# Step 2: Column categories\n",
    "categorical_cols = ['Gender', 'Religion', 'Branch', 'Section-1', 'Section-2', 'Section-3']\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Step 3: Preprocessing\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', drop='if_binary', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# Step 4: LightGBM Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('model', LGBMClassifier(\n",
    "        objective='binary',\n",
    "        class_weight='balanced',\n",
    "        learning_rate=0.01,\n",
    "        max_depth=12,\n",
    "        min_child_samples=100,\n",
    "        min_split_gain=0.2,\n",
    "        n_estimators=100,\n",
    "        subsample=0.8664,\n",
    "        colsample_bytree=1.0,\n",
    "        verbose=-1,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Step 5: Cross-validation predictions\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "y_probs = cross_val_predict(pipeline, X, y, cv=cv, method='predict_proba')[:, 1]\n",
    "y_true = y.copy()  # true labels for all folds\n",
    "\n",
    "# Step 6: Find optimal threshold\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_true, y_probs)\n",
    "valid = [(p, r, t) for p, r, t in zip(precisions, recalls, thresholds) if r >= 0.85 and p > 0.50]\n",
    "\n",
    "if valid:\n",
    "    best_prec, best_rec, best_thresh = max(valid, key=lambda x: 2*x[0]*x[1]/(x[0]+x[1]))\n",
    "else:\n",
    "    best_thresh = 0.5  # fallback\n",
    "    best_prec = precision_score(y_true, y_probs >= best_thresh, zero_division=0)\n",
    "    best_rec = recall_score(y_true, y_probs >= best_thresh)\n",
    "    best_f1 = f1_score(y_true, y_probs >= best_thresh)\n",
    "    print(\"No threshold met all conditions. Using default 0.5.\")\n",
    "\n",
    "# Step 7: Final metrics at optimal threshold\n",
    "y_pred_final = (y_probs >= best_thresh).astype(int)\n",
    "final_acc = accuracy_score(y_true, y_pred_final)\n",
    "final_prec = precision_score(y_true, y_pred_final, zero_division=0)\n",
    "final_rec = recall_score(y_true, y_pred_final)\n",
    "final_f1 = f1_score(y_true, y_pred_final)\n",
    "\n",
    "# Step 8: Print results\n",
    "print(\"\\n--- Threshold-Tuned LightGBM Results ---\")\n",
    "print(f\"Threshold   : {best_thresh:.4f}\")\n",
    "print(f\"Accuracy    : {final_acc:.4f}\")\n",
    "print(f\"Precision   : {final_prec:.4f}\")\n",
    "print(f\"Recall      : {final_rec:.4f}\")\n",
    "print(f\"F1 Score    : {final_f1:.4f}\")\n",
    "\n",
    "# Step 9: Save to CSV\n",
    "model_name = 'LightGBM-Tuned-Threshold'\n",
    "model_desc = 'BayesOpt+Threshold@{:.4f}'.format(best_thresh)\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "\n",
    "result_df = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(final_acc, 4),\n",
    "    'Precision': round(final_prec, 4),\n",
    "    'Recall': round(final_rec, 4),\n",
    "    'F1 Score': round(final_f1, 4)\n",
    "}])\n",
    "result_df.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "675c6094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.2000, Precision=0.2000, Recall=1.0000, F1=0.3333, Threshold=0.0000\n",
      "Fold 2: Accuracy=0.2000, Precision=0.2000, Recall=1.0000, F1=0.3333, Threshold=0.0000\n",
      "Fold 3: Accuracy=0.2000, Precision=0.2000, Recall=1.0000, F1=0.3333, Threshold=0.0000\n",
      "Fold 4: Accuracy=0.2069, Precision=0.2069, Recall=1.0000, F1=0.3429, Threshold=0.0001\n",
      "Fold 5: Accuracy=0.2014, Precision=0.2014, Recall=1.0000, F1=0.3353, Threshold=0.0000\n",
      "\n",
      "--- LightGBM Tuned Summary ---\n",
      "Mean Accuracy : 0.2017\n",
      "Mean Precision: 0.2017\n",
      "Mean Recall   : 1.0000\n",
      "Mean F1 Score : 0.3356\n",
      "\n",
      "CSV Row Format:\n",
      "LightGBM-Tuned-HighRecall,OneHot+Scaler+5Fold-Stratified+ThresholdTuned+VerboseOff,0.2017,0.2017,1.0000,0.3356\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "# Step 1: Prepare data\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag', 'Predicted Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# Optional: Check constant columns\n",
    "constant_cols = [col for col in X.columns if X[col].nunique() <= 1]\n",
    "if constant_cols:\n",
    "    print(\"Warning: Constant columns detected:\", constant_cols)\n",
    "\n",
    "# Step 2: Column categories\n",
    "categorical_cols = ['Gender', 'Religion', 'Branch', 'Section-1', 'Section-2', 'Section-3']\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Step 3: Preprocessing\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', drop='if_binary', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# Step 4: LightGBM Pipeline with tuned parameters\n",
    "pipeline = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('model', LGBMClassifier(\n",
    "        objective='binary',\n",
    "        class_weight='balanced',\n",
    "        n_estimators=200,           # Increased to allow more learning\n",
    "        max_depth=8,                # Slightly deeper trees\n",
    "        learning_rate=0.05,         # Lower for better convergence\n",
    "        min_split_gain=0.01,\n",
    "        min_child_samples=10,       # Lowered to capture smaller patterns\n",
    "        min_data_in_leaf=10,        # Lowered to reduce overfitting\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.7,      # Slightly reduced to increase diversity\n",
    "        scale_pos_weight=3,         # Increase to prioritize positive class (tune based on imbalance)\n",
    "        verbose=-1,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Step 5: Cross-validation with threshold tuning\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    # Fit the pipeline\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # Get probability scores for threshold tuning\n",
    "    y_prob = pipeline.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    # Find optimal threshold for recall >= 0.85\n",
    "    precisions, recalls, thresholds = precision_recall_curve(y_val, y_prob)\n",
    "    threshold = thresholds[np.argmax(recalls >= 0.85)] if np.any(recalls >= 0.85) else 0.5\n",
    "\n",
    "    # Apply threshold to predictions\n",
    "    y_pred = (y_prob >= threshold).astype(int)\n",
    "\n",
    "    # Calculate metrics\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}, F1={f1:.4f}, Threshold={threshold:.4f}\")\n",
    "\n",
    "# Step 6: Averages\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# Step 7: Model description\n",
    "model_name = 'LightGBM-Tuned-HighRecall'\n",
    "model_desc = 'OneHot+Scaler+5Fold-Stratified+ThresholdTuned+VerboseOff'\n",
    "\n",
    "# Console summary\n",
    "print(\"\\n--- LightGBM Tuned Summary ---\")\n",
    "print(f\"Mean Accuracy : {mean_acc:.4f}\")\n",
    "print(f\"Mean Precision: {mean_prec:.4f}\")\n",
    "print(f\"Mean Recall   : {mean_rec:.4f}\")\n",
    "print(f\"Mean F1 Score : {mean_f1:.4f}\")\n",
    "\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# Step 8: Save to CSV\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "result_df = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "\n",
    "result_df.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "262e550f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 18:56:04,711] A new study created in memory with name: no-name-ea097395-081d-45b5-9c72-69a950a23895\n",
      "Best trial: 0. Best value: 0.623218:   2%|â–         | 1/50 [00:01<01:02,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 18:56:05,984] Trial 0 finished with value: 0.6232183908045976 and parameters: {'n_estimators': 274, 'learning_rate': 0.12943432035516703, 'max_depth': 7, 'num_leaves': 37, 'min_child_samples': 41, 'subsample': 0.7726104962620636, 'colsample_bytree': 0.7055135162673605}. Best is trial 0 with value: 0.6232183908045976.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.623218:   4%|â–         | 2/50 [00:02<01:02,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 18:56:07,324] Trial 1 finished with value: 0.6022988505747126 and parameters: {'n_estimators': 171, 'learning_rate': 0.1254065378413808, 'max_depth': 7, 'num_leaves': 64, 'min_child_samples': 14, 'subsample': 0.8845647153000895, 'colsample_bytree': 0.63654892338312}. Best is trial 0 with value: 0.6232183908045976.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.704828:   6%|â–Œ         | 3/50 [00:03<00:49,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 18:56:08,079] Trial 2 finished with value: 0.7048275862068966 and parameters: {'n_estimators': 119, 'learning_rate': 0.141743005637849, 'max_depth': 3, 'num_leaves': 41, 'min_child_samples': 34, 'subsample': 0.8528944368742704, 'colsample_bytree': 0.7339201716544633}. Best is trial 2 with value: 0.7048275862068966.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.704828:   8%|â–Š         | 4/50 [00:04<00:51,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 18:56:09,316] Trial 3 finished with value: 0.636551724137931 and parameters: {'n_estimators': 120, 'learning_rate': 0.08963186433686471, 'max_depth': 9, 'num_leaves': 64, 'min_child_samples': 16, 'subsample': 0.9295288542951307, 'colsample_bytree': 0.628843182173922}. Best is trial 2 with value: 0.7048275862068966.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.704828:  10%|â–ˆ         | 5/50 [00:05<00:50,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 18:56:10,427] Trial 4 finished with value: 0.6572413793103448 and parameters: {'n_estimators': 187, 'learning_rate': 0.09697859288208036, 'max_depth': 10, 'num_leaves': 42, 'min_child_samples': 45, 'subsample': 0.6752632648140585, 'colsample_bytree': 0.9556743770005429}. Best is trial 2 with value: 0.7048275862068966.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.910575:  12%|â–ˆâ–        | 6/50 [00:06<00:44,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 18:56:11,253] Trial 5 finished with value: 0.9105747126436782 and parameters: {'n_estimators': 128, 'learning_rate': 0.014554857766166909, 'max_depth': 4, 'num_leaves': 69, 'min_child_samples': 32, 'subsample': 0.8104465472368176, 'colsample_bytree': 0.6276939094146502}. Best is trial 5 with value: 0.9105747126436782.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.910575:  14%|â–ˆâ–        | 7/50 [00:08<00:58,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 18:56:13,319] Trial 6 finished with value: 0.5882758620689655 and parameters: {'n_estimators': 250, 'learning_rate': 0.06532001433077816, 'max_depth': 9, 'num_leaves': 41, 'min_child_samples': 13, 'subsample': 0.9010052104549857, 'colsample_bytree': 0.7220910479151434}. Best is trial 5 with value: 0.9105747126436782.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.910575:  16%|â–ˆâ–Œ        | 8/50 [00:09<00:50,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 18:56:14,168] Trial 7 finished with value: 0.7597701149425288 and parameters: {'n_estimators': 119, 'learning_rate': 0.06904038886159725, 'max_depth': 4, 'num_leaves': 60, 'min_child_samples': 45, 'subsample': 0.9806880464832293, 'colsample_bytree': 0.9302937671632896}. Best is trial 5 with value: 0.9105747126436782.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.910575:  18%|â–ˆâ–Š        | 9/50 [00:10<00:45,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 18:56:15,105] Trial 8 finished with value: 0.7459770114942529 and parameters: {'n_estimators': 121, 'learning_rate': 0.0416616521060133, 'max_depth': 12, 'num_leaves': 31, 'min_child_samples': 34, 'subsample': 0.6016043891441043, 'colsample_bytree': 0.8754014143882602}. Best is trial 5 with value: 0.9105747126436782.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.910575:  20%|â–ˆâ–ˆ        | 10/50 [00:11<00:44,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 18:56:16,214] Trial 9 finished with value: 0.6505747126436782 and parameters: {'n_estimators': 161, 'learning_rate': 0.10421615080365149, 'max_depth': 8, 'num_leaves': 55, 'min_child_samples': 34, 'subsample': 0.7257048544526679, 'colsample_bytree': 0.8320440023185659}. Best is trial 5 with value: 0.9105747126436782.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.910575:  22%|â–ˆâ–ˆâ–       | 11/50 [00:12<00:46,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 18:56:17,558] Trial 10 finished with value: 0.8691954022988506 and parameters: {'n_estimators': 224, 'learning_rate': 0.011201939058785387, 'max_depth': 5, 'num_leaves': 80, 'min_child_samples': 24, 'subsample': 0.8090623131897657, 'colsample_bytree': 0.6071485725444605}. Best is trial 5 with value: 0.9105747126436782.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.910575:  24%|â–ˆâ–ˆâ–       | 12/50 [00:13<00:44,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 18:56:18,661] Trial 11 finished with value: 0.8485057471264369 and parameters: {'n_estimators': 232, 'learning_rate': 0.013143212494575757, 'max_depth': 5, 'num_leaves': 80, 'min_child_samples': 24, 'subsample': 0.8060618220680413, 'colsample_bytree': 0.6072039811138609}. Best is trial 5 with value: 0.9105747126436782.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.910575:  26%|â–ˆâ–ˆâ–Œ       | 13/50 [00:15<00:43,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 18:56:19,871] Trial 12 finished with value: 0.8075862068965517 and parameters: {'n_estimators': 226, 'learning_rate': 0.015439095116811578, 'max_depth': 5, 'num_leaves': 79, 'min_child_samples': 26, 'subsample': 0.8112480561603898, 'colsample_bytree': 0.6696315551757601}. Best is trial 5 with value: 0.9105747126436782.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.910575:  28%|â–ˆâ–ˆâ–Š       | 14/50 [00:16<00:42,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 18:56:21,085] Trial 13 finished with value: 0.6910344827586207 and parameters: {'n_estimators': 203, 'learning_rate': 0.03917044866376569, 'max_depth': 5, 'num_leaves': 72, 'min_child_samples': 21, 'subsample': 0.7440027187309903, 'colsample_bytree': 0.7672579188009249}. Best is trial 5 with value: 0.9105747126436782.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.910575:  30%|â–ˆâ–ˆâ–ˆ       | 15/50 [00:17<00:41,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 18:56:22,277] Trial 14 finished with value: 0.7735632183908047 and parameters: {'n_estimators': 299, 'learning_rate': 0.04356326461928324, 'max_depth': 3, 'num_leaves': 73, 'min_child_samples': 29, 'subsample': 0.8379346336390906, 'colsample_bytree': 0.670636785008359}. Best is trial 5 with value: 0.9105747126436782.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.910575:  32%|â–ˆâ–ˆâ–ˆâ–      | 16/50 [00:18<00:40,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 18:56:23,510] Trial 15 finished with value: 0.7255172413793105 and parameters: {'n_estimators': 152, 'learning_rate': 0.027245410807788507, 'max_depth': 6, 'num_leaves': 70, 'min_child_samples': 20, 'subsample': 0.6775109406725263, 'colsample_bytree': 0.806913433609824}. Best is trial 5 with value: 0.9105747126436782.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.910575:  34%|â–ˆâ–ˆâ–ˆâ–      | 17/50 [00:19<00:37,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 18:56:24,461] Trial 16 finished with value: 0.7186206896551723 and parameters: {'n_estimators': 212, 'learning_rate': 0.06011534159188067, 'max_depth': 4, 'num_leaves': 22, 'min_child_samples': 38, 'subsample': 0.9646574993772924, 'colsample_bytree': 0.6095221727731172}. Best is trial 5 with value: 0.9105747126436782.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.910575:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 18/50 [00:20<00:35,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 18:56:25,560] Trial 17 finished with value: 0.9105747126436782 and parameters: {'n_estimators': 144, 'learning_rate': 0.010905939425416952, 'max_depth': 6, 'num_leaves': 54, 'min_child_samples': 29, 'subsample': 0.7634433117944978, 'colsample_bytree': 0.6729903841902101}. Best is trial 5 with value: 0.9105747126436782.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.910575:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 19/50 [00:21<00:32,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 18:56:26,460] Trial 18 finished with value: 0.8213793103448275 and parameters: {'n_estimators': 145, 'learning_rate': 0.03347137487598999, 'max_depth': 6, 'num_leaves': 48, 'min_child_samples': 49, 'subsample': 0.7035817205778234, 'colsample_bytree': 0.6814603886107802}. Best is trial 5 with value: 0.9105747126436782.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.910575:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 20/50 [00:22<00:30,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 18:56:27,410] Trial 19 finished with value: 0.8349425287356322 and parameters: {'n_estimators': 103, 'learning_rate': 0.02523955604738498, 'max_depth': 12, 'num_leaves': 55, 'min_child_samples': 30, 'subsample': 0.6152396279457476, 'colsample_bytree': 0.7547015858834994}. Best is trial 5 with value: 0.9105747126436782.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.910575:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/50 [00:23<00:28,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 18:56:28,324] Trial 20 finished with value: 0.7117241379310345 and parameters: {'n_estimators': 136, 'learning_rate': 0.0526929272357087, 'max_depth': 6, 'num_leaves': 49, 'min_child_samples': 39, 'subsample': 0.7639552521801275, 'colsample_bytree': 0.8662991916920607}. Best is trial 5 with value: 0.9105747126436782.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.910575:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 22/50 [00:24<00:28,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 18:56:29,442] Trial 21 finished with value: 0.9036781609195403 and parameters: {'n_estimators': 180, 'learning_rate': 0.012343831018930121, 'max_depth': 4, 'num_leaves': 75, 'min_child_samples': 29, 'subsample': 0.7946188126589926, 'colsample_bytree': 0.6512200536060809}. Best is trial 5 with value: 0.9105747126436782.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.910575:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 23/50 [00:25<00:27,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 18:56:30,500] Trial 22 finished with value: 0.8078160919540229 and parameters: {'n_estimators': 187, 'learning_rate': 0.02332212383044825, 'max_depth': 4, 'num_leaves': 67, 'min_child_samples': 28, 'subsample': 0.8556817929639109, 'colsample_bytree': 0.6738934289164392}. Best is trial 5 with value: 0.9105747126436782.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 23. Best value: 0.931034:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 24/50 [00:26<00:26,  1.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 18:56:31,418] Trial 23 finished with value: 0.9310344827586207 and parameters: {'n_estimators': 176, 'learning_rate': 0.010870704349832255, 'max_depth': 3, 'num_leaves': 59, 'min_child_samples': 33, 'subsample': 0.7805541334893635, 'colsample_bytree': 0.6435270716715916}. Best is trial 23 with value: 0.9310344827586207.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 23. Best value: 0.931034:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 25/50 [00:27<00:23,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 18:56:32,243] Trial 24 finished with value: 0.9036781609195403 and parameters: {'n_estimators': 137, 'learning_rate': 0.026108261769540238, 'max_depth': 3, 'num_leaves': 57, 'min_child_samples': 32, 'subsample': 0.765319488074004, 'colsample_bytree': 0.698127858617611}. Best is trial 23 with value: 0.9310344827586207.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 23. Best value: 0.931034:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/50 [00:28<00:22,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 18:56:33,195] Trial 25 finished with value: 0.8351724137931035 and parameters: {'n_estimators': 164, 'learning_rate': 0.0497978719627479, 'max_depth': 3, 'num_leaves': 62, 'min_child_samples': 37, 'subsample': 0.7208371092888796, 'colsample_bytree': 0.6440497998361633}. Best is trial 23 with value: 0.9310344827586207.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 23. Best value: 0.931034:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 27/50 [00:29<00:21,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 18:56:34,071] Trial 26 finished with value: 0.7114942528735633 and parameters: {'n_estimators': 102, 'learning_rate': 0.0741146079916432, 'max_depth': 6, 'num_leaves': 49, 'min_child_samples': 32, 'subsample': 0.6890942327754204, 'colsample_bytree': 0.7579351647160979}. Best is trial 23 with value: 0.9310344827586207.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 23. Best value: 0.931034:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 28/50 [00:30<00:20,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 18:56:35,052] Trial 27 finished with value: 0.7806896551724136 and parameters: {'n_estimators': 153, 'learning_rate': 0.035441953085649645, 'max_depth': 4, 'num_leaves': 53, 'min_child_samples': 19, 'subsample': 0.8905482421508466, 'colsample_bytree': 0.7089151729599528}. Best is trial 23 with value: 0.9310344827586207.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 23. Best value: 0.931034:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 29/50 [00:31<00:19,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 18:56:36,017] Trial 28 finished with value: 0.8694252873563219 and parameters: {'n_estimators': 139, 'learning_rate': 0.021065033356895514, 'max_depth': 7, 'num_leaves': 68, 'min_child_samples': 42, 'subsample': 0.6501159739761548, 'colsample_bytree': 0.7883728493094412}. Best is trial 23 with value: 0.9310344827586207.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 23. Best value: 0.931034:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 30/50 [00:33<00:24,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 18:56:37,833] Trial 29 finished with value: 0.5680459770114943 and parameters: {'n_estimators': 179, 'learning_rate': 0.11680807123692225, 'max_depth': 8, 'num_leaves': 59, 'min_child_samples': 10, 'subsample': 0.7833757702159005, 'colsample_bytree': 0.6981586603311583}. Best is trial 23 with value: 0.9310344827586207.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 23. Best value: 0.931034:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/50 [00:34<00:21,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 18:56:38,819] Trial 30 finished with value: 0.7117241379310345 and parameters: {'n_estimators': 131, 'learning_rate': 0.05344199981554171, 'max_depth': 5, 'num_leaves': 33, 'min_child_samples': 26, 'subsample': 0.8309190681945167, 'colsample_bytree': 0.6484034545168335}. Best is trial 23 with value: 0.9310344827586207.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 23. Best value: 0.931034:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 32/50 [00:35<00:19,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 18:56:39,784] Trial 31 finished with value: 0.8967816091954024 and parameters: {'n_estimators': 196, 'learning_rate': 0.011533010280979535, 'max_depth': 4, 'num_leaves': 77, 'min_child_samples': 32, 'subsample': 0.7825695252588017, 'colsample_bytree': 0.6511430490833743}. Best is trial 23 with value: 0.9310344827586207.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 23. Best value: 0.931034:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 33/50 [00:36<00:17,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 18:56:40,765] Trial 32 finished with value: 0.8760919540229886 and parameters: {'n_estimators': 174, 'learning_rate': 0.03153850523777705, 'max_depth': 3, 'num_leaves': 75, 'min_child_samples': 36, 'subsample': 0.7454515694643884, 'colsample_bytree': 0.6269770767012512}. Best is trial 23 with value: 0.9310344827586207.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 23. Best value: 0.931034:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 34/50 [00:37<00:16,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 18:56:41,831] Trial 33 finished with value: 0.8691954022988506 and parameters: {'n_estimators': 166, 'learning_rate': 0.019040589846820295, 'max_depth': 4, 'num_leaves': 66, 'min_child_samples': 27, 'subsample': 0.8628459544946647, 'colsample_bytree': 0.6489876127375321}. Best is trial 23 with value: 0.9310344827586207.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 23. Best value: 0.931034:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 35/50 [00:37<00:14,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 18:56:42,660] Trial 34 finished with value: 0.6914942528735633 and parameters: {'n_estimators': 153, 'learning_rate': 0.14181392687047628, 'max_depth': 3, 'num_leaves': 62, 'min_child_samples': 30, 'subsample': 0.8303483916332124, 'colsample_bytree': 0.7186606693901026}. Best is trial 23 with value: 0.9310344827586207.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 23. Best value: 0.931034:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 36/50 [00:39<00:14,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 18:56:43,733] Trial 35 finished with value: 0.8416091954022988 and parameters: {'n_estimators': 177, 'learning_rate': 0.01866674161737824, 'max_depth': 7, 'num_leaves': 70, 'min_child_samples': 41, 'subsample': 0.7936772287730781, 'colsample_bytree': 0.6297187184370182}. Best is trial 23 with value: 0.9310344827586207.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 23. Best value: 0.931034:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 37/50 [00:40<00:14,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 18:56:45,007] Trial 36 finished with value: 0.8829885057471264 and parameters: {'n_estimators': 198, 'learning_rate': 0.010018954167034935, 'max_depth': 5, 'num_leaves': 46, 'min_child_samples': 22, 'subsample': 0.7493599852759565, 'colsample_bytree': 0.7315184020792771}. Best is trial 23 with value: 0.9310344827586207.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 23. Best value: 0.931034:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 38/50 [00:41<00:12,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 18:56:46,066] Trial 37 finished with value: 0.7324137931034483 and parameters: {'n_estimators': 126, 'learning_rate': 0.08304270090690188, 'max_depth': 4, 'num_leaves': 64, 'min_child_samples': 36, 'subsample': 0.7234910241654162, 'colsample_bytree': 0.6865955283890041}. Best is trial 23 with value: 0.9310344827586207.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 23. Best value: 0.931034:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 39/50 [00:42<00:12,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 18:56:47,352] Trial 38 finished with value: 0.670344827586207 and parameters: {'n_estimators': 188, 'learning_rate': 0.031551209721302605, 'max_depth': 11, 'num_leaves': 75, 'min_child_samples': 24, 'subsample': 0.765688210780348, 'colsample_bytree': 0.6007297361764834}. Best is trial 23 with value: 0.9310344827586207.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 23. Best value: 0.931034:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 40/50 [00:43<00:10,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 18:56:48,220] Trial 39 finished with value: 0.732183908045977 and parameters: {'n_estimators': 115, 'learning_rate': 0.12828214572693278, 'max_depth': 3, 'num_leaves': 52, 'min_child_samples': 34, 'subsample': 0.867350917800929, 'colsample_bytree': 0.6260194957326859}. Best is trial 23 with value: 0.9310344827586207.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 23. Best value: 0.931034:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 41/50 [00:44<00:10,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 18:56:49,687] Trial 40 finished with value: 0.6710344827586207 and parameters: {'n_estimators': 260, 'learning_rate': 0.04368365079000415, 'max_depth': 6, 'num_leaves': 43, 'min_child_samples': 31, 'subsample': 0.826978232531919, 'colsample_bytree': 0.6626651975008017}. Best is trial 23 with value: 0.9310344827586207.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 23. Best value: 0.931034:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 42/50 [00:45<00:08,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 18:56:50,657] Trial 41 finished with value: 0.9036781609195403 and parameters: {'n_estimators': 147, 'learning_rate': 0.02665982991743007, 'max_depth': 3, 'num_leaves': 55, 'min_child_samples': 33, 'subsample': 0.7705282664269228, 'colsample_bytree': 0.6959036215875297}. Best is trial 23 with value: 0.9310344827586207.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 23. Best value: 0.931034:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 43/50 [00:46<00:07,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 18:56:51,499] Trial 42 finished with value: 0.9310344827586207 and parameters: {'n_estimators': 110, 'learning_rate': 0.019171971714250294, 'max_depth': 3, 'num_leaves': 58, 'min_child_samples': 28, 'subsample': 0.9164304279938748, 'colsample_bytree': 0.7377654018202351}. Best is trial 23 with value: 0.9310344827586207.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 23. Best value: 0.931034:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 44/50 [00:47<00:06,  1.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 18:56:52,417] Trial 43 finished with value: 0.869655172413793 and parameters: {'n_estimators': 120, 'learning_rate': 0.017749426685932296, 'max_depth': 4, 'num_leaves': 60, 'min_child_samples': 28, 'subsample': 0.9542919541610017, 'colsample_bytree': 0.9907781787990794}. Best is trial 23 with value: 0.9310344827586207.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 23. Best value: 0.931034:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 45/50 [00:48<00:05,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 18:56:53,471] Trial 44 finished with value: 0.8694252873563219 and parameters: {'n_estimators': 111, 'learning_rate': 0.016255706835430542, 'max_depth': 5, 'num_leaves': 65, 'min_child_samples': 17, 'subsample': 0.999843834203986, 'colsample_bytree': 0.7327655310253693}. Best is trial 23 with value: 0.9310344827586207.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 23. Best value: 0.931034:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 46/50 [00:49<00:03,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 18:56:54,395] Trial 45 finished with value: 0.9241379310344827 and parameters: {'n_estimators': 108, 'learning_rate': 0.01126257296120688, 'max_depth': 9, 'num_leaves': 59, 'min_child_samples': 24, 'subsample': 0.9158913528956754, 'colsample_bytree': 0.6645812044458386}. Best is trial 23 with value: 0.9310344827586207.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 23. Best value: 0.931034:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 47/50 [00:50<00:02,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 18:56:55,384] Trial 46 finished with value: 0.7112643678160919 and parameters: {'n_estimators': 108, 'learning_rate': 0.03780495984664625, 'max_depth': 9, 'num_leaves': 58, 'min_child_samples': 25, 'subsample': 0.9336939207444835, 'colsample_bytree': 0.6261069519815493}. Best is trial 23 with value: 0.9310344827586207.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 23. Best value: 0.931034:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 48/50 [00:51<00:02,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 18:56:56,488] Trial 47 finished with value: 0.6229885057471265 and parameters: {'n_estimators': 126, 'learning_rate': 0.10311678878046253, 'max_depth': 10, 'num_leaves': 52, 'min_child_samples': 23, 'subsample': 0.9169590804649255, 'colsample_bytree': 0.7480113330906584}. Best is trial 23 with value: 0.9310344827586207.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 23. Best value: 0.931034:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 49/50 [00:52<00:01,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 18:56:57,468] Trial 48 finished with value: 0.8763218390804598 and parameters: {'n_estimators': 113, 'learning_rate': 0.022434961238292944, 'max_depth': 8, 'num_leaves': 62, 'min_child_samples': 35, 'subsample': 0.9079749918497606, 'colsample_bytree': 0.7783721326586229}. Best is trial 23 with value: 0.9310344827586207.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 23. Best value: 0.931034: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:53<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 18:56:58,566] Trial 49 finished with value: 0.9172413793103449 and parameters: {'n_estimators': 128, 'learning_rate': 0.010455705284692135, 'max_depth': 10, 'num_leaves': 45, 'min_child_samples': 26, 'subsample': 0.8855321732976328, 'colsample_bytree': 0.7170246110540526}. Best is trial 23 with value: 0.9310344827586207.\n",
      "Fold 1: Accuracy=0.8483, Precision=1.0000, Recall=0.2414, F1=0.3889, Threshold=0.50\n",
      "Fold 2: Accuracy=0.8621, Precision=1.0000, Recall=0.3103, F1=0.4737, Threshold=0.50\n",
      "Fold 3: Accuracy=0.8759, Precision=0.9231, Recall=0.4138, F1=0.5714, Threshold=0.50\n",
      "Fold 4: Accuracy=0.8552, Precision=0.7647, Recall=0.4333, F1=0.5532, Threshold=0.50\n",
      "Fold 5: Accuracy=0.8611, Precision=1.0000, Recall=0.3103, F1=0.4737, Threshold=0.50\n",
      "\n",
      "--- Final LightGBM Optimized ---\n",
      "Mean Accuracy : 0.8605\n",
      "Mean Precision: 0.9376\n",
      "Mean Recall   : 0.3418\n",
      "Mean F1 Score : 0.4922\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import optuna\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "# Step 1: Prepare data\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag', 'Predicted Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# Check constant columns\n",
    "constant_cols = [col for col in X.columns if X[col].nunique() <= 1]\n",
    "if constant_cols:\n",
    "    print(\"Warning: Constant columns detected:\", constant_cols)\n",
    "\n",
    "# Step 2: Column types\n",
    "categorical_cols = ['Gender', 'Religion', 'Branch', 'Section-1', 'Section-2', 'Section-3']\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Step 3: Preprocessor\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', drop='if_binary', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# Step 4: Classifier wrapper for threshold tuning\n",
    "class ThresholdLGBMClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, **params):\n",
    "        self.model = LGBMClassifier(**params)\n",
    "        self.threshold = 0.5\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.model.fit(X, y)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        probas = self.model.predict_proba(X)[:, 1]\n",
    "        return (probas >= self.threshold).astype(int)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return self.model.predict_proba(X)\n",
    "\n",
    "# Step 5: Objective function for Optuna\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 300),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.15),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 20, 80),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 10, 50),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 1.0),\n",
    "        \"class_weight\": \"balanced\",\n",
    "        \"random_state\": 42,\n",
    "        \"verbose\": -1\n",
    "    }\n",
    "\n",
    "    model = ThresholdLGBMClassifier(**params)\n",
    "    pipeline = Pipeline([('prep', preprocessor), ('clf', model)])\n",
    "    \n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    recalls = []\n",
    "\n",
    "    for train_idx, val_idx in cv.split(X, y):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        probas = pipeline.predict_proba(X_val)[:, 1]\n",
    "\n",
    "        # Find best threshold to maximize recall >= 0.85\n",
    "        best_recall, best_thresh = 0, 0.5\n",
    "        for thresh in np.arange(0.3, 0.8, 0.02):\n",
    "            preds = (probas >= thresh).astype(int)\n",
    "            rec = recall_score(y_val, preds)\n",
    "            if rec > best_recall:\n",
    "                best_recall, best_thresh = rec, thresh\n",
    "\n",
    "        model.threshold = best_thresh\n",
    "        preds = (probas >= best_thresh).astype(int)\n",
    "\n",
    "        recalls.append(recall_score(y_val, preds))\n",
    "\n",
    "    return np.mean(recalls)\n",
    "\n",
    "# Step 6: Tune with Optuna\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=50, show_progress_bar=True)\n",
    "best_params = study.best_trial.params\n",
    "\n",
    "# Step 7: Final Evaluation\n",
    "model = ThresholdLGBMClassifier(**best_params)\n",
    "pipeline = Pipeline([('prep', preprocessor), ('clf', model)])\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    probas = pipeline.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    # Best threshold for this fold\n",
    "    best_thresh, best_f1 = 0.5, 0\n",
    "    for thresh in np.arange(0.3, 0.8, 0.01):\n",
    "        preds = (probas >= thresh).astype(int)\n",
    "        rec = recall_score(y_val, preds)\n",
    "        prec = precision_score(y_val, preds, zero_division=0)\n",
    "        f1_val = f1_score(y_val, preds)\n",
    "        if rec >= 0.85 and prec > 0.5 and f1_val > best_f1:\n",
    "            best_f1, best_thresh = f1_val, thresh\n",
    "\n",
    "    model.threshold = best_thresh\n",
    "    y_pred = pipeline.predict(X_val)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}, F1={f1:.4f}, Threshold={best_thresh:.2f}\")\n",
    "\n",
    "# Final metrics\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "print(\"\\n--- Final LightGBM Optimized ---\")\n",
    "print(f\"Mean Accuracy : {mean_acc:.4f}\")\n",
    "print(f\"Mean Precision: {mean_prec:.4f}\")\n",
    "print(f\"Mean Recall   : {mean_rec:.4f}\")\n",
    "print(f\"Mean F1 Score : {mean_f1:.4f}\")\n",
    "\n",
    "# CSV logging\n",
    "model_name = 'LightGBM-Optuna-Threshold'\n",
    "model_desc = 'Optuna+ThresholdTuning+5Fold'\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "result_df = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "result_df.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec73b938",
   "metadata": {},
   "source": [
    "# CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e8057ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.8690, Precision=0.7083,  Recall=0.5862, F1=0.6415\n",
      "Fold 2: Accuracy=0.8483, Precision=0.7059,  Recall=0.4138, F1=0.5217\n",
      "Fold 3: Accuracy=0.8414, Precision=0.5938,  Recall=0.6552, F1=0.6230\n",
      "Fold 4: Accuracy=0.8483, Precision=0.6250,  Recall=0.6667, F1=0.6452\n",
      "Fold 5: Accuracy=0.8750, Precision=0.6774,  Recall=0.7241, F1=0.7000\n",
      "\n",
      "--- CatBoost Summary ---\n",
      "Mean Accuracy : 0.8564\n",
      "Mean Precision: 0.6621\n",
      "Mean Recall   : 0.6092\n",
      "Mean F1 Score : 0.6263\n",
      "\n",
      "CSV Row Format:\n",
      "CatBoost-Balanced,OneHot+Scaler+5Fold-Stratified+VerboseOff,0.8564,0.6621,0.6092,0.6263\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Step 1: Prepare data\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag', 'Predicted Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# Optional: Check constant columns\n",
    "constant_cols = [col for col in X.columns if X[col].nunique() <= 1]\n",
    "if constant_cols:\n",
    "    print(\"Warning: Constant columns detected:\", constant_cols)\n",
    "\n",
    "# Step 2: Column categories\n",
    "categorical_cols = ['Gender', 'Religion', 'Branch', 'Section-1', 'Section-2', 'Section-3']\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Step 3: Preprocessing\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', drop='if_binary', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# Step 4: CatBoost Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('model', CatBoostClassifier(\n",
    "        iterations=100,\n",
    "        learning_rate=0.1,\n",
    "        depth=6,\n",
    "        auto_class_weights='Balanced',\n",
    "        verbose=0,  # suppress CatBoost internal logs\n",
    "        random_seed=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Step 5: Cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_val)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f},  Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# Step 6: Averages\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# Step 7: Model description\n",
    "model_name = 'CatBoost-Balanced'\n",
    "model_desc = 'OneHot+Scaler+5Fold-Stratified+VerboseOff'\n",
    "\n",
    "# Console summary\n",
    "print(\"\\n--- CatBoost Summary ---\")\n",
    "print(f\"Mean Accuracy : {mean_acc:.4f}\")\n",
    "print(f\"Mean Precision: {mean_prec:.4f}\")\n",
    "print(f\"Mean Recall   : {mean_rec:.4f}\")\n",
    "print(f\"Mean F1 Score : {mean_f1:.4f}\")\n",
    "\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# Step 8: Save to CSV\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "result_df = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "\n",
    "result_df.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "73991d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.8759, Precision=0.7895,  Recall=0.5172, F1=0.6250\n",
      "Fold 2: Accuracy=0.8483, Precision=0.7059,  Recall=0.4138, F1=0.5217\n",
      "Fold 3: Accuracy=0.8345, Precision=0.5806,  Recall=0.6207, F1=0.6000\n",
      "Fold 4: Accuracy=0.8414, Precision=0.6207,  Recall=0.6000, F1=0.6102\n",
      "Fold 5: Accuracy=0.8681, Precision=0.7273,  Recall=0.5517, F1=0.6275\n",
      "\n",
      "--- CatBoost Tuned Summary ---\n",
      "Mean Accuracy : 0.8536\n",
      "Mean Precision: 0.6848\n",
      "Mean Recall   : 0.5407\n",
      "Mean F1 Score : 0.5969\n",
      "\n",
      "CSV Row Format:\n",
      "CatBoost-Tuned,OneHot+Scaler+5Fold+Depth8+LR0.05+BagTemp1.0,0.8536,0.6848,0.5407,0.5969\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Step 1: Prepare data\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag', 'Predicted Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# Optional: Check constant columns\n",
    "constant_cols = [col for col in X.columns if X[col].nunique() <= 1]\n",
    "if constant_cols:\n",
    "    print(\"Warning: Constant columns detected:\", constant_cols)\n",
    "\n",
    "# Step 2: Column categories\n",
    "categorical_cols = ['Gender', 'Religion', 'Branch', 'Section-1', 'Section-2', 'Section-3']\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Step 3: Preprocessing\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', drop='if_binary', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# Step 4: Tuned CatBoost Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('model', CatBoostClassifier(\n",
    "        iterations=300,\n",
    "        learning_rate=0.05,\n",
    "        depth=8,\n",
    "        l2_leaf_reg=5,\n",
    "        border_count=128,\n",
    "        bagging_temperature=1.0,\n",
    "        auto_class_weights='Balanced',\n",
    "        random_seed=42,\n",
    "        verbose=0\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Step 5: Cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_val)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f},  Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# Step 6: Averages\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# Step 7: Model description\n",
    "model_name = 'CatBoost-Tuned'\n",
    "model_desc = 'OneHot+Scaler+5Fold+Depth8+LR0.05+BagTemp1.0'\n",
    "\n",
    "# Console summary\n",
    "print(\"\\n--- CatBoost Tuned Summary ---\")\n",
    "print(f\"Mean Accuracy : {mean_acc:.4f}\")\n",
    "print(f\"Mean Precision: {mean_prec:.4f}\")\n",
    "print(f\"Mean Recall   : {mean_rec:.4f}\")\n",
    "print(f\"Mean F1 Score : {mean_f1:.4f}\")\n",
    "\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# Step 8: Save to CSV\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "result_df = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "\n",
    "result_df.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "507c491c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.8828, Precision=0.8750,  Recall=0.4828, F1=0.6222\n",
      "Fold 2: Accuracy=0.8414, Precision=0.6875,  Recall=0.3793, F1=0.4889\n",
      "Fold 3: Accuracy=0.8483, Precision=0.6296,  Recall=0.5862, F1=0.6071\n",
      "Fold 4: Accuracy=0.8552, Precision=0.6667,  Recall=0.6000, F1=0.6316\n",
      "Fold 5: Accuracy=0.8472, Precision=0.6667,  Recall=0.4828, F1=0.5600\n",
      "\n",
      "--- CatBoost Aggressive Summary ---\n",
      "Mean Accuracy : 0.8550\n",
      "Mean Precision: 0.7051\n",
      "Mean Recall   : 0.5062\n",
      "Mean F1 Score : 0.5820\n",
      "\n",
      "CSV Row Format:\n",
      "CatBoost-Aggressive,OneHot+Scaler+500Iter+LR0.03+Depth10+Bag0.25,0.8550,0.7051,0.5062,0.5820\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Prepare data\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag', 'Predicted Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# Optional: Check constant columns\n",
    "constant_cols = [col for col in X.columns if X[col].nunique() <= 1]\n",
    "if constant_cols:\n",
    "    print(\"Warning: Constant columns detected:\", constant_cols)\n",
    "\n",
    "# Define column types\n",
    "categorical_cols = ['Gender', 'Religion', 'Branch', 'Section-1', 'Section-2', 'Section-3']\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Preprocessing\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', drop='if_binary', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# Aggressively Tuned CatBoost\n",
    "pipeline = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('model', CatBoostClassifier(\n",
    "        iterations=500,\n",
    "        learning_rate=0.03,\n",
    "        depth=10,\n",
    "        l2_leaf_reg=3,\n",
    "        border_count=128,\n",
    "        bagging_temperature=0.25,\n",
    "        auto_class_weights='Balanced',\n",
    "        random_seed=42,\n",
    "        verbose=0\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_val)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f},  Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# Averages\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# Description\n",
    "model_name = 'CatBoost-Aggressive'\n",
    "model_desc = 'OneHot+Scaler+500Iter+LR0.03+Depth10+Bag0.25'\n",
    "\n",
    "print(\"\\n--- CatBoost Aggressive Summary ---\")\n",
    "print(f\"Mean Accuracy : {mean_acc:.4f}\")\n",
    "print(f\"Mean Precision: {mean_prec:.4f}\")\n",
    "print(f\"Mean Recall   : {mean_rec:.4f}\")\n",
    "print(f\"Mean F1 Score : {mean_f1:.4f}\")\n",
    "\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# Save to CSV\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "result_df = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "\n",
    "result_df.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0a769b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.8897, Precision=0.7826, Recall=0.6207, F1=0.6923\n",
      "Fold 2: Accuracy=0.8621, Precision=0.7143, Recall=0.5172, F1=0.6000\n",
      "Fold 3: Accuracy=0.8138, Precision=0.5263, Recall=0.6897, F1=0.5970\n",
      "Fold 4: Accuracy=0.8621, Precision=0.6471, Recall=0.7333, F1=0.6875\n",
      "Fold 5: Accuracy=0.8819, Precision=0.7000, Recall=0.7241, F1=0.7119\n",
      "\n",
      "--- CatBoost Bayesian Tuning Summary ---\n",
      "Mean Accuracy : 0.8619\n",
      "Mean Precision: 0.6741\n",
      "Mean Recall   : 0.6570\n",
      "Mean F1 Score : 0.6577\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer\n",
    "\n",
    "# Prepare data\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag', 'Predicted Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# Constant column check\n",
    "constant_cols = [col for col in X.columns if X[col].nunique() <= 1]\n",
    "if constant_cols:\n",
    "    print(\"Warning: Constant columns detected:\", constant_cols)\n",
    "\n",
    "# Categorical and numerical columns\n",
    "categorical_cols = ['Gender', 'Religion', 'Branch', 'Section-1', 'Section-2', 'Section-3']\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Preprocessing\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', drop='if_binary', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# Define CatBoost with default settings (will be tuned)\n",
    "cat_model = CatBoostClassifier(\n",
    "    auto_class_weights='Balanced',\n",
    "    random_seed=42,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Create pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('model', cat_model)\n",
    "])\n",
    "\n",
    "# Define parameter search space\n",
    "param_space = {\n",
    "    'model__iterations': Integer(300, 800),\n",
    "    'model__learning_rate': Real(0.01, 0.2, prior='log-uniform'),\n",
    "    'model__depth': Integer(4, 10),\n",
    "    'model__l2_leaf_reg': Real(1, 10),\n",
    "    'model__bagging_temperature': Real(0, 1.0),\n",
    "    'model__border_count': Integer(32, 254)\n",
    "}\n",
    "\n",
    "# Setup Bayesian optimization with 5-fold stratified CV\n",
    "opt = BayesSearchCV(\n",
    "    estimator=pipeline,\n",
    "    search_spaces=param_space,\n",
    "    scoring='accuracy',\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    n_iter=32,\n",
    "    n_jobs=-1,\n",
    "    verbose=0,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the search\n",
    "opt.fit(X, y)\n",
    "\n",
    "# Extract best pipeline and evaluate manually\n",
    "best_pipeline = opt.best_estimator_\n",
    "\n",
    "# Manual 5-Fold Eval\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "acc_list, prec_list, rec_list, f1_list = [], [], [], []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    best_pipeline.fit(X_train, y_train)\n",
    "    y_pred = best_pipeline.predict(X_val)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    acc_list.append(acc)\n",
    "    prec_list.append(prec)\n",
    "    rec_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# Averages\n",
    "mean_acc = np.mean(acc_list)\n",
    "mean_prec = np.mean(prec_list)\n",
    "mean_rec = np.mean(rec_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "model_name = 'CatBoost-BayesTuned'\n",
    "model_desc = 'OneHot+Scaler+BayesSearch+5Fold'\n",
    "\n",
    "print(\"\\n--- CatBoost Bayesian Tuning Summary ---\")\n",
    "print(f\"Mean Accuracy : {mean_acc:.4f}\")\n",
    "print(f\"Mean Precision: {mean_prec:.4f}\")\n",
    "print(f\"Mean Recall   : {mean_rec:.4f}\")\n",
    "print(f\"Mean F1 Score : {mean_f1:.4f}\")\n",
    "\n",
    "# Save to CSV\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "result_df = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "result_df.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395d5dd5",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "686a2696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.8069, Precision=0.5143, Recall=0.6207, F1=0.5625\n",
      "Fold 2: Accuracy=0.8207, Precision=0.5556, Recall=0.5172, F1=0.5357\n",
      "Fold 3: Accuracy=0.7655, Precision=0.4444, Recall=0.6897, F1=0.5405\n",
      "Fold 4: Accuracy=0.7793, Precision=0.4783, Recall=0.7333, F1=0.5789\n",
      "Fold 5: Accuracy=0.7222, Precision=0.3878, Recall=0.6552, F1=0.4872\n",
      "\n",
      "--- SVM (RBF) Summary ---\n",
      "Name                          : SVC-RBF-Pipeline\n",
      "Description                   : OneHot+Scaler+5Fold+Balanced\n",
      "Accuracy                      : 0.7789\n",
      "Precision                     : 0.4761\n",
      "Recall                        : 0.6432\n",
      "F1 Score                      : 0.5410\n",
      "\n",
      "CSV Row Format:\n",
      "SVC-RBF-Pipeline,OneHot+Scaler+5Fold+Balanced,0.7789,0.4761,0.6432,0.5410\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Data setup\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag', 'Predicted Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# Identify column types\n",
    "categorical_cols = ['Gender', 'Religion', 'Branch', 'Section-1', 'Section-2', 'Section-3']\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Preprocessing\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', drop='if_binary', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# SVM model inside pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('model', SVC(kernel='rbf', class_weight='balanced', probability=True, random_state=42))\n",
    "])\n",
    "\n",
    "# CV setup\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n",
    "\n",
    "# Cross-validation loop\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_val)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# Mean scores\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# Model info\n",
    "model_name = 'SVC-RBF-Pipeline'\n",
    "model_desc = 'OneHot+Scaler+5Fold+Balanced'\n",
    "\n",
    "print(\"\\n--- SVM (RBF) Summary ---\")\n",
    "print(f\"{'Name':<30}: {model_name}\")\n",
    "print(f\"{'Description':<30}: {model_desc}\")\n",
    "print(f\"{'Accuracy':<30}: {mean_acc:.4f}\")\n",
    "print(f\"{'Precision':<30}: {mean_prec:.4f}\")\n",
    "print(f\"{'Recall':<30}: {mean_rec:.4f}\")\n",
    "print(f\"{'F1 Score':<30}: {mean_f1:.4f}\")\n",
    "\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# Save to CSV\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "new_row = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "\n",
    "new_row.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ac3d4ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.8414, Precision=0.6000, Recall=0.6207, F1=0.6102\n",
      "Fold 2: Accuracy=0.8414, Precision=0.6364, Recall=0.4828, F1=0.5490\n",
      "Fold 3: Accuracy=0.8552, Precision=0.6429, Recall=0.6207, F1=0.6316\n",
      "Fold 4: Accuracy=0.8069, Precision=0.5357, Recall=0.5000, F1=0.5172\n",
      "Fold 5: Accuracy=0.8333, Precision=0.5862, Recall=0.5862, F1=0.5862\n",
      "\n",
      "--- Tuned SVM (RBF) Summary ---\n",
      "Mean Accuracy : 0.8356\n",
      "Mean Precision: 0.6002\n",
      "Mean Recall   : 0.5621\n",
      "Mean F1 Score : 0.5788\n",
      "\n",
      "CSV Row Format:\n",
      "SVC-BayesTuned,OneHot+Scaler+BayesSearch+RBF+Balanced,0.8356,0.6002,0.5621,0.5788\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Step 1: Data setup\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag', 'Predicted Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# Step 2: Column types\n",
    "categorical_cols = ['Gender', 'Religion', 'Branch', 'Section-1', 'Section-2', 'Section-3']\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Step 3: Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', drop='if_binary', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# Step 4: SVC pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('model', SVC(probability=True, random_state=42))\n",
    "])\n",
    "\n",
    "# Step 5: Define search space\n",
    "param_space = {\n",
    "    'model__C': Real(0.1, 100, prior='log-uniform'),\n",
    "    'model__gamma': Real(1e-4, 1.0, prior='log-uniform'),\n",
    "    'model__kernel': ['rbf'],\n",
    "    'model__class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "# Step 6: Bayesian optimization\n",
    "opt = BayesSearchCV(\n",
    "    estimator=pipeline,\n",
    "    search_spaces=param_space,\n",
    "    scoring='accuracy',\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    n_iter=32,\n",
    "    n_jobs=-1,\n",
    "    verbose=0,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Step 7: Fit optimizer\n",
    "opt.fit(X, y)\n",
    "best_pipeline = opt.best_estimator_\n",
    "\n",
    "# Step 8: Manual evaluation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "acc_list, prec_list, rec_list, f1_list = [], [], [], []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    best_pipeline.fit(X_train, y_train)\n",
    "    y_pred = best_pipeline.predict(X_val)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    acc_list.append(acc)\n",
    "    prec_list.append(prec)\n",
    "    rec_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# Step 9: Aggregate metrics\n",
    "mean_acc = np.mean(acc_list)\n",
    "mean_prec = np.mean(prec_list)\n",
    "mean_rec = np.mean(rec_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "model_name = 'SVC-BayesTuned'\n",
    "model_desc = 'OneHot+Scaler+BayesSearch+RBF+Balanced'\n",
    "\n",
    "print(\"\\n--- Tuned SVM (RBF) Summary ---\")\n",
    "print(f\"Mean Accuracy : {mean_acc:.4f}\")\n",
    "print(f\"Mean Precision: {mean_prec:.4f}\")\n",
    "print(f\"Mean Recall   : {mean_rec:.4f}\")\n",
    "print(f\"Mean F1 Score : {mean_f1:.4f}\")\n",
    "\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# Step 10: Save to CSV\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "result_df = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "\n",
    "result_df.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "51a6935a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.8414, Precision=0.6000, Recall=0.6207, F1=0.6102\n",
      "Fold 2: Accuracy=0.8414, Precision=0.6364, Recall=0.4828, F1=0.5490\n",
      "Fold 3: Accuracy=0.8552, Precision=0.6429, Recall=0.6207, F1=0.6316\n",
      "Fold 4: Accuracy=0.8069, Precision=0.5357, Recall=0.5000, F1=0.5172\n",
      "Fold 5: Accuracy=0.8333, Precision=0.5862, Recall=0.5862, F1=0.5862\n",
      "\n",
      "--- Tuned SVM (RBF) Summary ---\n",
      "Mean Accuracy : 0.8356\n",
      "Mean Precision: 0.6002\n",
      "Mean Recall   : 0.5621\n",
      "Mean F1 Score : 0.5788\n",
      "\n",
      "CSV Row Format:\n",
      "SVC-BayesTuned,OneHot+Scaler+BayesSearch+RBF+Balanced,0.8356,0.6002,0.5621,0.5788\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Step 1: Data setup\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag', 'Predicted Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# Step 2: Column types\n",
    "categorical_cols = ['Gender', 'Religion', 'Branch', 'Section-1', 'Section-2', 'Section-3']\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Step 3: Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', drop='if_binary', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# Step 4: SVC pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('model', SVC(probability=True, random_state=42))\n",
    "])\n",
    "\n",
    "# Step 5: Define search space\n",
    "param_space = {\n",
    "    'model__C': Real(0.1, 100, prior='log-uniform'),\n",
    "    'model__gamma': Real(1e-4, 1.0, prior='log-uniform'),\n",
    "    'model__kernel': ['rbf'],\n",
    "    'model__class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "# Step 6: Bayesian optimization\n",
    "opt = BayesSearchCV(\n",
    "    estimator=pipeline,\n",
    "    search_spaces=param_space,\n",
    "    scoring='accuracy',\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    n_iter=32,\n",
    "    n_jobs=-1,\n",
    "    verbose=0,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Step 7: Fit optimizer\n",
    "opt.fit(X, y)\n",
    "best_pipeline = opt.best_estimator_\n",
    "\n",
    "# Step 8: Manual evaluation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "acc_list, prec_list, rec_list, f1_list = [], [], [], []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    best_pipeline.fit(X_train, y_train)\n",
    "    y_pred = best_pipeline.predict(X_val)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    acc_list.append(acc)\n",
    "    prec_list.append(prec)\n",
    "    rec_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# Step 9: Aggregate metrics\n",
    "mean_acc = np.mean(acc_list)\n",
    "mean_prec = np.mean(prec_list)\n",
    "mean_rec = np.mean(rec_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "model_name = 'SVC-BayesTuned'\n",
    "model_desc = 'OneHot+Scaler+BayesSearch+RBF+Balanced'\n",
    "\n",
    "print(\"\\n--- Tuned SVM (RBF) Summary ---\")\n",
    "print(f\"Mean Accuracy : {mean_acc:.4f}\")\n",
    "print(f\"Mean Precision: {mean_prec:.4f}\")\n",
    "print(f\"Mean Recall   : {mean_rec:.4f}\")\n",
    "print(f\"Mean F1 Score : {mean_f1:.4f}\")\n",
    "\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# Step 10: Save to CSV\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "result_df = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "\n",
    "result_df.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b53f9c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.2000, Precision=0.2000, Recall=1.0000, F1=0.3333\n",
      "Fold 2: Accuracy=0.2000, Precision=0.2000, Recall=1.0000, F1=0.3333\n",
      "Fold 3: Accuracy=0.2000, Precision=0.2000, Recall=1.0000, F1=0.3333\n",
      "Fold 4: Accuracy=0.2069, Precision=0.2069, Recall=1.0000, F1=0.3429\n",
      "Fold 5: Accuracy=0.2014, Precision=0.2014, Recall=1.0000, F1=0.3353\n",
      "\n",
      "--- Tuned SVM (RBF) Summary ---\n",
      "Mean Accuracy : 0.2017\n",
      "Mean Precision: 0.2017\n",
      "Mean Recall   : 1.0000\n",
      "Mean F1 Score : 0.3356\n",
      "\n",
      "CSV Row Format:\n",
      "SVC-BayesTuned-Recall,OneHot+Scaler+BayesSearch+RBF+Balanced+RecallOpt,0.2017,0.2017,1.0000,0.3356\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Step 1: Data setup\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag', 'Predicted Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# Step 2: Column types\n",
    "categorical_cols = ['Gender', 'Religion', 'Branch', 'Section-1', 'Section-2', 'Section-3']\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Step 3: Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', drop='if_binary', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# Step 4: SVC pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('model', SVC(probability=True, random_state=42))\n",
    "])\n",
    "\n",
    "# Step 5: Define search space for BayesSearchCV\n",
    "param_space = {\n",
    "    'model__C': Real(0.1, 100, prior='log-uniform'),\n",
    "    'model__gamma': Real(1e-4, 1.0, prior='log-uniform'),\n",
    "    'model__kernel': ['rbf'],\n",
    "    'model__class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "# Step 6: Bayesian optimization focused on RECALL\n",
    "opt = BayesSearchCV(\n",
    "    estimator=pipeline,\n",
    "    search_spaces=param_space,\n",
    "    scoring='recall',  # prioritize recall\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    n_iter=32,\n",
    "    n_jobs=-1,\n",
    "    verbose=0,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Step 7: Fit optimizer\n",
    "opt.fit(X, y)\n",
    "best_pipeline = opt.best_estimator_\n",
    "\n",
    "# Step 8: Manual evaluation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "acc_list, prec_list, rec_list, f1_list = [], [], [], []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    best_pipeline.fit(X_train, y_train)\n",
    "    y_pred = best_pipeline.predict(X_val)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    acc_list.append(acc)\n",
    "    prec_list.append(prec)\n",
    "    rec_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# Step 9: Aggregate metrics\n",
    "mean_acc = np.mean(acc_list)\n",
    "mean_prec = np.mean(prec_list)\n",
    "mean_rec = np.mean(rec_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "model_name = 'SVC-BayesTuned-Recall'\n",
    "model_desc = 'OneHot+Scaler+BayesSearch+RBF+Balanced+RecallOpt'\n",
    "\n",
    "print(\"\\n--- Tuned SVM (RBF) Summary ---\")\n",
    "print(f\"Mean Accuracy : {mean_acc:.4f}\")\n",
    "print(f\"Mean Precision: {mean_prec:.4f}\")\n",
    "print(f\"Mean Recall   : {mean_rec:.4f}\")\n",
    "print(f\"Mean F1 Score : {mean_f1:.4f}\")\n",
    "\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# Step 10: Save to CSV\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "result_df = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "\n",
    "result_df.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09e7176",
   "metadata": {},
   "source": [
    "# Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ebbca60a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.8828, Precision=0.8750, Recall=0.4828, F1=0.6222\n",
      "Fold 2: Accuracy=0.8552, Precision=0.7857, Recall=0.3793, F1=0.5116\n",
      "Fold 3: Accuracy=0.8759, Precision=0.7391, Recall=0.5862, F1=0.6538\n",
      "Fold 4: Accuracy=0.8759, Precision=0.8000, Recall=0.5333, F1=0.6400\n",
      "Fold 5: Accuracy=0.8472, Precision=0.7333, Recall=0.3793, F1=0.5000\n",
      "\n",
      "--- Model Summary ---\n",
      "Name                          : Bagging-DecisionTree\n",
      "Description                   : Bagging-with-Preprocessing-5Fold\n",
      "Accuracy                      : 0.8674\n",
      "Precision                     : 0.7866\n",
      "Recall                        : 0.4722\n",
      "F1 Score                      : 0.5855\n",
      "\n",
      "CSV Row Format:\n",
      "Bagging-DecisionTree,Bagging-with-Preprocessing-5Fold,0.8674,0.7866,0.4722,0.5855\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Data\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag', 'Predicted Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# Identify columns\n",
    "categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "# Preprocessor\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# Bagging Classifier pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocess', preprocessor),\n",
    "    ('model', BaggingClassifier(\n",
    "        estimator=DecisionTreeClassifier(),\n",
    "        n_estimators=50,\n",
    "        max_samples=0.8,\n",
    "        max_features=1.0,\n",
    "        bootstrap=True,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "# CV setup\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Metric storage\n",
    "accuracy_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "\n",
    "# 5-Fold Evaluation\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_val)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# Final metrics\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# Model info\n",
    "model_name = 'Bagging-DecisionTree'\n",
    "model_desc = 'Bagging-with-Preprocessing-5Fold'\n",
    "\n",
    "print(\"\\n--- Model Summary ---\")\n",
    "print(f\"{'Name':<30}: {model_name}\")\n",
    "print(f\"{'Description':<30}: {model_desc}\")\n",
    "print(f\"{'Accuracy':<30}: {mean_acc:.4f}\")\n",
    "print(f\"{'Precision':<30}: {mean_prec:.4f}\")\n",
    "print(f\"{'Recall':<30}: {mean_rec:.4f}\")\n",
    "print(f\"{'F1 Score':<30}: {mean_f1:.4f}\")\n",
    "\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# Save to CSV\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "new_row = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "new_row.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fc1f299b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.8690, Precision=0.7778, Recall=0.4828, F1=0.5957\n",
      "Fold 2: Accuracy=0.8552, Precision=0.7857, Recall=0.3793, F1=0.5116\n",
      "Fold 3: Accuracy=0.8621, Precision=0.6800, Recall=0.5862, F1=0.6296\n",
      "Fold 4: Accuracy=0.8828, Precision=0.7600, Recall=0.6333, F1=0.6909\n",
      "Fold 5: Accuracy=0.8750, Precision=0.8235, Recall=0.4828, F1=0.6087\n",
      "\n",
      "--- Final Tuned Model Summary ---\n",
      "Name                          : Bagging+DT-Tuned\n",
      "Description                   : BayesCV-Tuned-Recall-Max-5Fold\n",
      "Accuracy                      : 0.8688\n",
      "Precision                     : 0.7654\n",
      "Recall                        : 0.5129\n",
      "F1 Score                      : 0.6073\n",
      "\n",
      "CSV Row Format:\n",
      "Bagging+DT-Tuned,BayesCV-Tuned-Recall-Max-5Fold,0.8688,0.7654,0.5129,0.6073\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Data\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag', 'Predicted Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# Columns\n",
    "categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "# Preprocessor\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# Full pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocess', preprocessor),\n",
    "    ('model', BaggingClassifier(\n",
    "        estimator=DecisionTreeClassifier(),\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Parameter search space for Bagging + Decision Tree\n",
    "search_space = {\n",
    "    'model__n_estimators': Integer(10, 100),\n",
    "    'model__max_samples': Real(0.5, 1.0),\n",
    "    'model__max_features': Real(0.5, 1.0),\n",
    "    'model__estimator__max_depth': Integer(2, 20),\n",
    "    'model__estimator__min_samples_split': Integer(2, 10),\n",
    "    'model__estimator__min_samples_leaf': Integer(1, 10)\n",
    "}\n",
    "\n",
    "# BayesSearchCV setup (recall as scoring metric)\n",
    "bayes_search = BayesSearchCV(\n",
    "    estimator=pipeline,\n",
    "    search_spaces=search_space,\n",
    "    scoring=make_scorer(recall_score),\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    n_iter=30,\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Fit\n",
    "bayes_search.fit(X, y)\n",
    "\n",
    "# Best model\n",
    "best_model = bayes_search.best_estimator_\n",
    "\n",
    "# 5-Fold Evaluation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    best_model.fit(X_train, y_train)\n",
    "    y_pred = best_model.predict(X_val)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# Final metrics\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# Metadata\n",
    "model_name = 'Bagging+DT-Tuned'\n",
    "model_desc = 'BayesCV-Tuned-Recall-Max-5Fold'\n",
    "\n",
    "print(\"\\n--- Final Tuned Model Summary ---\")\n",
    "print(f\"{'Name':<30}: {model_name}\")\n",
    "print(f\"{'Description':<30}: {model_desc}\")\n",
    "print(f\"{'Accuracy':<30}: {mean_acc:.4f}\")\n",
    "print(f\"{'Precision':<30}: {mean_prec:.4f}\")\n",
    "print(f\"{'Recall':<30}: {mean_rec:.4f}\")\n",
    "print(f\"{'F1 Score':<30}: {mean_f1:.4f}\")\n",
    "\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# Save to CSV\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "new_row = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "new_row.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "83dd842e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.8690, Precision=0.7778, Recall=0.4828, F1=0.5957\n",
      "Fold 2: Accuracy=0.8552, Precision=0.7857, Recall=0.3793, F1=0.5116\n",
      "Fold 3: Accuracy=0.8621, Precision=0.6800, Recall=0.5862, F1=0.6296\n",
      "Fold 4: Accuracy=0.8828, Precision=0.7600, Recall=0.6333, F1=0.6909\n",
      "Fold 5: Accuracy=0.8750, Precision=0.8235, Recall=0.4828, F1=0.6087\n",
      "\n",
      "--- Final Tuned Model Summary ---\n",
      "Name                          : Bagging+DT-Tuned\n",
      "Description                   : BayesCV-Tuned-Recall-Max-5Fold\n",
      "Accuracy                      : 0.8688\n",
      "Precision                     : 0.7654\n",
      "Recall                        : 0.5129\n",
      "F1 Score                      : 0.6073\n",
      "\n",
      "CSV Row Format:\n",
      "Bagging+DT-Tuned,BayesCV-Tuned-Recall-Max-5Fold,0.8688,0.7654,0.5129,0.6073\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Data\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag', 'Predicted Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# Columns\n",
    "categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "# Preprocessor\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# Full pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocess', preprocessor),\n",
    "    ('model', BaggingClassifier(\n",
    "        estimator=DecisionTreeClassifier(),\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Parameter search space for Bagging + Decision Tree\n",
    "search_space = {\n",
    "    'model__n_estimators': Integer(10, 100),\n",
    "    'model__max_samples': Real(0.5, 1.0),\n",
    "    'model__max_features': Real(0.5, 1.0),\n",
    "    'model__estimator__max_depth': Integer(2, 20),\n",
    "    'model__estimator__min_samples_split': Integer(2, 10),\n",
    "    'model__estimator__min_samples_leaf': Integer(1, 10)\n",
    "}\n",
    "\n",
    "# BayesSearchCV setup (recall as scoring metric)\n",
    "bayes_search = BayesSearchCV(\n",
    "    estimator=pipeline,\n",
    "    search_spaces=search_space,\n",
    "    scoring=make_scorer(recall_score),\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    n_iter=30,\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Fit\n",
    "bayes_search.fit(X, y)\n",
    "\n",
    "# Best model\n",
    "best_model = bayes_search.best_estimator_\n",
    "\n",
    "# 5-Fold Evaluation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    best_model.fit(X_train, y_train)\n",
    "    y_pred = best_model.predict(X_val)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# Final metrics\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# Metadata\n",
    "model_name = 'Bagging+DT-Tuned'\n",
    "model_desc = 'BayesCV-Tuned-Recall-Max-5Fold'\n",
    "\n",
    "print(\"\\n--- Final Tuned Model Summary ---\")\n",
    "print(f\"{'Name':<30}: {model_name}\")\n",
    "print(f\"{'Description':<30}: {model_desc}\")\n",
    "print(f\"{'Accuracy':<30}: {mean_acc:.4f}\")\n",
    "print(f\"{'Precision':<30}: {mean_prec:.4f}\")\n",
    "print(f\"{'Recall':<30}: {mean_rec:.4f}\")\n",
    "print(f\"{'F1 Score':<30}: {mean_f1:.4f}\")\n",
    "\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# Save to CSV\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "new_row = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "new_row.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "62fa9965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.8345, Precision=0.5610, Recall=0.7931, F1=0.6571\n",
      "Fold 2: Accuracy=0.8000, Precision=0.5000, Recall=0.7241, F1=0.5915\n",
      "Fold 3: Accuracy=0.7379, Precision=0.4211, Recall=0.8276, F1=0.5581\n",
      "Fold 4: Accuracy=0.7586, Precision=0.4576, Recall=0.9000, F1=0.6067\n",
      "Fold 5: Accuracy=0.7431, Precision=0.4231, Recall=0.7586, F1=0.5432\n",
      "\n",
      "--- Final Tuned Bagging Model Summary ---\n",
      "Name                          : Bagging+DT-Balanced-Tuned\n",
      "Description                   : BaggingDT+Balanced+BayesCV-Recall\n",
      "Accuracy                      : 0.7748\n",
      "Precision                     : 0.4725\n",
      "Recall                        : 0.8007\n",
      "F1 Score                      : 0.5914\n",
      "\n",
      "CSV Row Format:\n",
      "Bagging+DT-Balanced-Tuned,BaggingDT+Balanced+BayesCV-Recall,0.7748,0.4725,0.8007,0.5914\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- Data Setup ---\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag', 'Predicted Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "# --- Preprocessing ---\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# --- Pipeline ---\n",
    "pipeline = Pipeline([\n",
    "    ('preprocess', preprocessor),\n",
    "    ('model', BaggingClassifier(\n",
    "        estimator=DecisionTreeClassifier(class_weight='balanced'),\n",
    "        n_estimators=50,\n",
    "        max_samples=0.8,\n",
    "        max_features=1.0,\n",
    "        bootstrap=True,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "# --- Search Space ---\n",
    "search_space = {\n",
    "    'model__n_estimators': Integer(20, 100),\n",
    "    'model__max_samples': Real(0.4, 1.0),\n",
    "    'model__max_features': Real(0.4, 1.0),\n",
    "    'model__estimator__max_depth': Integer(3, 20),\n",
    "    'model__estimator__min_samples_split': Integer(2, 15),\n",
    "    'model__estimator__min_samples_leaf': Integer(1, 10)\n",
    "}\n",
    "\n",
    "# --- Tuning ---\n",
    "bayes_search = BayesSearchCV(\n",
    "    estimator=pipeline,\n",
    "    search_spaces=search_space,\n",
    "    scoring=make_scorer(recall_score),\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    n_iter=30,\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# --- Fit ---\n",
    "bayes_search.fit(X, y)\n",
    "best_model = bayes_search.best_estimator_\n",
    "\n",
    "# --- Cross-Validation Evaluation ---\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    best_model.fit(X_train, y_train)\n",
    "    y_pred = best_model.predict(X_val)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# --- Final Metrics ---\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# --- Output ---\n",
    "model_name = 'Bagging+DT-Balanced-Tuned'\n",
    "model_desc = 'BaggingDT+Balanced+BayesCV-Recall'\n",
    "\n",
    "print(\"\\n--- Final Tuned Bagging Model Summary ---\")\n",
    "print(f\"{'Name':<30}: {model_name}\")\n",
    "print(f\"{'Description':<30}: {model_desc}\")\n",
    "print(f\"{'Accuracy':<30}: {mean_acc:.4f}\")\n",
    "print(f\"{'Precision':<30}: {mean_prec:.4f}\")\n",
    "print(f\"{'Recall':<30}: {mean_rec:.4f}\")\n",
    "print(f\"{'F1 Score':<30}: {mean_f1:.4f}\")\n",
    "\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# --- Save to CSV ---\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "new_row = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "new_row.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65502245",
   "metadata": {},
   "source": [
    "# AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b4dab5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.8690, Precision=0.8125, Recall=0.4483, F1=0.5778\n",
      "Fold 2: Accuracy=0.8690, Precision=0.9167, Recall=0.3793, F1=0.5366\n",
      "Fold 3: Accuracy=0.8690, Precision=0.7273, Recall=0.5517, F1=0.6275\n",
      "Fold 4: Accuracy=0.8552, Precision=0.6957, Recall=0.5333, F1=0.6038\n",
      "Fold 5: Accuracy=0.8819, Precision=0.7500, Recall=0.6207, F1=0.6792\n",
      "\n",
      "--- Model Summary ---\n",
      "Name                          : AdaBoostClassifier\n",
      "Description                   : AdaBoost-5Fold-Preprocessed\n",
      "Accuracy                      : 0.8688\n",
      "Precision                     : 0.7804\n",
      "Recall                        : 0.5067\n",
      "F1 Score                      : 0.6050\n",
      "\n",
      "CSV Row Format:\n",
      "AdaBoostClassifier,AdaBoost-5Fold-Preprocessed,0.8688,0.7804,0.5067,0.6050\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Data setup\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag', 'Predicted Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# Identify categorical and numerical columns\n",
    "categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "# Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols),\n",
    "        ('num', StandardScaler(), numerical_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# AdaBoost model pipeline\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocess', preprocessor),\n",
    "    ('classifier', AdaBoostClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# CV setup\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Metric storage\n",
    "accuracy_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "\n",
    "# 5-Fold Evaluation\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# Final metrics\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# Model info\n",
    "model_name = 'AdaBoostClassifier'\n",
    "model_desc = 'AdaBoost-5Fold-Preprocessed'\n",
    "\n",
    "# Print formatted summary\n",
    "print(\"\\n--- Model Summary ---\")\n",
    "print(f\"{'Name':<30}: {model_name}\")\n",
    "print(f\"{'Description':<30}: {model_desc}\")\n",
    "print(f\"{'Accuracy':<30}: {mean_acc:.4f}\")\n",
    "print(f\"{'Precision':<30}: {mean_prec:.4f}\")\n",
    "print(f\"{'Recall':<30}: {mean_rec:.4f}\")\n",
    "print(f\"{'F1 Score':<30}: {mean_f1:.4f}\")\n",
    "\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# Save to CSV (append row, create file if not exists)\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "new_row = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "new_row.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "17154eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.8828, Precision=0.8000, Recall=0.5517, F1=0.6531\n",
      "Fold 2: Accuracy=0.8621, Precision=0.8000, Recall=0.4138, F1=0.5455\n",
      "Fold 3: Accuracy=0.8621, Precision=0.7143, Recall=0.5172, F1=0.6000\n",
      "Fold 4: Accuracy=0.8483, Precision=0.6538, Recall=0.5667, F1=0.6071\n",
      "Fold 5: Accuracy=0.8542, Precision=0.6538, Recall=0.5862, F1=0.6182\n",
      "\n",
      "--- Tuned AdaBoost Summary ---\n",
      "Name                          : AdaBoostClassifier-Tuned\n",
      "Description                   : AdaBoost-Tuned-SAMME-OrderedDict({'classifier__learning_rate': 1.0, 'classifier__n_estimators': 180})\n",
      "Accuracy                      : 0.8619\n",
      "Precision                     : 0.7244\n",
      "Recall                        : 0.5271\n",
      "F1 Score                      : 0.6048\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Integer, Real\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Data setup\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag', 'Predicted Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# Categorical and numerical columns\n",
    "categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "# Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# AdaBoost pipeline\n",
    "pipe = Pipeline([\n",
    "    ('preprocess', preprocessor),\n",
    "    ('classifier', AdaBoostClassifier(algorithm='SAMME', random_state=42))\n",
    "])\n",
    "\n",
    "# Hyperparameter search space (no 'SAMME.R')\n",
    "search_space = {\n",
    "    'classifier__n_estimators': Integer(50, 300),\n",
    "    'classifier__learning_rate': Real(0.01, 1.0, prior='log-uniform')\n",
    "}\n",
    "\n",
    "# CV and tuner\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "opt = BayesSearchCV(\n",
    "    pipe,\n",
    "    search_spaces=search_space,\n",
    "    scoring='recall',\n",
    "    n_iter=25,\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=0,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the tuner\n",
    "opt.fit(X, y)\n",
    "\n",
    "# Final best model\n",
    "best_model = opt.best_estimator_\n",
    "\n",
    "# CV metric evaluation using best model\n",
    "accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    best_model.fit(X_train, y_train)\n",
    "    y_pred = best_model.predict(X_val)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# Final averages\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# Model info\n",
    "model_name = 'AdaBoostClassifier-Tuned'\n",
    "model_desc = f\"AdaBoost-Tuned-SAMME-{opt.best_params_}\"\n",
    "\n",
    "# Print summary\n",
    "print(\"\\n--- Tuned AdaBoost Summary ---\")\n",
    "print(f\"{'Name':<30}: {model_name}\")\n",
    "print(f\"{'Description':<30}: {model_desc}\")\n",
    "print(f\"{'Accuracy':<30}: {mean_acc:.4f}\")\n",
    "print(f\"{'Precision':<30}: {mean_prec:.4f}\")\n",
    "print(f\"{'Recall':<30}: {mean_rec:.4f}\")\n",
    "print(f\"{'F1 Score':<30}: {mean_f1:.4f}\")\n",
    "\n",
    "# CSV write\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "new_row = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "new_row.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0376e20f",
   "metadata": {},
   "source": [
    "# BalancedBaggingClassifier with a DecisionTreeClassifier(max_depth=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8996deb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.8276, Precision=0.5526, Recall=0.7241, F1=0.6269\n",
      "Fold 2: Accuracy=0.8690, Precision=0.6786, Recall=0.6552, F1=0.6667\n",
      "Fold 3: Accuracy=0.7448, Precision=0.4259, Recall=0.7931, F1=0.5542\n",
      "Fold 4: Accuracy=0.8069, Precision=0.5217, Recall=0.8000, F1=0.6316\n",
      "Fold 5: Accuracy=0.8542, Precision=0.6053, Recall=0.7931, F1=0.6866\n",
      "\n",
      "--- Model Summary ---\n",
      "Name                          : BalancedBagging-DecisionTree\n",
      "Description                   : Bagging+Balanced+DT(max_depth=6)+5Fold\n",
      "Accuracy                      : 0.8205\n",
      "Precision                     : 0.5568\n",
      "Recall                        : 0.7531\n",
      "F1 Score                      : 0.6332\n",
      "\n",
      "CSV Row Format:\n",
      "BalancedBagging-DecisionTree,Bagging+Balanced+DT(max_depth=6)+5Fold,0.8205,0.5568,0.7531,0.6332\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Assume df_clean is preloaded\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag', 'Predicted Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# Preprocessing (same as your other pipelines)\n",
    "categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "numeric_cols = X.select_dtypes(include=['number']).columns.tolist()\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols),\n",
    "    ('num', StandardScaler(), numeric_cols)\n",
    "])\n",
    "\n",
    "# Classifier setup\n",
    "base_estimator = DecisionTreeClassifier(max_depth=6, random_state=42)\n",
    "clf = BalancedBaggingClassifier(\n",
    "    estimator=base_estimator,\n",
    "    n_estimators=50,\n",
    "    sampling_strategy='auto',\n",
    "    replacement=False,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', clf)\n",
    "])\n",
    "\n",
    "# Cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "accuracy_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_val)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# Aggregate results\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# Model metadata\n",
    "model_name = 'BalancedBagging-DecisionTree'\n",
    "model_desc = 'Bagging+Balanced+DT(max_depth=6)+5Fold'\n",
    "\n",
    "print(\"\\n--- Model Summary ---\")\n",
    "print(f\"{'Name':<30}: {model_name}\")\n",
    "print(f\"{'Description':<30}: {model_desc}\")\n",
    "print(f\"{'Accuracy':<30}: {mean_acc:.4f}\")\n",
    "print(f\"{'Precision':<30}: {mean_prec:.4f}\")\n",
    "print(f\"{'Recall':<30}: {mean_rec:.4f}\")\n",
    "print(f\"{'F1 Score':<30}: {mean_f1:.4f}\")\n",
    "\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# Save results\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "new_row = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "new_row.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d06555",
   "metadata": {},
   "source": [
    "# EasyEnsembleClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3397a732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.8345, Precision=0.5581, Recall=0.8276, F1=0.6667\n",
      "Fold 2: Accuracy=0.8207, Precision=0.5429, Recall=0.6552, F1=0.5938\n",
      "Fold 3: Accuracy=0.7448, Precision=0.4231, Recall=0.7586, F1=0.5432\n",
      "Fold 4: Accuracy=0.8069, Precision=0.5208, Recall=0.8333, F1=0.6410\n",
      "Fold 5: Accuracy=0.7986, Precision=0.5000, Recall=0.9310, F1=0.6506\n",
      "\n",
      "--- Model Summary ---\n",
      "Name                          : EasyEnsembleClassifier\n",
      "Description                   : Ensemble+Undersampling+AdaBoost+5Fold\n",
      "Accuracy                      : 0.8011\n",
      "Precision                     : 0.5090\n",
      "Recall                        : 0.8011\n",
      "F1 Score                      : 0.6191\n",
      "\n",
      "CSV Row Format:\n",
      "EasyEnsembleClassifier,Ensemble+Undersampling+AdaBoost+5Fold,0.8011,0.5090,0.8011,0.6191\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from imblearn.ensemble import EasyEnsembleClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Dataset\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag', 'Predicted Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# Feature columns\n",
    "categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "numeric_cols = X.select_dtypes(include=['number']).columns.tolist()\n",
    "\n",
    "# Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols),\n",
    "    ('num', StandardScaler(), numeric_cols)\n",
    "])\n",
    "\n",
    "# Classifier: EasyEnsemble with default AdaBoost base\n",
    "clf = EasyEnsembleClassifier(\n",
    "    n_estimators=10,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Full pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', clf)\n",
    "])\n",
    "\n",
    "# Stratified K-Fold CV\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Metrics\n",
    "accuracy_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_val)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# Aggregate metrics\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# Metadata\n",
    "model_name = 'EasyEnsembleClassifier'\n",
    "model_desc = 'Ensemble+Undersampling+AdaBoost+5Fold'\n",
    "\n",
    "print(\"\\n--- Model Summary ---\")\n",
    "print(f\"{'Name':<30}: {model_name}\")\n",
    "print(f\"{'Description':<30}: {model_desc}\")\n",
    "print(f\"{'Accuracy':<30}: {mean_acc:.4f}\")\n",
    "print(f\"{'Precision':<30}: {mean_prec:.4f}\")\n",
    "print(f\"{'Recall':<30}: {mean_rec:.4f}\")\n",
    "print(f\"{'F1 Score':<30}: {mean_f1:.4f}\")\n",
    "\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# Save to CSV\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "new_row = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "new_row.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1424f5bb",
   "metadata": {},
   "source": [
    "# EasyEnsembleClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4e7cf45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Threshold=0.50, Accuracy=0.8483, Precision=0.5854, Recall=0.8276, F1=0.6857\n",
      "Fold 2: Threshold=0.50, Accuracy=0.8207, Precision=0.5429, Recall=0.6552, F1=0.5938\n",
      "Fold 3: Threshold=0.50, Accuracy=0.7379, Precision=0.4118, Recall=0.7241, F1=0.5250\n",
      "Fold 4: Threshold=0.50, Accuracy=0.8000, Precision=0.5094, Recall=0.9000, F1=0.6506\n",
      "Fold 5: Threshold=0.50, Accuracy=0.8194, Precision=0.5283, Recall=0.9655, F1=0.6829\n",
      "\n",
      "--- Model Summary ---\n",
      "Name                          : EasyEnsembleClassifier+ThresholdTuning\n",
      "Description                   : EEC-ThresholdTuning-5Fold\n",
      "Accuracy                      : 0.8053\n",
      "Precision                     : 0.5155\n",
      "Recall                        : 0.8145\n",
      "F1 Score                      : 0.6276\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from imblearn.ensemble import EasyEnsembleClassifier\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Target and features\n",
    "current_df = df_clean.copy()  # Ensure `df_clean` is already cleaned\n",
    "X = current_df.drop(columns=['Risk Flag', 'Predicted Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# CV setup\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Metric storage\n",
    "accuracy_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "\n",
    "# Initialize EasyEnsembleClassifier\n",
    "base_model = EasyEnsembleClassifier(random_state=42, n_estimators=10)\n",
    "\n",
    "# Preprocessing for categorical and numeric features\n",
    "categorical_features = X.select_dtypes(include=['object']).columns\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Feature selection\n",
    "feature_selector = SelectFromModel(estimator=RandomForestClassifier(random_state=42), max_features=20)\n",
    "\n",
    "# Threshold tuning range\n",
    "thresholds = np.linspace(0.1, 0.5, 5)\n",
    "\n",
    "# Pipeline setup\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('feature_selection', feature_selector),\n",
    "    ('classifier', base_model)\n",
    "])\n",
    "\n",
    "# 5-Fold Evaluation\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_probs = pipeline.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    # Threshold tuning\n",
    "    best_metrics = {'acc': 0, 'prec': 0, 'rec': 0, 'f1': 0, 'threshold': 0}\n",
    "    for thresh in thresholds:\n",
    "        y_pred = (y_probs >= thresh).astype(int)\n",
    "        acc = accuracy_score(y_val, y_pred)\n",
    "        prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "        rec = recall_score(y_val, y_pred)\n",
    "        f1 = f1_score(y_val, y_pred)\n",
    "        \n",
    "        if f1 > best_metrics['f1']:\n",
    "            best_metrics = {'acc': acc, 'prec': prec, 'rec': rec, 'f1': f1, 'threshold': thresh}\n",
    "    \n",
    "    accuracy_list.append(best_metrics['acc'])\n",
    "    precision_list.append(best_metrics['prec'])\n",
    "    recall_list.append(best_metrics['rec'])\n",
    "    f1_list.append(best_metrics['f1'])\n",
    "    \n",
    "    print(f\"Fold {fold}: Threshold={best_metrics['threshold']:.2f}, Accuracy={best_metrics['acc']:.4f}, \"\n",
    "          f\"Precision={best_metrics['prec']:.4f}, Recall={best_metrics['rec']:.4f}, F1={best_metrics['f1']:.4f}\")\n",
    "\n",
    "# Final metrics\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# Model info\n",
    "model_name = 'EasyEnsembleClassifier+ThresholdTuning'\n",
    "model_desc = 'EEC-ThresholdTuning-5Fold'\n",
    "\n",
    "# Print formatted summary\n",
    "print(\"\\n--- Model Summary ---\")\n",
    "print(f\"{'Name':<30}: {model_name}\")\n",
    "print(f\"{'Description':<30}: {model_desc}\")\n",
    "print(f\"{'Accuracy':<30}: {mean_acc:.4f}\")\n",
    "print(f\"{'Precision':<30}: {mean_prec:.4f}\")\n",
    "print(f\"{'Recall':<30}: {mean_rec:.4f}\")\n",
    "print(f\"{'F1 Score':<30}: {mean_f1:.4f}\")\n",
    "\n",
    "# Save to CSV\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "new_row = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "\n",
    "new_row.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fef45b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold=0.10 | Accuracy=0.2017, Precision=0.2017, Recall=1.0000, F1=0.3356\n",
      "Threshold=0.15 | Accuracy=0.2017, Precision=0.2017, Recall=1.0000, F1=0.3356\n",
      "Threshold=0.20 | Accuracy=0.2017, Precision=0.2017, Recall=1.0000, F1=0.3356\n",
      "Threshold=0.25 | Accuracy=0.2044, Precision=0.2022, Recall=1.0000, F1=0.3364\n",
      "Threshold=0.30 | Accuracy=0.2058, Precision=0.2025, Recall=1.0000, F1=0.3368\n",
      "Threshold=0.35 | Accuracy=0.2472, Precision=0.2113, Recall=1.0000, F1=0.3489\n",
      "Threshold=0.40 | Accuracy=0.4378, Precision=0.2644, Recall=1.0000, F1=0.4181\n",
      "Threshold=0.45 | Accuracy=0.6243, Precision=0.3458, Recall=0.9586, F1=0.5077\n",
      "Threshold=0.50 | Accuracy=0.7970, Precision=0.5018, Recall=0.8152, F1=0.6186\n",
      "\n",
      "No threshold met strict criteria. Falling back to best F1 score.\n",
      "\n",
      "--- Best Threshold Tuned Model Summary ---\n",
      "Name                          : EasyEnsemble-Top20Feat+Thresh\n",
      "Description                   : 5Fold-EEC+Top20Selector+ThreshTuned-0.50\n",
      "Accuracy                      : 0.7970\n",
      "Precision                     : 0.5018\n",
      "Recall                        : 0.8152\n",
      "F1 Score                      : 0.6186\n",
      "\n",
      "CSV Row Format:\n",
      "EasyEnsemble-Top20Feat+Thresh,5Fold-EEC+Top20Selector+ThreshTuned-0.50,0.7970,0.5018,0.8152,0.6186\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.ensemble import EasyEnsembleClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- Custom Transformer for Top 20 Features ---\n",
    "class TopFeatureSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, model, k=20):\n",
    "        self.model = model\n",
    "        self.k = k\n",
    "        self.top_indices = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.model.fit(X, y)\n",
    "        if hasattr(self.model, \"feature_importances_\"):\n",
    "            importances = self.model.feature_importances_\n",
    "        else:\n",
    "            raise AttributeError(\"Model must have feature_importances_\")\n",
    "        self.top_indices = np.argsort(importances)[::-1][:self.k]\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[:, self.top_indices]\n",
    "\n",
    "# --- Load data ---\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag', 'Predicted Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# --- Identify column types ---\n",
    "categorical_cols = X.select_dtypes(include='object').columns.tolist()\n",
    "numerical_cols = X.select_dtypes(include=np.number).columns.tolist()\n",
    "\n",
    "# --- Preprocessing ---\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# --- Pipeline components ---\n",
    "rf_for_selection = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "top_k_selector = TopFeatureSelector(model=rf_for_selection, k=20)\n",
    "\n",
    "model = EasyEnsembleClassifier(\n",
    "    n_estimators=10,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('selector', top_k_selector),\n",
    "    ('model', model)\n",
    "])\n",
    "\n",
    "# --- CV and threshold tuning ---\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "thresholds = np.arange(0.1, 0.51, 0.05)\n",
    "\n",
    "best_metrics = {'threshold': 0, 'accuracy': 0, 'precision': 0, 'recall': 0, 'f1': 0}\n",
    "\n",
    "# Try all thresholds\n",
    "for threshold in thresholds:\n",
    "    acc_list, prec_list, rec_list, f1_list = [], [], [], []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        y_proba = pipeline.predict_proba(X_val)[:, 1]\n",
    "        y_pred = (y_proba >= threshold).astype(int)\n",
    "\n",
    "        acc = accuracy_score(y_val, y_pred)\n",
    "        prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "        rec = recall_score(y_val, y_pred)\n",
    "        f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "        acc_list.append(acc)\n",
    "        prec_list.append(prec)\n",
    "        rec_list.append(rec)\n",
    "        f1_list.append(f1)\n",
    "\n",
    "    mean_acc = np.mean(acc_list)\n",
    "    mean_prec = np.mean(prec_list)\n",
    "    mean_rec = np.mean(rec_list)\n",
    "    mean_f1 = np.mean(f1_list)\n",
    "\n",
    "    print(f\"Threshold={threshold:.2f} | Accuracy={mean_acc:.4f}, Precision={mean_prec:.4f}, Recall={mean_rec:.4f}, F1={mean_f1:.4f}\")\n",
    "\n",
    "    if (\n",
    "        mean_rec > best_metrics['recall'] and\n",
    "        mean_prec > 0.6 and\n",
    "        mean_f1 > 0.7 and\n",
    "        mean_acc > 0.8\n",
    "    ):\n",
    "        best_metrics.update({\n",
    "            'threshold': threshold,\n",
    "            'accuracy': mean_acc,\n",
    "            'precision': mean_prec,\n",
    "            'recall': mean_rec,\n",
    "            'f1': mean_f1\n",
    "        })\n",
    "\n",
    "# --- Fallback if no threshold met all strict criteria ---\n",
    "if best_metrics['f1'] == 0:\n",
    "    print(\"\\nNo threshold met strict criteria. Falling back to best F1 score.\")\n",
    "    best_f1 = 0\n",
    "    for threshold in thresholds:\n",
    "        acc_list, prec_list, rec_list, f1_list = [], [], [], []\n",
    "\n",
    "        for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "            X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "            pipeline.fit(X_train, y_train)\n",
    "            y_proba = pipeline.predict_proba(X_val)[:, 1]\n",
    "            y_pred = (y_proba >= threshold).astype(int)\n",
    "\n",
    "            acc_list.append(accuracy_score(y_val, y_pred))\n",
    "            prec_list.append(precision_score(y_val, y_pred, zero_division=0))\n",
    "            rec_list.append(recall_score(y_val, y_pred))\n",
    "            f1_list.append(f1_score(y_val, y_pred))\n",
    "\n",
    "        mean_f1 = np.mean(f1_list)\n",
    "        if mean_f1 > best_f1:\n",
    "            best_f1 = mean_f1\n",
    "            best_metrics.update({\n",
    "                'threshold': threshold,\n",
    "                'accuracy': np.mean(acc_list),\n",
    "                'precision': np.mean(prec_list),\n",
    "                'recall': np.mean(rec_list),\n",
    "                'f1': mean_f1\n",
    "            })\n",
    "\n",
    "# --- Reporting ---\n",
    "model_name = 'EasyEnsemble-Top20Feat+Thresh'\n",
    "model_desc = f'5Fold-EEC+Top20Selector+ThreshTuned-{best_metrics[\"threshold\"]:.2f}'\n",
    "\n",
    "print(\"\\n--- Best Threshold Tuned Model Summary ---\")\n",
    "print(f\"{'Name':<30}: {model_name}\")\n",
    "print(f\"{'Description':<30}: {model_desc}\")\n",
    "print(f\"{'Accuracy':<30}: {best_metrics['accuracy']:.4f}\")\n",
    "print(f\"{'Precision':<30}: {best_metrics['precision']:.4f}\")\n",
    "print(f\"{'Recall':<30}: {best_metrics['recall']:.4f}\")\n",
    "print(f\"{'F1 Score':<30}: {best_metrics['f1']:.4f}\")\n",
    "\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{best_metrics['accuracy']:.4f},{best_metrics['precision']:.4f},{best_metrics['recall']:.4f},{best_metrics['f1']:.4f}\")\n",
    "\n",
    "# --- Save results ---\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "new_row = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(best_metrics['accuracy'], 4),\n",
    "    'Precision': round(best_metrics['precision'], 4),\n",
    "    'Recall': round(best_metrics['recall'], 4),\n",
    "    'F1 Score': round(best_metrics['f1'], 4)\n",
    "}])\n",
    "new_row.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca243728",
   "metadata": {},
   "source": [
    "# BalancedBaggingClassifier + LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1e6dd3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold=0.10 | Accuracy=0.6146, Precision=0.3422, Recall=0.9724, F1=0.5057\n",
      "Threshold=0.15 | Accuracy=0.6767, Precision=0.3815, Recall=0.9448, F1=0.5426\n",
      "Threshold=0.20 | Accuracy=0.7072, Precision=0.4049, Recall=0.9313, F1=0.5633\n",
      "Threshold=0.25 | Accuracy=0.7362, Precision=0.4296, Recall=0.8970, F1=0.5791\n",
      "Threshold=0.30 | Accuracy=0.7679, Precision=0.4648, Recall=0.8628, F1=0.6019\n",
      "Threshold=0.35 | Accuracy=0.7901, Precision=0.4945, Recall=0.8287, F1=0.6167\n",
      "Threshold=0.40 | Accuracy=0.8025, Precision=0.5141, Recall=0.8085, F1=0.6252\n",
      "Threshold=0.45 | Accuracy=0.8232, Precision=0.5511, Recall=0.7809, F1=0.6433\n",
      "Threshold=0.50 | Accuracy=0.8329, Precision=0.5719, Recall=0.7674, F1=0.6523\n",
      "\n",
      "No threshold met strict criteria. Falling back to best F1 score.\n",
      "\n",
      "--- Best Threshold Tuned Model Summary ---\n",
      "Name                          : BalancedBagging-LGBM\n",
      "Description                   : 5Fold-BBC+LGBM-ThresholdTuned-0.50\n",
      "Accuracy                      : 0.8329\n",
      "Precision                     : 0.5719\n",
      "Recall                        : 0.7674\n",
      "F1 Score                      : 0.6523\n",
      "\n",
      "CSV Row Format:\n",
      "BalancedBagging-LGBM,5Fold-BBC+LGBM-ThresholdTuned-0.50,0.8329,0.5719,0.7674,0.6523\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from lightgbm import LGBMClassifier\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- Data setup ---\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag', 'Predicted Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# --- Column types ---\n",
    "categorical_cols = X.select_dtypes(include='object').columns.tolist()\n",
    "numerical_cols = X.select_dtypes(include=np.number).columns.tolist()\n",
    "\n",
    "# --- Preprocessing ---\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# --- Classifier setup ---\n",
    "lgbm = LGBMClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.1,\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "bbc = BalancedBaggingClassifier(\n",
    "    estimator=lgbm,\n",
    "    n_estimators=10,\n",
    "    sampling_strategy='auto',\n",
    "    replacement=False,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# --- Full pipeline ---\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', bbc)\n",
    "])\n",
    "\n",
    "# --- Evaluation ---\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "thresholds = np.arange(0.1, 0.51, 0.05)\n",
    "best_metrics = {'threshold': 0, 'accuracy': 0, 'precision': 0, 'recall': 0, 'f1': 0}\n",
    "\n",
    "for threshold in thresholds:\n",
    "    acc_list, prec_list, rec_list, f1_list = [], [], [], []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        y_proba = pipeline.predict_proba(X_val)[:, 1]\n",
    "        y_pred = (y_proba >= threshold).astype(int)\n",
    "\n",
    "        acc_list.append(accuracy_score(y_val, y_pred))\n",
    "        prec_list.append(precision_score(y_val, y_pred, zero_division=0))\n",
    "        rec_list.append(recall_score(y_val, y_pred))\n",
    "        f1_list.append(f1_score(y_val, y_pred))\n",
    "\n",
    "    mean_acc = np.mean(acc_list)\n",
    "    mean_prec = np.mean(prec_list)\n",
    "    mean_rec = np.mean(rec_list)\n",
    "    mean_f1 = np.mean(f1_list)\n",
    "\n",
    "    print(f\"Threshold={threshold:.2f} | Accuracy={mean_acc:.4f}, Precision={mean_prec:.4f}, Recall={mean_rec:.4f}, F1={mean_f1:.4f}\")\n",
    "\n",
    "    if (\n",
    "        mean_rec > best_metrics['recall'] and\n",
    "        mean_prec > 0.6 and\n",
    "        mean_f1 > 0.7 and\n",
    "        mean_acc > 0.8\n",
    "    ):\n",
    "        best_metrics.update({\n",
    "            'threshold': threshold,\n",
    "            'accuracy': mean_acc,\n",
    "            'precision': mean_prec,\n",
    "            'recall': mean_rec,\n",
    "            'f1': mean_f1\n",
    "        })\n",
    "\n",
    "# --- Fallback to best F1 if no strict threshold matched ---\n",
    "if best_metrics['f1'] == 0:\n",
    "    print(\"\\nNo threshold met strict criteria. Falling back to best F1 score.\")\n",
    "    best_f1 = 0\n",
    "    for threshold in thresholds:\n",
    "        acc_list, prec_list, rec_list, f1_list = [], [], [], []\n",
    "\n",
    "        for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "            X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "            pipeline.fit(X_train, y_train)\n",
    "            y_proba = pipeline.predict_proba(X_val)[:, 1]\n",
    "            y_pred = (y_proba >= threshold).astype(int)\n",
    "\n",
    "            acc_list.append(accuracy_score(y_val, y_pred))\n",
    "            prec_list.append(precision_score(y_val, y_pred, zero_division=0))\n",
    "            rec_list.append(recall_score(y_val, y_pred))\n",
    "            f1_list.append(f1_score(y_val, y_pred))\n",
    "\n",
    "        mean_f1 = np.mean(f1_list)\n",
    "        if mean_f1 > best_f1:\n",
    "            best_f1 = mean_f1\n",
    "            best_metrics.update({\n",
    "                'threshold': threshold,\n",
    "                'accuracy': np.mean(acc_list),\n",
    "                'precision': np.mean(prec_list),\n",
    "                'recall': np.mean(rec_list),\n",
    "                'f1': mean_f1\n",
    "            })\n",
    "\n",
    "# --- Reporting ---\n",
    "model_name = 'BalancedBagging-LGBM'\n",
    "model_desc = f'5Fold-BBC+LGBM-ThresholdTuned-{best_metrics[\"threshold\"]:.2f}'\n",
    "\n",
    "print(\"\\n--- Best Threshold Tuned Model Summary ---\")\n",
    "print(f\"{'Name':<30}: {model_name}\")\n",
    "print(f\"{'Description':<30}: {model_desc}\")\n",
    "print(f\"{'Accuracy':<30}: {best_metrics['accuracy']:.4f}\")\n",
    "print(f\"{'Precision':<30}: {best_metrics['precision']:.4f}\")\n",
    "print(f\"{'Recall':<30}: {best_metrics['recall']:.4f}\")\n",
    "print(f\"{'F1 Score':<30}: {best_metrics['f1']:.4f}\")\n",
    "\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{best_metrics['accuracy']:.4f},{best_metrics['precision']:.4f},{best_metrics['recall']:.4f},{best_metrics['f1']:.4f}\")\n",
    "\n",
    "# --- Save to CSV ---\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "new_row = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(best_metrics['accuracy'], 4),\n",
    "    'Precision': round(best_metrics['precision'], 4),\n",
    "    'Recall': round(best_metrics['recall'], 4),\n",
    "    'F1 Score': round(best_metrics['f1'], 4)\n",
    "}])\n",
    "new_row.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79697540",
   "metadata": {},
   "source": [
    "# StackingClassifier with Threshold Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb8d4db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold=0.10 | Accuracy=0.7362, Precision=0.4282, Recall=0.8492, F1=0.5677\n",
      "Threshold=0.15 | Accuracy=0.7901, Precision=0.4943, Recall=0.8147, F1=0.6126\n",
      "Threshold=0.20 | Accuracy=0.8246, Precision=0.5511, Recall=0.7669, F1=0.6399\n",
      "Threshold=0.25 | Accuracy=0.8426, Precision=0.6018, Recall=0.7186, F1=0.6506\n",
      "Threshold=0.30 | Accuracy=0.8591, Precision=0.6572, Recall=0.6910, F1=0.6670\n",
      "Threshold=0.35 | Accuracy=0.8660, Precision=0.6772, Recall=0.6775, F1=0.6716\n",
      "Threshold=0.40 | Accuracy=0.8660, Precision=0.6964, Recall=0.6294, F1=0.6547\n",
      "Threshold=0.45 | Accuracy=0.8674, Precision=0.7313, Recall=0.5814, F1=0.6382\n",
      "Threshold=0.50 | Accuracy=0.8674, Precision=0.7489, Recall=0.5474, F1=0.6255\n",
      "\n",
      "No threshold met strict criteria. Falling back to best F1 score.\n",
      "\n",
      "--- Best Threshold Tuned Model Summary ---\n",
      "Name                          : Stacking-CatLGBMSVCBBC\n",
      "Description                   : StackingCatLGBMSVCBBC+LogRegMeta+ThreshTuned-0.35\n",
      "Accuracy                      : 0.8660\n",
      "Precision                     : 0.6772\n",
      "Recall                        : 0.6775\n",
      "F1 Score                      : 0.6716\n",
      "\n",
      "CSV Row Format:\n",
      "Stacking-CatLGBMSVCBBC,StackingCatLGBMSVCBBC+LogRegMeta+ThreshTuned-0.35,0.8660,0.6772,0.6775,0.6716\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.svm import SVC\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- Data prep ---\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag', 'Predicted Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "categorical_cols = X.select_dtypes(include='object').columns.tolist()\n",
    "numerical_cols = X.select_dtypes(include=np.number).columns.tolist()\n",
    "\n",
    "# --- Preprocessing ---\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# --- Base models ---\n",
    "cat = CatBoostClassifier(verbose=0, random_state=42)\n",
    "lgbm = LGBMClassifier(n_estimators=100, max_depth=5, learning_rate=0.1, random_state=42)\n",
    "svc = SVC(kernel='rbf', C=1, probability=True, random_state=42)\n",
    "bbc = BalancedBaggingClassifier(\n",
    "    estimator=DecisionTreeClassifier(max_depth=6, random_state=42),\n",
    "    n_estimators=10,\n",
    "    sampling_strategy='auto',\n",
    "    replacement=False,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# --- Meta model ---\n",
    "meta_model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# --- Stacking ---\n",
    "stacking_model = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('cat', cat),\n",
    "        ('lgbm', lgbm),\n",
    "        ('svc', svc),\n",
    "        ('bbc', bbc)\n",
    "    ],\n",
    "    final_estimator=meta_model,\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    passthrough=True\n",
    ")\n",
    "\n",
    "# --- Full pipeline ---\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', stacking_model)\n",
    "])\n",
    "\n",
    "# --- CV + Threshold tuning ---\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "thresholds = np.arange(0.1, 0.51, 0.05)\n",
    "best_metrics = {'threshold': 0, 'accuracy': 0, 'precision': 0, 'recall': 0, 'f1': 0}\n",
    "\n",
    "for threshold in thresholds:\n",
    "    acc_list, prec_list, rec_list, f1_list = [], [], [], []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        y_proba = pipeline.predict_proba(X_val)[:, 1]\n",
    "        y_pred = (y_proba >= threshold).astype(int)\n",
    "\n",
    "        acc_list.append(accuracy_score(y_val, y_pred))\n",
    "        prec_list.append(precision_score(y_val, y_pred, zero_division=0))\n",
    "        rec_list.append(recall_score(y_val, y_pred))\n",
    "        f1_list.append(f1_score(y_val, y_pred))\n",
    "\n",
    "    mean_acc = np.mean(acc_list)\n",
    "    mean_prec = np.mean(prec_list)\n",
    "    mean_rec = np.mean(rec_list)\n",
    "    mean_f1 = np.mean(f1_list)\n",
    "\n",
    "    print(f\"Threshold={threshold:.2f} | Accuracy={mean_acc:.4f}, Precision={mean_prec:.4f}, Recall={mean_rec:.4f}, F1={mean_f1:.4f}\")\n",
    "\n",
    "    if (\n",
    "        mean_rec > best_metrics['recall'] and\n",
    "        mean_prec > 0.6 and\n",
    "        mean_f1 > 0.7 and\n",
    "        mean_acc > 0.8\n",
    "    ):\n",
    "        best_metrics.update({\n",
    "            'threshold': threshold,\n",
    "            'accuracy': mean_acc,\n",
    "            'precision': mean_prec,\n",
    "            'recall': mean_rec,\n",
    "            'f1': mean_f1\n",
    "        })\n",
    "\n",
    "# --- Fallback: best F1 if strict criteria fail ---\n",
    "if best_metrics['f1'] == 0:\n",
    "    print(\"\\nNo threshold met strict criteria. Falling back to best F1 score.\")\n",
    "    best_f1 = 0\n",
    "    for threshold in thresholds:\n",
    "        acc_list, prec_list, rec_list, f1_list = [], [], [], []\n",
    "\n",
    "        for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "            X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "            pipeline.fit(X_train, y_train)\n",
    "            y_proba = pipeline.predict_proba(X_val)[:, 1]\n",
    "            y_pred = (y_proba >= threshold).astype(int)\n",
    "\n",
    "            acc_list.append(accuracy_score(y_val, y_pred))\n",
    "            prec_list.append(precision_score(y_val, y_pred, zero_division=0))\n",
    "            rec_list.append(recall_score(y_val, y_pred))\n",
    "            f1_list.append(f1_score(y_val, y_pred))\n",
    "\n",
    "        mean_f1 = np.mean(f1_list)\n",
    "        if mean_f1 > best_f1:\n",
    "            best_f1 = mean_f1\n",
    "            best_metrics.update({\n",
    "                'threshold': threshold,\n",
    "                'accuracy': np.mean(acc_list),\n",
    "                'precision': np.mean(prec_list),\n",
    "                'recall': np.mean(rec_list),\n",
    "                'f1': mean_f1\n",
    "            })\n",
    "\n",
    "# --- Reporting ---\n",
    "model_name = 'Stacking-CatLGBMSVCBBC'\n",
    "model_desc = f'StackingCatLGBMSVCBBC+LogRegMeta+ThreshTuned-{best_metrics[\"threshold\"]:.2f}'\n",
    "\n",
    "print(\"\\n--- Best Threshold Tuned Model Summary ---\")\n",
    "print(f\"{'Name':<30}: {model_name}\")\n",
    "print(f\"{'Description':<30}: {model_desc}\")\n",
    "print(f\"{'Accuracy':<30}: {best_metrics['accuracy']:.4f}\")\n",
    "print(f\"{'Precision':<30}: {best_metrics['precision']:.4f}\")\n",
    "print(f\"{'Recall':<30}: {best_metrics['recall']:.4f}\")\n",
    "print(f\"{'F1 Score':<30}: {best_metrics['f1']:.4f}\")\n",
    "\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{best_metrics['accuracy']:.4f},{best_metrics['precision']:.4f},{best_metrics['recall']:.4f},{best_metrics['f1']:.4f}\")\n",
    "\n",
    "# --- Save to CSV ---\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "new_row = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(best_metrics['accuracy'], 4),\n",
    "    'Precision': round(best_metrics['precision'], 4),\n",
    "    'Recall': round(best_metrics['recall'], 4),\n",
    "    'F1 Score': round(best_metrics['f1'], 4)\n",
    "}])\n",
    "new_row.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6537e310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.8690, Precision=0.8125, Recall=0.4483, F1=0.5778\n",
      "Fold 2: Accuracy=0.8759, Precision=0.9231, Recall=0.4138, F1=0.5714\n",
      "Fold 3: Accuracy=0.8552, Precision=0.6429, Recall=0.6207, F1=0.6316\n",
      "Fold 4: Accuracy=0.8621, Precision=0.6923, Recall=0.6000, F1=0.6429\n",
      "Fold 5: Accuracy=0.8750, Precision=0.7619, Recall=0.5517, F1=0.6400\n",
      "\n",
      "--- Ensemble Model Summary ---\n",
      "Name                          : ManualSoftVoting-Cat+Ada+SVC\n",
      "Description                   : ManualSoftVoting-Weights[1,2,2]-Thresh0.45\n",
      "Accuracy                      : 0.8674\n",
      "Precision                     : 0.7665\n",
      "Recall                        : 0.5269\n",
      "F1 Score                      : 0.6127\n",
      "\n",
      "CSV Row Format:\n",
      "ManualSoftVoting-Cat+Ada+SVC,ManualSoftVoting-Weights[1,2,2]-Thresh0.45,0.8674,0.7665,0.5269,0.6127\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from catboost import CatBoostClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- Prepare Data ---\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag', 'Predicted Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# --- Preprocessing ---\n",
    "categorical_cols = X.select_dtypes(include='object').columns.tolist()\n",
    "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# --- Models ---\n",
    "svc = Pipeline([\n",
    "    ('pre', preprocessor),\n",
    "    ('model', SVC(\n",
    "        kernel='rbf',\n",
    "        C=10, gamma=0.01,\n",
    "        probability=True,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "adaboost = Pipeline([\n",
    "    ('pre', preprocessor),\n",
    "    ('model', AdaBoostClassifier(\n",
    "        n_estimators=150,\n",
    "        learning_rate=0.6,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "catboost = Pipeline([\n",
    "    ('pre', preprocessor),\n",
    "    ('model', CatBoostClassifier(\n",
    "        iterations=250,\n",
    "        learning_rate=0.04,\n",
    "        depth=6,\n",
    "        l2_leaf_reg=3,\n",
    "        verbose=0,\n",
    "        random_seed=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# --- CV Setup ---\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n",
    "\n",
    "# --- Weights & Threshold ---\n",
    "weights = [1, 2, 2]  # svc, adaboost, catboost\n",
    "threshold = 0.45\n",
    "\n",
    "# --- 5-Fold Evaluation ---\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    svc.fit(X_train, y_train)\n",
    "    adaboost.fit(X_train, y_train)\n",
    "    catboost.fit(X_train, y_train)\n",
    "\n",
    "    svc_proba = svc.predict_proba(X_val)[:, 1]\n",
    "    ada_proba = adaboost.predict_proba(X_val)[:, 1]\n",
    "    cat_proba = catboost.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    # Manual soft voting\n",
    "    blended_proba = (\n",
    "        weights[0] * svc_proba +\n",
    "        weights[1] * ada_proba +\n",
    "        weights[2] * cat_proba\n",
    "    ) / sum(weights)\n",
    "\n",
    "    y_pred = (blended_proba >= threshold).astype(int)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# --- Final Metrics ---\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "model_name = 'ManualSoftVoting-Cat+Ada+SVC'\n",
    "model_desc = 'ManualSoftVoting-Weights[1,2,2]-Thresh0.45'\n",
    "\n",
    "print(\"\\n--- Ensemble Model Summary ---\")\n",
    "print(f\"{'Name':<30}: {model_name}\")\n",
    "print(f\"{'Description':<30}: {model_desc}\")\n",
    "print(f\"{'Accuracy':<30}: {mean_acc:.4f}\")\n",
    "print(f\"{'Precision':<30}: {mean_prec:.4f}\")\n",
    "print(f\"{'Recall':<30}: {mean_rec:.4f}\")\n",
    "print(f\"{'F1 Score':<30}: {mean_f1:.4f}\")\n",
    "\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# --- Save to CSV ---\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "new_row = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "new_row.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c89fff0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Acc=0.8483, Prec=0.8889, Recall=0.2759, F1=0.4211\n",
      "Fold 2: Acc=0.8690, Prec=1.0000, Recall=0.3448, F1=0.5128\n",
      "Fold 3: Acc=0.8621, Prec=0.9091, Recall=0.3448, F1=0.5000\n",
      "Fold 4: Acc=0.8552, Prec=0.7368, Recall=0.4667, F1=0.5714\n",
      "Fold 5: Acc=0.8611, Prec=0.8462, Recall=0.3793, F1=0.5238\n",
      "\n",
      "--- Final Model Metrics ---\n",
      "Name                          : Stacking-EEC+BBC-LGBM+CatBoost\n",
      "Description                   : Stack[RidgeCV]-Thresh0.4\n",
      "Accuracy                      : 0.8591\n",
      "Precision                     : 0.8762\n",
      "Recall                        : 0.3623\n",
      "F1 Score                      : 0.5058\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from imblearn.ensemble import EasyEnsembleClassifier, BalancedBaggingClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- Data ---\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag', 'Predicted Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# --- Preprocessing ---\n",
    "categorical_cols = X.select_dtypes(include='object').columns.tolist()\n",
    "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# --- Base Estimators ---\n",
    "eec = Pipeline([\n",
    "    ('pre', preprocessor),\n",
    "    ('model', EasyEnsembleClassifier(n_estimators=10, random_state=42))\n",
    "])\n",
    "\n",
    "bbc = Pipeline([\n",
    "    ('pre', preprocessor),\n",
    "    ('model', BalancedBaggingClassifier(\n",
    "        estimator=LGBMClassifier(random_state=42),\n",
    "        n_estimators=10,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "catboost = Pipeline([\n",
    "    ('pre', preprocessor),\n",
    "    ('model', CatBoostClassifier(\n",
    "        iterations=250,\n",
    "        learning_rate=0.04,\n",
    "        depth=6,\n",
    "        l2_leaf_reg=3,\n",
    "        verbose=0,\n",
    "        random_seed=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# --- Meta Estimator ---\n",
    "meta_model = RidgeClassifierCV()\n",
    "\n",
    "# --- StackingClassifier ---\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('eec', eec),\n",
    "        ('bbc', bbc),\n",
    "        ('cat', catboost)\n",
    "    ],\n",
    "    final_estimator=meta_model,\n",
    "    stack_method='predict_proba',\n",
    "    passthrough=False,\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# --- Evaluation ---\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "acc_list, prec_list, rec_list, f1_list = [], [], [], []\n",
    "threshold = 0.4  # Tune between 0.3 - 0.5\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    stacking_clf.fit(X_train, y_train)\n",
    "\n",
    "    # RidgeClassifierCV doesnâ€™t support predict_proba\n",
    "    try:\n",
    "        decision_scores = stacking_clf.final_estimator_.decision_function(\n",
    "            stacking_clf.transform(X_val)\n",
    "        )\n",
    "    except Exception:\n",
    "        # fallback if transform not available\n",
    "        decision_scores = stacking_clf.decision_function(X_val)\n",
    "\n",
    "    y_pred = (decision_scores >= threshold).astype(int)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    acc_list.append(acc)\n",
    "    prec_list.append(prec)\n",
    "    rec_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Acc={acc:.4f}, Prec={prec:.4f}, Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# --- Results Summary ---\n",
    "mean_acc = np.mean(acc_list)\n",
    "mean_prec = np.mean(prec_list)\n",
    "mean_rec = np.mean(rec_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "model_name = 'Stacking-EEC+BBC-LGBM+CatBoost'\n",
    "model_desc = f'Stack[RidgeCV]-Thresh{threshold}'\n",
    "\n",
    "print(\"\\n--- Final Model Metrics ---\")\n",
    "print(f\"{'Name':<30}: {model_name}\")\n",
    "print(f\"{'Description':<30}: {model_desc}\")\n",
    "print(f\"{'Accuracy':<30}: {mean_acc:.4f}\")\n",
    "print(f\"{'Precision':<30}: {mean_prec:.4f}\")\n",
    "print(f\"{'Recall':<30}: {mean_rec:.4f}\")\n",
    "print(f\"{'F1 Score':<30}: {mean_f1:.4f}\")\n",
    "\n",
    "# --- Save to CSV ---\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "new_row = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "new_row.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c7f3b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
