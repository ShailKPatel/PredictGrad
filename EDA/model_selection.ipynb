{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38157fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Gender Religion Branch Section-1 Section-2 Section-3  Roll-1  Math-1 Theory  \\\n",
      "0      M    Hindu     CE         D         D         A     350             47   \n",
      "1      F    Hindu    CST         B         B         D      18             84   \n",
      "2      F    Hindu   AIML         A         A         C      23             74   \n",
      "3      M    Hindu    CST         B         B         D     212             55   \n",
      "4      M    Hindu    CST         B         B         D     208             38   \n",
      "\n",
      "   Physics Theory  Physics Practical  ...  Predicted FSD Theory  \\\n",
      "0              48                 75  ...             72.266535   \n",
      "1              83                 81  ...             87.523458   \n",
      "2              85                 86  ...             89.409752   \n",
      "3              69                 82  ...             79.807055   \n",
      "4              59                 74  ...             56.474296   \n",
      "\n",
      "   Predicted Math-3 Theory  Predicted Python Theory  \\\n",
      "0                56.352210                71.642156   \n",
      "1                82.966865                81.393865   \n",
      "2                76.982002                86.897293   \n",
      "3                67.253716                74.606764   \n",
      "4                51.995650                53.483393   \n",
      "\n",
      "   Predicted Sem 3 Percentage  Sem 1 Percentile  Sem 2 Percentile  \\\n",
      "0                       64.14             26.38             30.66   \n",
      "1                       83.40             95.99             84.39   \n",
      "2                       83.49             92.47             91.16   \n",
      "3                       72.31             66.30             51.59   \n",
      "4                       53.42             15.68             11.53   \n",
      "\n",
      "   Predicted Sem 3 Percentile  Predicted Percentile Drop  Predicted Risk Flag  \\\n",
      "0                       38.26                      -7.60                False   \n",
      "1                       88.54                      -4.15                False   \n",
      "2                       88.81                       2.35                False   \n",
      "3                       61.26                      -9.67                False   \n",
      "4                       15.47                      -3.94                False   \n",
      "\n",
      "   Risk Flag  \n",
      "0      False  \n",
      "1      False  \n",
      "2      False  \n",
      "3      False  \n",
      "4      False  \n",
      "\n",
      "[5 rows x 51 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Ensure the path to the DEModelHandler is correct\n",
    "sys.path.append(os.path.abspath(\"../SubjectModels/de_model\"))\n",
    "from de_handler import DEModelHandler  \n",
    "\n",
    "# Ensure the path to the FSDModelHandler is correct\n",
    "sys.path.append(os.path.abspath(\"../SubjectModels/fsd_model\"))\n",
    "from fsd_handler import FSDModelHandler  \n",
    "\n",
    "# Ensure the path to the Math3ModelHandler is correct\n",
    "sys.path.append(os.path.abspath(\"../SubjectModels/math3_model\"))\n",
    "from math3_handler import Math3ModelHandler  \n",
    "\n",
    "# Ensure the path to the PythonModelHandler is correct\n",
    "sys.path.append(os.path.abspath(\"../SubjectModels/python_model\"))\n",
    "from python_handler import PythonModelHandler  \n",
    "\n",
    "df = pd.read_csv(\"../dataset/train_dataset.csv\")\n",
    "\n",
    "# Drop the irrelevant, data leak columns\n",
    "df_clean = df.drop(\n",
    "    columns=[\n",
    "        \"Student ID\",\n",
    "        \"Mentor-1\",\n",
    "        \"Mentor-2\",\n",
    "        \"Mentor-3\",\n",
    "        \"Roll-2\",\n",
    "        \"Roll-3\",\n",
    "        \"Math-3 Theory\",\n",
    "        \"DE Practical\",\n",
    "        \"FSD Theory\",\n",
    "        \"FSD Practical\",\n",
    "        \"Python Theory\",\n",
    "        \"Python Practical\",\n",
    "        \"Communication Theory\",\n",
    "        \"Law Theory\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "# columns for Semester 1 core subjects\n",
    "sem1_columns = [\n",
    "    \"Math-1 Theory\",\n",
    "    \"Physics Theory\",\n",
    "    \"Java-1 Theory\",\n",
    "    \"Software Engineering Theory\",\n",
    "]\n",
    "\n",
    "# Calculate Semester 1 Percentage as the average of core subject scores\n",
    "# scores are numerical and out of 100\n",
    "df_clean[\"Sem 1 Percentage\"] = df_clean[sem1_columns].mean(axis=1).round(2)\n",
    "\n",
    "# columns for Semester 2 core subjects\n",
    "sem2_columns = [\n",
    "    \"Math-2 Theory\",\n",
    "    \"Data Structures using Java Theory\",\n",
    "    \"DBMS Theory\",\n",
    "    \"Fundamental of Electronics and Electrical Theory\",\n",
    "    \"Java-2 Theory\",\n",
    "]\n",
    "\n",
    "# Calculate Semester 2 Percentage as the average of core subject scores\n",
    "# scores are numerical and out of 100\n",
    "df_clean[\"Sem 2 Percentage\"] = df_clean[sem2_columns].mean(axis=1).round(2)\n",
    "\n",
    "# Rename columns Div-1, Div-2, Div-3 to Section-1, Section-2, Section-3\n",
    "df_clean = df_clean.rename(\n",
    "    columns={\"Div-1\": \"Section-1\", \"Div-2\": \"Section-2\", \"Div-3\": \"Section-3\"}\n",
    ")\n",
    "\n",
    "# Transform values in Section-1, Section-2, Section-3 to keep only the first character\n",
    "# Thus we get Only Department\n",
    "for section in [\"Section-1\", \"Section-2\", \"Section-3\"]:\n",
    "    df_clean[section] = df_clean[section].str[0]\n",
    "\n",
    "# adding DE predicted column\n",
    "preprocessor = DEModelHandler()\n",
    "fe_de = preprocessor.predict_from_model(\n",
    "    df,\n",
    "    model_path=\"../SubjectModels/de_model/de_model.joblib\",\n",
    "    return_type=\"df\"\n",
    ")\n",
    "\n",
    "# Add the predicted DE Theory marks to df_clean\n",
    "df_clean[\"Predicted DE Theory\"] = fe_de[\"Predicted DE Theory\"]\n",
    "\n",
    "\n",
    "# adding FSD predicted column\n",
    "preprocessor = FSDModelHandler()\n",
    "fe_fsd = preprocessor.predict_from_model(\n",
    "    df,\n",
    "    model_path=\"../SubjectModels/fsd_model/fsd_model.joblib\",\n",
    "    return_type=\"df\"\n",
    ")\n",
    "\n",
    "# Add the predicted FSD Theory marks to df_clean\n",
    "df_clean[\"Predicted FSD Theory\"] = fe_fsd[\"Predicted FSD Theory\"]\n",
    "\n",
    "\n",
    "# adding Math3 predicted column\n",
    "preprocessor = Math3ModelHandler()\n",
    "fe_math3 = preprocessor.predict_from_model(\n",
    "    df,\n",
    "    model_path=\"../SubjectModels/math3_model/math3_model.joblib\",\n",
    "    return_type=\"df\"\n",
    ")\n",
    "\n",
    "# Add the predicted Math3 Theory marks to df_clean\n",
    "df_clean[\"Predicted Math-3 Theory\"] = fe_math3[\"Predicted Math-3 Theory\"]\n",
    "\n",
    "\n",
    "# adding Python predicted column\n",
    "preprocessor = PythonModelHandler()\n",
    "fe_python = preprocessor.predict_from_model(\n",
    "    df,\n",
    "    model_path=\"../SubjectModels/python_model/python_model.joblib\",\n",
    "    return_type=\"df\"\n",
    ")\n",
    "\n",
    "# Add the predicted Python Theory marks to df_clean\n",
    "df_clean[\"Predicted Python Theory\"] = fe_python[\"Predicted Python Theory\"]\n",
    "\n",
    "#  Calculate predicted Semester 3 percentage (mean of 4 predicted subject marks)\n",
    "sem3_subjects = [\n",
    "    \"Predicted Math-3 Theory\",\n",
    "    \"Predicted DE Theory\",\n",
    "    \"Predicted FSD Theory\",\n",
    "    \"Predicted Python Theory\",\n",
    "]\n",
    "\n",
    "df_clean[\"Predicted Sem 3 Percentage\"] = df_clean[sem3_subjects].mean(axis=1).round(2)\n",
    "\n",
    "df_clean[\"Sem 1 Percentile\"] = df_clean[\"Sem 1 Percentage\"].rank(pct=True) * 100\n",
    "df_clean[\"Sem 2 Percentile\"] = df_clean[\"Sem 2 Percentage\"].rank(pct=True) * 100\n",
    "df_clean[\"Predicted Sem 3 Percentile\"] = df_clean[\"Predicted Sem 3 Percentage\"].rank(pct=True) * 100\n",
    "\n",
    "# Round for consistency\n",
    "df_clean[[\"Sem 1 Percentile\", \"Sem 2 Percentile\", \"Predicted Sem 3 Percentile\"]] = df_clean[\n",
    "    [\"Sem 1 Percentile\", \"Sem 2 Percentile\", \"Predicted Sem 3 Percentile\"]\n",
    "].round(2)\n",
    "\n",
    "df_clean[\"Predicted Percentile Drop\"] = (\n",
    "    df_clean[\"Sem 2 Percentile\"] - df_clean[\"Predicted Sem 3 Percentile\"]\n",
    ").round(2)\n",
    "\n",
    "df_clean[\"Predicted Risk Flag\"] = df_clean[\"Predicted Percentile Drop\"] > 10\n",
    "\n",
    "# Columns for Semester 3 core theory subjects\n",
    "sem3_columns = [\n",
    "    \"Math-3 Theory\",\n",
    "    \"DE Theory\",\n",
    "    \"FSD Theory\",\n",
    "    \"Python Theory\",\n",
    "]\n",
    "\n",
    "# Calculate Semester 3 Total as the sum of core subject scores\n",
    "df[\"Sem 3 Percentage\"] = (df[sem3_columns].sum(axis=1) / 4).round(2)\n",
    "\n",
    "df_clean[\"Sem 3 Percentile\"] = df[\"Sem 3 Percentage\"].rank(pct=True) * 100\n",
    "\n",
    "df_clean[\"Percentile Drop\"] = (\n",
    "    df_clean[\"Sem 2 Percentile\"] - df_clean[\"Sem 3 Percentile\"]\n",
    ").round(2)\n",
    "\n",
    "df_clean[\"Risk Flag\"] = df_clean[\"Percentile Drop\"] > 10\n",
    "\n",
    "columns_to_drop = [\n",
    "    \"Sem 3 Percentile\",\n",
    "    \"Percentile Drop\"\n",
    "]\n",
    "\n",
    "df_clean.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "print(df_clean.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268fddad",
   "metadata": {},
   "source": [
    "# Dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ef56866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.8000, Precision=0.0000, Recall=0.0000, F1=0.0000\n",
      "Fold 2: Accuracy=0.8000, Precision=0.0000, Recall=0.0000, F1=0.0000\n",
      "Fold 3: Accuracy=0.8000, Precision=0.0000, Recall=0.0000, F1=0.0000\n",
      "Fold 4: Accuracy=0.7931, Precision=0.0000, Recall=0.0000, F1=0.0000\n",
      "Fold 5: Accuracy=0.7986, Precision=0.0000, Recall=0.0000, F1=0.0000\n",
      "\n",
      "--- Baseline Model Summary ---\n",
      "Name                          : DummyClassifier-MostFreq\n",
      "Description                   : Baseline-MostFrequent-5Fold\n",
      "Accuracy                      : 0.7983\n",
      "Precision                     : 0.0000\n",
      "Recall                        : 0.0000\n",
      "F1 Score                      : 0.0000\n",
      "\n",
      "CSV Row Format:\n",
      "DummyClassifier-MostFreq,Baseline-MostFrequent-5Fold,0.7983,0.0000,0.0000,0.0000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Target and features\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag', 'Predicted Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# DummyClassifier â€“ always predicts the most frequent class\n",
    "dummy = DummyClassifier(strategy='most_frequent')\n",
    "\n",
    "# CV setup\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Metric storage\n",
    "accuracy_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "\n",
    "# 5-Fold Evaluation\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    dummy.fit(X_train, y_train)\n",
    "    y_pred = dummy.predict(X_val)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# Final metrics\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# Model info\n",
    "model_name = 'DummyClassifier-MostFreq'\n",
    "model_desc = 'Baseline-MostFrequent-5Fold'\n",
    "\n",
    "# Print formatted summary\n",
    "print(\"\\n--- Baseline Model Summary ---\")\n",
    "print(f\"{'Name':<30}: {model_name}\")\n",
    "print(f\"{'Description':<30}: {model_desc}\")\n",
    "print(f\"{'Accuracy':<30}: {mean_acc:.4f}\")\n",
    "print(f\"{'Precision':<30}: {mean_prec:.4f}\")\n",
    "print(f\"{'Recall':<30}: {mean_rec:.4f}\")\n",
    "print(f\"{'F1 Score':<30}: {mean_f1:.4f}\")\n",
    "\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# Save to CSV (append row, create file if not exists)\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "new_row = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "\n",
    "# Append to file (header only if file doesn't exist)\n",
    "new_row.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5ddd4c",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d9afa15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.8207, Precision=0.5385, Recall=0.7241, F1=0.6176\n",
      "Fold 2: Accuracy=0.8552, Precision=0.6176, Recall=0.7241, F1=0.6667\n",
      "Fold 3: Accuracy=0.7931, Precision=0.4889, Recall=0.7586, F1=0.5946\n",
      "Fold 4: Accuracy=0.8069, Precision=0.5217, Recall=0.8000, F1=0.6316\n",
      "Fold 5: Accuracy=0.8125, Precision=0.5250, Recall=0.7241, F1=0.6087\n",
      "\n",
      "--- Average Metrics Summary ---\n",
      "Name                          : LogisticRegression-Balanced\n",
      "Description                   : OneHot+Scaler+5Fold-Stratified\n",
      "Accuracy                      : 0.8177\n",
      "Precision                     : 0.5383\n",
      "Recall                        : 0.7462\n",
      "F1 Score                      : 0.6238\n",
      "\n",
      "CSV Row Format:\n",
      "LogisticRegression-Balanced,OneHot+Scaler+5Fold-Stratified,0.8177,0.5383,0.7462,0.6238\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import warnings\n",
    "import csv\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Step 1: Copy and split data\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag', 'Predicted Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)  # convert bool to 0/1\n",
    "\n",
    "# Step 2: Column categorization\n",
    "categorical_cols = ['Gender', 'Religion', 'Branch', 'Section-1', 'Section-2', 'Section-3']\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Step 3: Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# Step 4: Full pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('model', LogisticRegression(class_weight='balanced', max_iter=1000))\n",
    "])\n",
    "\n",
    "# Step 5: 5-Fold Stratified CV\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Metrics storage\n",
    "accuracy_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "\n",
    "# Step 6: Loop through CV\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_val)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# Step 7: Average metrics\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# Model info\n",
    "model_name = 'LogisticRegression-Balanced'\n",
    "model_desc = 'OneHot+Scaler+5Fold-Stratified'\n",
    "\n",
    "# Print: CSV-style with labels and formatting\n",
    "print(\"\\n--- Average Metrics Summary ---\")\n",
    "print(f\"{'Name':<30}: {model_name}\")\n",
    "print(f\"{'Description':<30}: {model_desc}\")\n",
    "print(f\"{'Accuracy':<30}: {mean_acc:.4f}\")\n",
    "print(f\"{'Precision':<30}: {mean_prec:.4f}\")\n",
    "print(f\"{'Recall':<30}: {mean_rec:.4f}\")\n",
    "print(f\"{'F1 Score':<30}: {mean_f1:.4f}\")\n",
    "\n",
    "# Also print as CSV row\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# Step 8: Write to file if not already present\n",
    "output_path = 'risk_model_metrics.csv'\n",
    "write_header = not os.path.exists(output_path)\n",
    "\n",
    "with open(output_path, mode='a', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    if write_header:\n",
    "        writer.writerow(['Name', 'Desc', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
    "    writer.writerow([model_name, model_desc, f\"{mean_acc:.4f}\", f\"{mean_prec:.4f}\", f\"{mean_rec:.4f}\", f\"{mean_f1:.4f}\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefdbb3e",
   "metadata": {},
   "source": [
    "# DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b37e44c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.8000, Precision=0.5000,  Recall=0.4138, F1=0.4528\n",
      "Fold 2: Accuracy=0.8414, Precision=0.7143,  Recall=0.3448, F1=0.4651\n",
      "Fold 3: Accuracy=0.7517, Precision=0.4103,  Recall=0.5517, F1=0.4706\n",
      "Fold 4: Accuracy=0.7862, Precision=0.4848,  Recall=0.5333, F1=0.5079\n",
      "Fold 5: Accuracy=0.8403, Precision=0.6250,  Recall=0.5172, F1=0.5660\n",
      "\n",
      "--- DecisionTreeClassifier Summary ---\n",
      "Mean Accuracy : 0.8039\n",
      "Mean Precision: 0.5469\n",
      "Mean Recall   : 0.4722\n",
      "Mean F1 Score : 0.4925\n",
      "\n",
      "CSV Row Format:\n",
      "DecisionTreeClassifier-Balanced,OneHot+Scaler+5Fold-Stratified,0.8039,0.5469,0.4722,0.4925\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Step 1: Prepare data\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag', 'Predicted Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# Step 2: Column categories\n",
    "categorical_cols = ['Gender', 'Religion', 'Branch', 'Section-1', 'Section-2', 'Section-3']\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Step 3: Preprocessing\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# Step 4: Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('model', DecisionTreeClassifier(class_weight='balanced', random_state=42))\n",
    "])\n",
    "\n",
    "# Step 5: Cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_val)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f},  Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# Step 6: Averages\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# Step 7: Model description\n",
    "model_name = 'DecisionTreeClassifier-Balanced'\n",
    "model_desc = 'OneHot+Scaler+5Fold-Stratified'\n",
    "\n",
    "# Console summary\n",
    "print(\"\\n--- DecisionTreeClassifier Summary ---\")\n",
    "print(f\"Mean Accuracy : {mean_acc:.4f}\")\n",
    "print(f\"Mean Precision: {mean_prec:.4f}\")\n",
    "print(f\"Mean Recall   : {mean_rec:.4f}\")\n",
    "print(f\"Mean F1 Score : {mean_f1:.4f}\")\n",
    "\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# Step 8: Save to CSV\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "result_df = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "\n",
    "# Append to CSV, add header only if file doesn't exist\n",
    "result_df.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb71471c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.6828, Precision=0.3455,  Recall=0.6552, F1=0.4524\n",
      "Fold 2: Accuracy=0.8138, Precision=0.5357,  Recall=0.5172, F1=0.5263\n",
      "Fold 3: Accuracy=0.7034, Precision=0.3750,  Recall=0.7241, F1=0.4941\n",
      "Fold 4: Accuracy=0.7517, Precision=0.4348,  Recall=0.6667, F1=0.5263\n",
      "Fold 5: Accuracy=0.7222, Precision=0.3878,  Recall=0.6552, F1=0.4872\n",
      "\n",
      "--- DecisionTree_Recall_Tuned Summary ---\n",
      "Mean Accuracy : 0.7348\n",
      "Mean Precision: 0.4157\n",
      "Mean Recall   : 0.6437\n",
      "Mean F1 Score : 0.4973\n",
      "\n",
      "CSV Row Format:\n",
      "DecisionTree-RecallTuned,Thresh=0.35|Depth=6|Split=10|Leaf=5|5Fold,0.7348,0.4157,0.6437,0.4973\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Step 1: Data setup\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag', 'Predicted Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# Step 2: Column types\n",
    "categorical_cols = ['Gender', 'Religion', 'Branch', 'Section-1', 'Section-2', 'Section-3']\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Step 3: Preprocessing\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# Step 4: Recall-tuned DecisionTree\n",
    "pipeline = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('model', DecisionTreeClassifier(\n",
    "        class_weight='balanced',\n",
    "        max_depth=6,\n",
    "        min_samples_split=10,\n",
    "        min_samples_leaf=5,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Step 5: CV setup\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n",
    "\n",
    "# Step 6: Custom threshold\n",
    "threshold = 0.35\n",
    "\n",
    "# Step 7: Cross-validation\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    y_proba = pipeline.predict_proba(X_val)[:, 1]\n",
    "    y_pred = (y_proba >= threshold).astype(int)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f},  Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# Step 8: Mean metrics\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# Step 9: Model info\n",
    "model_name = 'DecisionTree-RecallTuned'\n",
    "model_desc = f'Thresh=0.35|Depth=6|Split=10|Leaf=5|5Fold'\n",
    "\n",
    "# Console output\n",
    "print(\"\\n--- DecisionTree_Recall_Tuned Summary ---\")\n",
    "print(f\"Mean Accuracy : {mean_acc:.4f}\")\n",
    "print(f\"Mean Precision: {mean_prec:.4f}\")\n",
    "print(f\"Mean Recall   : {mean_rec:.4f}\")\n",
    "print(f\"Mean F1 Score : {mean_f1:.4f}\")\n",
    "\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# Step 10: Save to CSV\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "result_df = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "\n",
    "result_df.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee992bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.8000, Precision=0.5000,  Recall=0.4138, F1=0.4528\n",
      "Fold 2: Accuracy=0.8414, Precision=0.7143,  Recall=0.3448, F1=0.4651\n",
      "Fold 3: Accuracy=0.7517, Precision=0.4103,  Recall=0.5517, F1=0.4706\n",
      "Fold 4: Accuracy=0.7862, Precision=0.4848,  Recall=0.5333, F1=0.5079\n",
      "Fold 5: Accuracy=0.8403, Precision=0.6250,  Recall=0.5172, F1=0.5660\n",
      "\n",
      "--- DecisionTree_MaxRecall Summary ---\n",
      "Mean Accuracy : 0.8039\n",
      "Mean Precision: 0.5469\n",
      "Mean Recall   : 0.4722\n",
      "Mean F1 Score : 0.4925\n",
      "\n",
      "CSV Row Format:\n",
      "DecisionTree-MaxRecall,Depth=None|Split=2|Leaf=1|Thresh=0.25|5Fold,0.8039,0.5469,0.4722,0.4925\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Step 1: Data setup\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag', 'Predicted Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "categorical_cols = ['Gender', 'Religion', 'Branch', 'Section-1', 'Section-2', 'Section-3']\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Step 2: Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# Step 3: Flexible (deep) DecisionTreeClassifier\n",
    "pipeline = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('model', DecisionTreeClassifier(\n",
    "        class_weight='balanced',\n",
    "        max_depth=None,             # no limit\n",
    "        min_samples_split=2,        # fine splits\n",
    "        min_samples_leaf=1,         # small leaves allowed\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Step 4: Cross-validation config\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n",
    "\n",
    "# Step 5: Threshold\n",
    "threshold = 0.25  # aggressive threshold to maximize recall\n",
    "\n",
    "# Step 6: CV loop\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_proba = pipeline.predict_proba(X_val)[:, 1]\n",
    "    y_pred = (y_proba >= threshold).astype(int)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f},  Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# Step 7: Aggregate results\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# Step 8: Metadata\n",
    "model_name = 'DecisionTree-MaxRecall'\n",
    "model_desc = 'Depth=None|Split=2|Leaf=1|Thresh=0.25|5Fold'\n",
    "\n",
    "print(\"\\n--- DecisionTree_MaxRecall Summary ---\")\n",
    "print(f\"Mean Accuracy : {mean_acc:.4f}\")\n",
    "print(f\"Mean Precision: {mean_prec:.4f}\")\n",
    "print(f\"Mean Recall   : {mean_rec:.4f}\")\n",
    "print(f\"Mean F1 Score : {mean_f1:.4f}\")\n",
    "\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# Step 9: Save to CSV\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "result_df = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "result_df.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a643a2d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.7586, Precision=0.4400, Recall=0.7586, F1=0.5570\n",
      "Fold 2: Accuracy=0.7517, Precision=0.4255, Recall=0.6897, F1=0.5263\n",
      "Fold 3: Accuracy=0.7241, Precision=0.3922, Recall=0.6897, F1=0.5000\n",
      "Fold 4: Accuracy=0.8069, Precision=0.5200, Recall=0.8667, F1=0.6500\n",
      "Fold 5: Accuracy=0.7500, Precision=0.4340, Recall=0.7931, F1=0.5610\n",
      "\n",
      "--- DecisionTree_SMOTE Summary ---\n",
      "Mean Accuracy : 0.7583\n",
      "Mean Precision: 0.4423\n",
      "Mean Recall   : 0.7595\n",
      "Mean F1 Score : 0.5589\n",
      "\n",
      "CSV Row Format:\n",
      "DecisionTree-SMOTE,Thresh=0.35|Depth=6|Split=10|Leaf=5|5Fold|SMOTE,0.7583,0.4423,0.7595,0.5589\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Step 1: Data setup\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag', 'Predicted Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# Step 2: Column types\n",
    "categorical_cols = ['Gender', 'Religion', 'Branch', 'Section-1', 'Section-2', 'Section-3']\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Step 3: Preprocessing\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# Step 4: SMOTE setup\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "# Step 5: Recall-tuned DecisionTree\n",
    "pipeline = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('model', DecisionTreeClassifier(\n",
    "        max_depth=6,\n",
    "        min_samples_split=10,\n",
    "        min_samples_leaf=5,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Step 6: CV setup\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n",
    "\n",
    "# Step 7: Custom threshold\n",
    "threshold = 0.35\n",
    "\n",
    "# Step 8: Cross-validation with SMOTE\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    # Apply SMOTE to training data\n",
    "    X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "    X_train_smote, y_train_smote = smote.fit_resample(X_train_preprocessed, y_train)\n",
    "\n",
    "    # Fit the model on SMOTE-resampled data\n",
    "    pipeline.named_steps['model'].fit(X_train_smote, y_train_smote)\n",
    "\n",
    "    # Transform validation data\n",
    "    X_val_preprocessed = preprocessor.transform(X_val)\n",
    "    y_proba = pipeline.named_steps['model'].predict_proba(X_val_preprocessed)[:, 1]\n",
    "    y_pred = (y_proba >= threshold).astype(int)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# Step 9: Mean metrics\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# Step 10: Model info\n",
    "model_name = 'DecisionTree-SMOTE'\n",
    "model_desc = f'Thresh=0.35|Depth=6|Split=10|Leaf=5|5Fold|SMOTE'\n",
    "\n",
    "# Console output\n",
    "print(\"\\n--- DecisionTree_SMOTE Summary ---\")\n",
    "print(f\"Mean Accuracy : {mean_acc:.4f}\")\n",
    "print(f\"Mean Precision: {mean_prec:.4f}\")\n",
    "print(f\"Mean Recall   : {mean_rec:.4f}\")\n",
    "print(f\"Mean F1 Score : {mean_f1:.4f}\")\n",
    "\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# Step 11: Save to CSV\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "result_df = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "\n",
    "result_df.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a761db51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.7931, Precision=0.4878, Recall=0.6897, F1=0.5714\n",
      "Fold 2: Accuracy=0.7586, Precision=0.4167, Recall=0.5172, F1=0.4615\n",
      "Fold 3: Accuracy=0.7103, Precision=0.3818, Recall=0.7241, F1=0.5000\n",
      "Fold 4: Accuracy=0.7241, Precision=0.4107, Recall=0.7667, F1=0.5349\n",
      "Fold 5: Accuracy=0.8125, Precision=0.5238, Recall=0.7586, F1=0.6197\n",
      "\n",
      "--- DecisionTree_SMOTE_RecallOptimized Summary ---\n",
      "Mean Accuracy : 0.7597\n",
      "Mean Precision: 0.4442\n",
      "Mean Recall   : 0.6913\n",
      "Mean F1 Score : 0.5375\n",
      "\n",
      "CSV Row Format:\n",
      "DecisionTree-SMOTE-RecallOptimized,Thresh=0.25|Depth=6|Split=10|Leaf=3|5Fold|SMOTE_0.8,0.7597,0.4442,0.6913,0.5375\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Step 1: Data setup\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag', 'Predicted Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# Step 2: Column types\n",
    "categorical_cols = ['Gender', 'Religion', 'Branch', 'Section-1', 'Section-2', 'Section-3']\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Step 3: Preprocessing\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# Step 4: SMOTE setup with adjusted sampling strategy\n",
    "smote = SMOTE(sampling_strategy=0.8, random_state=42)\n",
    "\n",
    "# Step 5: Recall-optimized DecisionTree\n",
    "pipeline = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('model', DecisionTreeClassifier(\n",
    "        max_depth=6,\n",
    "        min_samples_split=10,\n",
    "        min_samples_leaf=3,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Step 6: CV setup\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n",
    "\n",
    "# Step 7: Lowered threshold for higher recall\n",
    "threshold = 0.25\n",
    "\n",
    "# Step 8: Cross-validation with SMOTE\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    # Apply SMOTE to training data\n",
    "    X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "    X_train_smote, y_train_smote = smote.fit_resample(X_train_preprocessed, y_train)\n",
    "\n",
    "    # Fit the model on SMOTE-resampled data\n",
    "    pipeline.named_steps['model'].fit(X_train_smote, y_train_smote)\n",
    "\n",
    "    # Transform validation data\n",
    "    X_val_preprocessed = preprocessor.transform(X_val)\n",
    "    y_proba = pipeline.named_steps['model'].predict_proba(X_val_preprocessed)[:, 1]\n",
    "    y_pred = (y_proba >= threshold).astype(int)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# Step 9: Mean metrics\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# Step 10: Model info\n",
    "model_name = 'DecisionTree-SMOTE-RecallOptimized'\n",
    "model_desc = f'Thresh=0.25|Depth=6|Split=10|Leaf=3|5Fold|SMOTE_0.8'\n",
    "\n",
    "# Console output\n",
    "print(\"\\n--- DecisionTree_SMOTE_RecallOptimized Summary ---\")\n",
    "print(f\"Mean Accuracy : {mean_acc:.4f}\")\n",
    "print(f\"Mean Precision: {mean_prec:.4f}\")\n",
    "print(f\"Mean Recall   : {mean_rec:.4f}\")\n",
    "print(f\"Mean F1 Score : {mean_f1:.4f}\")\n",
    "\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# Step 11: Save to CSV\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "result_df = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "\n",
    "result_df.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58706e3",
   "metadata": {},
   "source": [
    "# RandomForestClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9de4e23a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.8138, Precision=0.7500,  Recall=0.1034, F1=0.1818\n",
      "Fold 2: Accuracy=0.8276, Precision=0.8333,  Recall=0.1724, F1=0.2857\n",
      "Fold 3: Accuracy=0.8345, Precision=0.8571,  Recall=0.2069, F1=0.3333\n",
      "Fold 4: Accuracy=0.8345, Precision=0.8000,  Recall=0.2667, F1=0.4000\n",
      "Fold 5: Accuracy=0.8403, Precision=0.8750,  Recall=0.2414, F1=0.3784\n",
      "\n",
      "--- RandomForestClassifier Summary ---\n",
      "Mean Accuracy : 0.8301\n",
      "Mean Precision: 0.8231\n",
      "Mean Recall   : 0.1982\n",
      "Mean F1 Score : 0.3158\n",
      "\n",
      "CSV Row Format:\n",
      "RandomForestClassifier-Balanced,OneHot+Scaler+5Fold-Stratified,0.8301,0.8231,0.1982,0.3158\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Step 1: Prepare data\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag', 'Predicted Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# Step 2: Column categories\n",
    "categorical_cols = ['Gender', 'Religion', 'Branch', 'Section-1', 'Section-2', 'Section-3']\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Step 3: Preprocessing\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# Step 4: Pipeline with Random Forest\n",
    "pipeline = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('model', RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=None,\n",
    "        class_weight='balanced',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Step 5: Cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_val)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f},  Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# Step 6: Averages\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# Step 7: Model description\n",
    "model_name = 'RandomForestClassifier-Balanced'\n",
    "model_desc = 'OneHot+Scaler+5Fold-Stratified'\n",
    "\n",
    "# Console summary\n",
    "print(\"\\n--- RandomForestClassifier Summary ---\")\n",
    "print(f\"Mean Accuracy : {mean_acc:.4f}\")\n",
    "print(f\"Mean Precision: {mean_prec:.4f}\")\n",
    "print(f\"Mean Recall   : {mean_rec:.4f}\")\n",
    "print(f\"Mean F1 Score : {mean_f1:.4f}\")\n",
    "\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# Step 8: Save to CSV\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "result_df = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "\n",
    "# Append to CSV, add header only if file doesn't exist\n",
    "result_df.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8d374e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.7586, Precision=0.4348, Recall=0.6897, F1=0.5333\n",
      "Fold 2: Accuracy=0.7724, Precision=0.4545, Recall=0.6897, F1=0.5479\n",
      "Fold 3: Accuracy=0.6690, Precision=0.3582, Recall=0.8276, F1=0.5000\n",
      "Fold 4: Accuracy=0.6552, Precision=0.3649, Recall=0.9000, F1=0.5192\n",
      "Fold 5: Accuracy=0.6875, Precision=0.3621, Recall=0.7241, F1=0.4828\n",
      "\n",
      "--- Average Metrics Summary ---\n",
      "Name                          : RandomForest-SMOTE-Threshold0.3\n",
      "Description                   : OneHot+Scaler+SMOTE+RF+Threshold=0.3\n",
      "Accuracy                      : 0.7085\n",
      "Precision                     : 0.3949\n",
      "Recall                        : 0.7662\n",
      "F1 Score                      : 0.5167\n",
      "\n",
      "CSV Row Format:\n",
      "RandomForest-SMOTE-Threshold0.3,OneHot+Scaler+SMOTE+RF+Threshold=0.3,0.7085,0.3949,0.7662,0.5167\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "import warnings\n",
    "import csv\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Step 1: Copy and split data\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag', 'Predicted Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)  # convert bool to 0/1\n",
    "\n",
    "# Step 2: Column categorization\n",
    "categorical_cols = ['Gender', 'Religion', 'Branch', 'Section-1', 'Section-2', 'Section-3']\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Step 3: Preprocessing\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# Step 4: Full pipeline with SMOTE + RandomForest\n",
    "pipeline = ImbPipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('model', RandomForestClassifier(\n",
    "        n_estimators=200,\n",
    "        max_depth=None,\n",
    "        class_weight='balanced',\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Step 5: 5-Fold Stratified CV\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Metrics storage\n",
    "accuracy_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "\n",
    "threshold = 0.3  # Custom threshold to maximize recall\n",
    "\n",
    "# Step 6: Loop through CV\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_proba = pipeline.predict_proba(X_val)[:, 1]  # Get probability for class 1\n",
    "\n",
    "    y_pred = (y_proba >= threshold).astype(int)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# Step 7: Average metrics\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# Model info\n",
    "model_name = 'RandomForest-SMOTE-Threshold0.3'\n",
    "model_desc = 'OneHot+Scaler+SMOTE+RF+Threshold=0.3'\n",
    "\n",
    "# Print: CSV-style with labels and formatting\n",
    "print(\"\\n--- Average Metrics Summary ---\")\n",
    "print(f\"{'Name':<30}: {model_name}\")\n",
    "print(f\"{'Description':<30}: {model_desc}\")\n",
    "print(f\"{'Accuracy':<30}: {mean_acc:.4f}\")\n",
    "print(f\"{'Precision':<30}: {mean_prec:.4f}\")\n",
    "print(f\"{'Recall':<30}: {mean_rec:.4f}\")\n",
    "print(f\"{'F1 Score':<30}: {mean_f1:.4f}\")\n",
    "\n",
    "# Also print as CSV row\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# Step 8: Write to file if not already present\n",
    "output_path = 'risk_model_metrics.csv'\n",
    "write_header = not os.path.exists(output_path)\n",
    "\n",
    "with open(output_path, mode='a', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    if write_header:\n",
    "        writer.writerow(['Name', 'Desc', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
    "    writer.writerow([model_name, model_desc, f\"{mean_acc:.4f}\", f\"{mean_prec:.4f}\", f\"{mean_rec:.4f}\", f\"{mean_f1:.4f}\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf804d22",
   "metadata": {},
   "source": [
    "# XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66ba5f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.8414, Precision=0.6500,  Recall=0.4483, F1=0.5306\n",
      "Fold 2: Accuracy=0.8759, Precision=0.7619,  Recall=0.5517, F1=0.6400\n",
      "Fold 3: Accuracy=0.8138, Precision=0.5278,  Recall=0.6552, F1=0.5846\n",
      "Fold 4: Accuracy=0.8414, Precision=0.6061,  Recall=0.6667, F1=0.6349\n",
      "Fold 5: Accuracy=0.8958, Precision=0.7917,  Recall=0.6552, F1=0.7170\n",
      "\n",
      "--- XGBoost Summary ---\n",
      "Mean Accuracy : 0.8536\n",
      "Mean Precision: 0.6675\n",
      "Mean Recall   : 0.5954\n",
      "Mean F1 Score : 0.6214\n",
      "\n",
      "CSV Row Format:\n",
      "XGBoost-Balanced,OneHot+Scaler+5Fold-Stratified,0.8536,0.6675,0.5954,0.6214\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Step 1: Prepare data\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag', 'Predicted Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# Step 2: Column categories\n",
    "categorical_cols = ['Gender', 'Religion', 'Branch', 'Section-1', 'Section-2', 'Section-3']\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Step 3: Preprocessing\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# Step 4: XGBoost Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('model', XGBClassifier(\n",
    "        objective='binary:logistic',\n",
    "        eval_metric='logloss',\n",
    "        scale_pos_weight=np.sum(y == 0) / np.sum(y == 1),  # Handles class imbalance\n",
    "        use_label_encoder=False,\n",
    "        n_estimators=100,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.1,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Step 5: Cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_val)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f},  Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# Step 6: Averages\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# Step 7: Model description\n",
    "model_name = 'XGBoost-Balanced'\n",
    "model_desc = 'OneHot+Scaler+5Fold-Stratified'\n",
    "\n",
    "# Console summary\n",
    "print(\"\\n--- XGBoost Summary ---\")\n",
    "print(f\"Mean Accuracy : {mean_acc:.4f}\")\n",
    "print(f\"Mean Precision: {mean_prec:.4f}\")\n",
    "print(f\"Mean Recall   : {mean_rec:.4f}\")\n",
    "print(f\"Mean F1 Score : {mean_f1:.4f}\")\n",
    "\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# Step 8: Save to CSV\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "result_df = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "\n",
    "# Append to CSV, add header only if file doesn't exist\n",
    "result_df.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b66f051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.8690, Precision=0.6250, Recall=0.8621, F1=0.7246\n",
      "Fold 2: Accuracy=0.8621, Precision=0.6452, Recall=0.6897, F1=0.6667\n",
      "Fold 3: Accuracy=0.7586, Precision=0.4400, Recall=0.7586, F1=0.5570\n",
      "Fold 4: Accuracy=0.8345, Precision=0.5750, Recall=0.7667, F1=0.6571\n",
      "Fold 5: Accuracy=0.8125, Precision=0.5238, Recall=0.7586, F1=0.6197\n",
      "\n",
      "--- Average Metrics Summary ---\n",
      "Name                          : XGBoost-SMOTE-Threshold0.25\n",
      "Description                   : OneHot+Scaler+SMOTE+XGB+Threshold=0.25\n",
      "Accuracy                      : 0.8273\n",
      "Precision                     : 0.5618\n",
      "Recall                        : 0.7671\n",
      "F1 Score                      : 0.6450\n",
      "\n",
      "CSV Row Format:\n",
      "XGBoost-SMOTE-Threshold0.25,OneHot+Scaler+SMOTE+XGB+Threshold=0.25,0.8273,0.5618,0.7671,0.6450\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from xgboost import XGBClassifier\n",
    "import warnings\n",
    "import csv\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Step 1: Copy and split data\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag', 'Predicted Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# Step 2: Column categorization\n",
    "categorical_cols = ['Gender', 'Religion', 'Branch', 'Section-1', 'Section-2', 'Section-3']\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Step 3: Preprocessing\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# Step 4: Pipeline with XGBoost + SMOTE\n",
    "pipeline = ImbPipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('model', XGBClassifier(\n",
    "        use_label_encoder=False,\n",
    "        eval_metric='logloss',\n",
    "        scale_pos_weight=4,  # 80:20 class balance\n",
    "        n_estimators=200,\n",
    "        max_depth=5,\n",
    "        learning_rate=0.1,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Step 5: Stratified 5-Fold CV\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Step 6: Metrics storage\n",
    "accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n",
    "\n",
    "# Threshold for classification\n",
    "threshold = 0.25\n",
    "\n",
    "# Step 7: CV loop\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_proba = pipeline.predict_proba(X_val)[:, 1]\n",
    "    y_pred = (y_proba >= threshold).astype(int)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# Step 8: Average metrics\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# Model info\n",
    "model_name = 'XGBoost-SMOTE-Threshold0.25'\n",
    "model_desc = 'OneHot+Scaler+SMOTE+XGB+Threshold=0.25'\n",
    "\n",
    "# Step 9: Print metrics\n",
    "print(\"\\n--- Average Metrics Summary ---\")\n",
    "print(f\"{'Name':<30}: {model_name}\")\n",
    "print(f\"{'Description':<30}: {model_desc}\")\n",
    "print(f\"{'Accuracy':<30}: {mean_acc:.4f}\")\n",
    "print(f\"{'Precision':<30}: {mean_prec:.4f}\")\n",
    "print(f\"{'Recall':<30}: {mean_rec:.4f}\")\n",
    "print(f\"{'F1 Score':<30}: {mean_f1:.4f}\")\n",
    "\n",
    "# Also print as CSV row\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# Step 10: Write to file if not already present\n",
    "output_path = 'risk_model_metrics.csv'\n",
    "write_header = not os.path.exists(output_path)\n",
    "\n",
    "with open(output_path, mode='a', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    if write_header:\n",
    "        writer.writerow(['Name', 'Desc', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
    "    writer.writerow([model_name, model_desc, f\"{mean_acc:.4f}\", f\"{mean_prec:.4f}\", f\"{mean_rec:.4f}\", f\"{mean_f1:.4f}\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23024535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 324 candidates, totalling 1620 fits\n",
      "Best Parameters: {'model__colsample_bytree': 0.8, 'model__learning_rate': 0.01, 'model__max_depth': 6, 'model__min_child_weight': 3, 'model__n_estimators': 300, 'model__subsample': 0.8}\n",
      "Fold 1: Accuracy=0.6207, Precision=0.3415, Recall=0.9655, F1=0.5045, Best Threshold=0.10\n",
      "Fold 2: Accuracy=0.6138, Precision=0.3333, Recall=0.9310, F1=0.4909, Best Threshold=0.10\n",
      "Fold 3: Accuracy=0.5586, Precision=0.3034, Recall=0.9310, F1=0.4576, Best Threshold=0.10\n",
      "Fold 4: Accuracy=0.5448, Precision=0.3125, Recall=1.0000, F1=0.4762, Best Threshold=0.10\n",
      "Fold 5: Accuracy=0.5000, Precision=0.2828, Recall=0.9655, F1=0.4375, Best Threshold=0.10\n",
      "\n",
      "--- Fine-Tuned XGBoost Summary ---\n",
      "Mean Accuracy : 0.5676\n",
      "Mean Precision: 0.3147\n",
      "Mean Recall   : 0.9586\n",
      "Mean F1 Score : 0.4733\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Step 1: Prepare data\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag', 'Predicted Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "categorical_cols = ['Gender', 'Religion', 'Branch', 'Section-1', 'Section-2', 'Section-3']\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Step 2: Preprocessing\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# Step 3: Pipeline with SMOTE\n",
    "pipeline = ImbPipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('model', XGBClassifier(\n",
    "        objective='binary:logistic',\n",
    "        use_label_encoder=False,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Step 4: Hyperparameter Optimization\n",
    "param_grid = {\n",
    "    'model__n_estimators': [100, 200, 300],\n",
    "    'model__max_depth': [4, 6, 8],\n",
    "    'model__learning_rate': [0.01, 0.1, 0.2],\n",
    "    'model__min_child_weight': [1, 3, 5],\n",
    "    'model__subsample': [0.8, 1.0],\n",
    "    'model__colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    scoring='f1',\n",
    "    cv=cv,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Step 5: Dynamic Threshold Tuning\n",
    "best_model = grid_search.best_estimator_\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "\n",
    "accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n",
    "thresholds = np.linspace(0.1, 0.9, 9)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    best_model.fit(X_train, y_train)\n",
    "    y_proba = best_model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    # Dynamic threshold tuning for recall\n",
    "    recalls = [recall_score(y_val, (y_proba >= t).astype(int)) for t in thresholds]\n",
    "    best_threshold = thresholds[np.argmax(recalls)]\n",
    "\n",
    "    y_pred = (y_proba >= best_threshold).astype(int)\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}, F1={f1:.4f}, Best Threshold={best_threshold:.2f}\")\n",
    "\n",
    "# Step 6: Aggregate Results\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# Step 7: Summary\n",
    "model_name = 'XGBoost-SMOTE-FineTuned'\n",
    "model_desc = f'OptimizedParams|DynamicThresh={best_threshold:.2f}|OneHot+Scaler'\n",
    "\n",
    "print(\"\\n--- Fine-Tuned XGBoost Summary ---\")\n",
    "print(f\"Mean Accuracy : {mean_acc:.4f}\")\n",
    "print(f\"Mean Precision: {mean_prec:.4f}\")\n",
    "print(f\"Mean Recall   : {mean_rec:.4f}\")\n",
    "print(f\"Mean F1 Score : {mean_f1:.4f}\")\n",
    "\n",
    "# Step 8: Save to CSV\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "result_df = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "result_df.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9cc6f567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 972 candidates, totalling 4860 fits\n",
      "Best Parameters: {'model__colsample_bytree': 0.8, 'model__learning_rate': 0.05, 'model__max_depth': 8, 'model__min_child_weight': 5, 'model__n_estimators': 300, 'model__scale_pos_weight': 4, 'model__subsample': 0.8}\n",
      "Fold 1: Accuracy=0.9241, Precision=0.8462, Recall=0.7586, F1=0.8000, Best Threshold=0.60\n",
      "Fold 2: Accuracy=0.8759, Precision=0.6897, Recall=0.6897, F1=0.6897, Best Threshold=0.40\n",
      "Fold 3: Accuracy=0.8207, Precision=0.5405, Recall=0.6897, F1=0.6061, Best Threshold=0.60\n",
      "Fold 4: Accuracy=0.8552, Precision=0.6452, Recall=0.6667, F1=0.6557, Best Threshold=0.70\n",
      "Fold 5: Accuracy=0.8681, Precision=0.6786, Recall=0.6552, F1=0.6667, Best Threshold=0.70\n",
      "\n",
      "--- Fine-Tuned XGBoost Summary ---\n",
      "Mean Accuracy : 0.8688\n",
      "Mean Precision: 0.6800\n",
      "Mean Recall   : 0.6920\n",
      "Mean F1 Score : 0.6836\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Step 1: Prepare data\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag', 'Predicted Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "categorical_cols = ['Gender', 'Religion', 'Branch', 'Section-1', 'Section-2', 'Section-3']\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Step 2: Preprocessing\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# Step 3: Pipeline with SMOTE\n",
    "pipeline = ImbPipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('model', XGBClassifier(\n",
    "        objective='binary:logistic',\n",
    "        use_label_encoder=False,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Step 4: Hyperparameter Optimization\n",
    "param_grid = {\n",
    "    'model__n_estimators': [200, 300, 400],\n",
    "    'model__max_depth': [4, 6, 8],\n",
    "    'model__learning_rate': [0.01, 0.05, 0.1],\n",
    "    'model__min_child_weight': [1, 3, 5],\n",
    "    'model__subsample': [0.8, 1.0],\n",
    "    'model__colsample_bytree': [0.8, 1.0],\n",
    "    'model__scale_pos_weight': [4, 5, 6]  # Adjusted for imbalance\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    scoring='balanced_accuracy',  # Balances true positive/negative rates\n",
    "    cv=cv,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Step 5: Dynamic Threshold Tuning\n",
    "best_model = grid_search.best_estimator_\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "\n",
    "accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n",
    "thresholds = np.linspace(0.1, 0.9, 9)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    best_model.fit(X_train, y_train)\n",
    "    y_proba = best_model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    # Dynamic threshold tuning for F1\n",
    "    f1_scores = [f1_score(y_val, (y_proba >= t).astype(int)) for t in thresholds]\n",
    "    best_threshold = thresholds[np.argmax(f1_scores)]\n",
    "\n",
    "    y_pred = (y_proba >= best_threshold).astype(int)\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}, F1={f1:.4f}, Best Threshold={best_threshold:.2f}\")\n",
    "\n",
    "# Step 6: Aggregate Results\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# Step 7: Summary\n",
    "model_name = 'XGBoost-SMOTE-FineTuned-Balanced'\n",
    "model_desc = f'OptimizedParams|DynamicThresh={best_threshold:.2f}|OneHot+Scaler'\n",
    "\n",
    "print(\"\\n--- Fine-Tuned XGBoost Summary ---\")\n",
    "print(f\"Mean Accuracy : {mean_acc:.4f}\")\n",
    "print(f\"Mean Precision: {mean_prec:.4f}\")\n",
    "print(f\"Mean Recall   : {mean_rec:.4f}\")\n",
    "print(f\"Mean F1 Score : {mean_f1:.4f}\")\n",
    "\n",
    "# Step 8: Save to CSV\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "result_df = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "result_df.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a727782",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
