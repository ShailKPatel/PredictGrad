{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38157fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Gender Religion Branch Section-1 Section-2 Section-3  Roll-1  Math-1 Theory  \\\n",
      "0      M    Hindu     CE         D         D         A     350             47   \n",
      "1      F    Hindu    CST         B         B         D      18             84   \n",
      "2      F    Hindu   AIML         A         A         C      23             74   \n",
      "3      M    Hindu    CST         B         B         D     212             55   \n",
      "4      M    Hindu    CST         B         B         D     208             38   \n",
      "\n",
      "   Physics Theory  Physics Practical  ...  Predicted FSD Theory  \\\n",
      "0              48                 75  ...             72.266535   \n",
      "1              83                 81  ...             87.523458   \n",
      "2              85                 86  ...             89.409752   \n",
      "3              69                 82  ...             79.807055   \n",
      "4              59                 74  ...             56.474296   \n",
      "\n",
      "   Predicted Math-3 Theory  Predicted Python Theory  \\\n",
      "0                56.352210                71.642156   \n",
      "1                82.966865                81.393865   \n",
      "2                76.982002                86.897293   \n",
      "3                67.253716                74.606764   \n",
      "4                51.995650                53.483393   \n",
      "\n",
      "   Predicted Sem 3 Percentage  Sem 1 Percentile  Sem 2 Percentile  \\\n",
      "0                       64.14             26.38             30.66   \n",
      "1                       83.40             95.99             84.39   \n",
      "2                       83.49             92.47             91.16   \n",
      "3                       72.31             66.30             51.59   \n",
      "4                       53.42             15.68             11.53   \n",
      "\n",
      "   Predicted Sem 3 Percentile  Predicted Percentile Drop  Predicted Risk Flag  \\\n",
      "0                       38.26                      -7.60                False   \n",
      "1                       88.54                      -4.15                False   \n",
      "2                       88.81                       2.35                False   \n",
      "3                       61.26                      -9.67                False   \n",
      "4                       15.47                      -3.94                False   \n",
      "\n",
      "   Risk Flag  \n",
      "0      False  \n",
      "1      False  \n",
      "2      False  \n",
      "3      False  \n",
      "4      False  \n",
      "\n",
      "[5 rows x 50 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Ensure the path to the DEModelHandler is correct\n",
    "sys.path.append(os.path.abspath(\"../SubjectModels/de_model\"))\n",
    "from de_handler import DEModelHandler  \n",
    "\n",
    "# Ensure the path to the FSDModelHandler is correct\n",
    "sys.path.append(os.path.abspath(\"../SubjectModels/fsd_model\"))\n",
    "from fsd_handler import FSDModelHandler  \n",
    "\n",
    "# Ensure the path to the Math3ModelHandler is correct\n",
    "sys.path.append(os.path.abspath(\"../SubjectModels/math3_model\"))\n",
    "from math3_handler import Math3ModelHandler  \n",
    "\n",
    "# Ensure the path to the PythonModelHandler is correct\n",
    "sys.path.append(os.path.abspath(\"../SubjectModels/python_model\"))\n",
    "from python_handler import PythonModelHandler  \n",
    "\n",
    "df = pd.read_csv(\"../../dataset/train_dataset.csv\")\n",
    "\n",
    "# Drop the irrelevant, data leak columns\n",
    "df_clean = df.drop(\n",
    "    columns=[\n",
    "        \"Student ID\",\n",
    "        \"Mentor-1\",\n",
    "        \"Mentor-2\",\n",
    "        \"Mentor-3\",\n",
    "        \"Roll-2\",\n",
    "        \"Roll-3\",\n",
    "        \"Math-3 Theory\",\n",
    "        \"DE Theory\",\n",
    "        \"DE Practical\",\n",
    "        \"FSD Theory\",\n",
    "        \"FSD Practical\",\n",
    "        \"Python Theory\",\n",
    "        \"Python Practical\",\n",
    "        \"Communication Theory\",\n",
    "        \"Law Theory\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "# columns for Semester 1 core subjects\n",
    "sem1_columns = [\n",
    "    \"Math-1 Theory\",\n",
    "    \"Physics Theory\",\n",
    "    \"Java-1 Theory\",\n",
    "    \"Software Engineering Theory\",\n",
    "]\n",
    "\n",
    "# Calculate Semester 1 Percentage as the average of core subject scores\n",
    "# scores are numerical and out of 100\n",
    "df_clean[\"Sem 1 Percentage\"] = df_clean[sem1_columns].mean(axis=1).round(2)\n",
    "\n",
    "# columns for Semester 2 core subjects\n",
    "sem2_columns = [\n",
    "    \"Math-2 Theory\",\n",
    "    \"Data Structures using Java Theory\",\n",
    "    \"DBMS Theory\",\n",
    "    \"Fundamental of Electronics and Electrical Theory\",\n",
    "    \"Java-2 Theory\",\n",
    "]\n",
    "\n",
    "# Calculate Semester 2 Percentage as the average of core subject scores\n",
    "# scores are numerical and out of 100\n",
    "df_clean[\"Sem 2 Percentage\"] = df_clean[sem2_columns].mean(axis=1).round(2)\n",
    "\n",
    "# Rename columns Div-1, Div-2, Div-3 to Section-1, Section-2, Section-3\n",
    "df_clean = df_clean.rename(\n",
    "    columns={\"Div-1\": \"Section-1\", \"Div-2\": \"Section-2\", \"Div-3\": \"Section-3\"}\n",
    ")\n",
    "\n",
    "# Transform values in Section-1, Section-2, Section-3 to keep only the first character\n",
    "# Thus we get Only Department\n",
    "for section in [\"Section-1\", \"Section-2\", \"Section-3\"]:\n",
    "    df_clean[section] = df_clean[section].str[0]\n",
    "\n",
    "# adding DE predicted column\n",
    "preprocessor = DEModelHandler()\n",
    "fe_de = preprocessor.predict_from_model(\n",
    "    df,\n",
    "    model_path=\"../SubjectModels/de_model/de_model.joblib\",\n",
    "    return_type=\"df\"\n",
    ")\n",
    "\n",
    "# Add the predicted DE Theory marks to df_clean\n",
    "df_clean[\"Predicted DE Theory\"] = fe_de[\"Predicted DE Theory\"]\n",
    "\n",
    "\n",
    "# adding FSD predicted column\n",
    "preprocessor = FSDModelHandler()\n",
    "fe_fsd = preprocessor.predict_from_model(\n",
    "    df,\n",
    "    model_path=\"../SubjectModels/fsd_model/fsd_model.joblib\",\n",
    "    return_type=\"df\"\n",
    ")\n",
    "\n",
    "# Add the predicted FSD Theory marks to df_clean\n",
    "df_clean[\"Predicted FSD Theory\"] = fe_fsd[\"Predicted FSD Theory\"]\n",
    "\n",
    "\n",
    "# adding Math3 predicted column\n",
    "preprocessor = Math3ModelHandler()\n",
    "fe_math3 = preprocessor.predict_from_model(\n",
    "    df,\n",
    "    model_path=\"../SubjectModels/math3_model/math3_model.joblib\",\n",
    "    return_type=\"df\"\n",
    ")\n",
    "\n",
    "# Add the predicted Math3 Theory marks to df_clean\n",
    "df_clean[\"Predicted Math-3 Theory\"] = fe_math3[\"Predicted Math-3 Theory\"]\n",
    "\n",
    "\n",
    "# adding Python predicted column\n",
    "preprocessor = PythonModelHandler()\n",
    "fe_python = preprocessor.predict_from_model(\n",
    "    df,\n",
    "    model_path=\"../SubjectModels/python_model/python_model.joblib\",\n",
    "    return_type=\"df\"\n",
    ")\n",
    "\n",
    "# Add the predicted Python Theory marks to df_clean\n",
    "df_clean[\"Predicted Python Theory\"] = fe_python[\"Predicted Python Theory\"]\n",
    "\n",
    "#  Calculate predicted Semester 3 percentage (mean of 4 predicted subject marks)\n",
    "sem3_subjects = [\n",
    "    \"Predicted Math-3 Theory\",\n",
    "    \"Predicted DE Theory\",\n",
    "    \"Predicted FSD Theory\",\n",
    "    \"Predicted Python Theory\",\n",
    "]\n",
    "\n",
    "df_clean[\"Predicted Sem 3 Percentage\"] = df_clean[sem3_subjects].mean(axis=1).round(2)\n",
    "\n",
    "df_clean[\"Sem 1 Percentile\"] = df_clean[\"Sem 1 Percentage\"].rank(pct=True) * 100\n",
    "df_clean[\"Sem 2 Percentile\"] = df_clean[\"Sem 2 Percentage\"].rank(pct=True) * 100\n",
    "df_clean[\"Predicted Sem 3 Percentile\"] = df_clean[\"Predicted Sem 3 Percentage\"].rank(pct=True) * 100\n",
    "\n",
    "# Round for consistency\n",
    "df_clean[[\"Sem 1 Percentile\", \"Sem 2 Percentile\", \"Predicted Sem 3 Percentile\"]] = df_clean[\n",
    "    [\"Sem 1 Percentile\", \"Sem 2 Percentile\", \"Predicted Sem 3 Percentile\"]\n",
    "].round(2)\n",
    "\n",
    "df_clean[\"Predicted Percentile Drop\"] = (\n",
    "    df_clean[\"Sem 2 Percentile\"] - df_clean[\"Predicted Sem 3 Percentile\"]\n",
    ").round(2)\n",
    "\n",
    "df_clean[\"Predicted Risk Flag\"] = df_clean[\"Predicted Percentile Drop\"] > 10\n",
    "\n",
    "# Columns for Semester 3 core theory subjects\n",
    "sem3_columns = [\n",
    "    \"Math-3 Theory\",\n",
    "    \"DE Theory\",\n",
    "    \"FSD Theory\",\n",
    "    \"Python Theory\",\n",
    "]\n",
    "\n",
    "# Calculate Semester 3 Total as the sum of core subject scores\n",
    "df[\"Sem 3 Percentage\"] = (df[sem3_columns].sum(axis=1) / 4).round(2)\n",
    "\n",
    "df_clean[\"Sem 3 Percentile\"] = df[\"Sem 3 Percentage\"].rank(pct=True) * 100\n",
    "\n",
    "df_clean[\"Percentile Drop\"] = (\n",
    "    df_clean[\"Sem 2 Percentile\"] - df_clean[\"Sem 3 Percentile\"]\n",
    ").round(2)\n",
    "\n",
    "df_clean[\"Risk Flag\"] = df_clean[\"Percentile Drop\"] > 10\n",
    "\n",
    "columns_to_drop = [\n",
    "    \"Sem 3 Percentile\",\n",
    "    \"Percentile Drop\"\n",
    "]\n",
    "\n",
    "df_clean.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "# After all operations on df_clean are complete, drop other DataFrames\n",
    "df = None\n",
    "fe_de = None\n",
    "fe_fsd = None\n",
    "fe_math3 = None\n",
    "fe_python = None\n",
    "\n",
    "print(df_clean.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268fddad",
   "metadata": {},
   "source": [
    "# Dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ef56866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.8000, Precision=0.0000, Recall=0.0000, F1=0.0000\n",
      "Fold 2: Accuracy=0.8000, Precision=0.0000, Recall=0.0000, F1=0.0000\n",
      "Fold 3: Accuracy=0.8000, Precision=0.0000, Recall=0.0000, F1=0.0000\n",
      "Fold 4: Accuracy=0.7931, Precision=0.0000, Recall=0.0000, F1=0.0000\n",
      "Fold 5: Accuracy=0.7986, Precision=0.0000, Recall=0.0000, F1=0.0000\n",
      "\n",
      "--- Baseline Model Summary ---\n",
      "Name                          : DummyClassifier-MostFreq\n",
      "Description                   : Baseline-MostFrequent-5Fold\n",
      "Accuracy                      : 0.7983\n",
      "Precision                     : 0.0000\n",
      "Recall                        : 0.0000\n",
      "F1 Score                      : 0.0000\n",
      "\n",
      "CSV Row Format:\n",
      "DummyClassifier-MostFreq,Baseline-MostFrequent-5Fold,0.7983,0.0000,0.0000,0.0000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Target and features\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# DummyClassifier – always predicts the most frequent class\n",
    "dummy = DummyClassifier(strategy='most_frequent')\n",
    "\n",
    "# CV setup\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Metric storage\n",
    "accuracy_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "\n",
    "# 5-Fold Evaluation\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    dummy.fit(X_train, y_train)\n",
    "    y_pred = dummy.predict(X_val)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# Final metrics\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# Model info\n",
    "model_name = 'DummyClassifier-MostFreq'\n",
    "model_desc = 'Baseline-MostFrequent-5Fold'\n",
    "\n",
    "# Print formatted summary\n",
    "print(\"\\n--- Baseline Model Summary ---\")\n",
    "print(f\"{'Name':<30}: {model_name}\")\n",
    "print(f\"{'Description':<30}: {model_desc}\")\n",
    "print(f\"{'Accuracy':<30}: {mean_acc:.4f}\")\n",
    "print(f\"{'Precision':<30}: {mean_prec:.4f}\")\n",
    "print(f\"{'Recall':<30}: {mean_rec:.4f}\")\n",
    "print(f\"{'F1 Score':<30}: {mean_f1:.4f}\")\n",
    "\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# Save to CSV (append row, create file if not exists)\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "new_row = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "\n",
    "# Append to file (header only if file doesn't exist)\n",
    "new_row.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5ddd4c",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d9afa15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.6552, Precision=0.2857, Recall=0.4828, F1=0.3590\n",
      "Fold 2: Accuracy=0.7172, Precision=0.3421, Recall=0.4483, F1=0.3881\n",
      "Fold 3: Accuracy=0.6345, Precision=0.2931, Recall=0.5862, F1=0.3908\n",
      "Fold 4: Accuracy=0.6276, Precision=0.2931, Recall=0.5667, F1=0.3864\n",
      "Fold 5: Accuracy=0.5486, Precision=0.2000, Recall=0.4138, F1=0.2697\n",
      "\n",
      "--- Average Metrics Summary ---\n",
      "Name                          : LogisticRegression-Balanced\n",
      "Description                   : OneHot+Scaler+5Fold-Stratified\n",
      "Accuracy                      : 0.6366\n",
      "Precision                     : 0.2828\n",
      "Recall                        : 0.4995\n",
      "F1 Score                      : 0.3588\n",
      "\n",
      "CSV Row Format:\n",
      "LogisticRegression-Balanced,OneHot+Scaler+5Fold-Stratified,0.6366,0.2828,0.4995,0.3588\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import warnings\n",
    "import csv\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Step 1: Copy and split data\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)  # convert bool to 0/1\n",
    "\n",
    "# Step 2: Column categorization\n",
    "categorical_cols = ['Gender', 'Religion', 'Branch', 'Section-1', 'Section-2', 'Section-3']\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Step 3: Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# Step 4: Full pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('model', LogisticRegression(class_weight='balanced', max_iter=1000))\n",
    "])\n",
    "\n",
    "# Step 5: 5-Fold Stratified CV\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Metrics storage\n",
    "accuracy_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "\n",
    "# Step 6: Loop through CV\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_val)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# Step 7: Average metrics\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# Model info\n",
    "model_name = 'LogisticRegression-Balanced'\n",
    "model_desc = 'OneHot+Scaler+5Fold-Stratified'\n",
    "\n",
    "# Print: CSV-style with labels and formatting\n",
    "print(\"\\n--- Average Metrics Summary ---\")\n",
    "print(f\"{'Name':<30}: {model_name}\")\n",
    "print(f\"{'Description':<30}: {model_desc}\")\n",
    "print(f\"{'Accuracy':<30}: {mean_acc:.4f}\")\n",
    "print(f\"{'Precision':<30}: {mean_prec:.4f}\")\n",
    "print(f\"{'Recall':<30}: {mean_rec:.4f}\")\n",
    "print(f\"{'F1 Score':<30}: {mean_f1:.4f}\")\n",
    "\n",
    "# Also print as CSV row\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# Step 8: Write to file if not already present\n",
    "output_path = 'risk_model_metrics.csv'\n",
    "write_header = not os.path.exists(output_path)\n",
    "\n",
    "with open(output_path, mode='a', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    if write_header:\n",
    "        writer.writerow(['Name', 'Desc', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
    "    writer.writerow([model_name, model_desc, f\"{mean_acc:.4f}\", f\"{mean_prec:.4f}\", f\"{mean_rec:.4f}\", f\"{mean_f1:.4f}\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefdbb3e",
   "metadata": {},
   "source": [
    "# DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b37e44c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.7034, Precision=0.2308,  Recall=0.2069, F1=0.2182\n",
      "Fold 2: Accuracy=0.7103, Precision=0.2174,  Recall=0.1724, F1=0.1923\n",
      "Fold 3: Accuracy=0.7241, Precision=0.3333,  Recall=0.3793, F1=0.3548\n",
      "Fold 4: Accuracy=0.6966, Precision=0.3409,  Recall=0.5000, F1=0.4054\n",
      "Fold 5: Accuracy=0.6875, Precision=0.1923,  Recall=0.1724, F1=0.1818\n",
      "\n",
      "--- DecisionTreeClassifier Summary ---\n",
      "Mean Accuracy : 0.7044\n",
      "Mean Precision: 0.2629\n",
      "Mean Recall   : 0.2862\n",
      "Mean F1 Score : 0.2705\n",
      "\n",
      "CSV Row Format:\n",
      "DecisionTreeClassifier-Balanced,OneHot+Scaler+5Fold-Stratified,0.7044,0.2629,0.2862,0.2705\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Step 1: Prepare data\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# Step 2: Column categories\n",
    "categorical_cols = ['Gender', 'Religion', 'Branch', 'Section-1', 'Section-2', 'Section-3']\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Step 3: Preprocessing\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# Step 4: Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('model', DecisionTreeClassifier(class_weight='balanced', random_state=42))\n",
    "])\n",
    "\n",
    "# Step 5: Cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_val)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f},  Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# Step 6: Averages\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# Step 7: Model description\n",
    "model_name = 'DecisionTreeClassifier-Balanced'\n",
    "model_desc = 'OneHot+Scaler+5Fold-Stratified'\n",
    "\n",
    "# Console summary\n",
    "print(\"\\n--- DecisionTreeClassifier Summary ---\")\n",
    "print(f\"Mean Accuracy : {mean_acc:.4f}\")\n",
    "print(f\"Mean Precision: {mean_prec:.4f}\")\n",
    "print(f\"Mean Recall   : {mean_rec:.4f}\")\n",
    "print(f\"Mean F1 Score : {mean_f1:.4f}\")\n",
    "\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# Step 8: Save to CSV\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "result_df = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "\n",
    "# Append to CSV, add header only if file doesn't exist\n",
    "result_df.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bb71471c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.5862, Precision=0.2687,  Recall=0.6207, F1=0.3750\n",
      "Fold 2: Accuracy=0.6207, Precision=0.2759,  Recall=0.5517, F1=0.3678\n",
      "Fold 3: Accuracy=0.5517, Precision=0.2805,  Recall=0.7931, F1=0.4144\n",
      "Fold 4: Accuracy=0.5310, Precision=0.2889,  Recall=0.8667, F1=0.4333\n",
      "Fold 5: Accuracy=0.5208, Precision=0.1970,  Recall=0.4483, F1=0.2737\n",
      "\n",
      "--- DecisionTree_Recall_Tuned Summary ---\n",
      "Mean Accuracy : 0.5621\n",
      "Mean Precision: 0.2622\n",
      "Mean Recall   : 0.6561\n",
      "Mean F1 Score : 0.3728\n",
      "\n",
      "CSV Row Format:\n",
      "DecisionTree-RecallTuned,Thresh=0.35|Depth=6|Split=10|Leaf=5|5Fold,0.5621,0.2622,0.6561,0.3728\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Step 1: Data setup\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# Step 2: Column types\n",
    "categorical_cols = ['Gender', 'Religion', 'Branch', 'Section-1', 'Section-2', 'Section-3']\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Step 3: Preprocessing\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# Step 4: Recall-tuned DecisionTree\n",
    "pipeline = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('model', DecisionTreeClassifier(\n",
    "        class_weight='balanced',\n",
    "        max_depth=6,\n",
    "        min_samples_split=10,\n",
    "        min_samples_leaf=5,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Step 5: CV setup\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n",
    "\n",
    "# Step 6: Custom threshold\n",
    "threshold = 0.35\n",
    "\n",
    "# Step 7: Cross-validation\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    y_proba = pipeline.predict_proba(X_val)[:, 1]\n",
    "    y_pred = (y_proba >= threshold).astype(int)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f},  Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# Step 8: Mean metrics\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# Step 9: Model info\n",
    "model_name = 'DecisionTree-RecallTuned'\n",
    "model_desc = f'Thresh=0.35|Depth=6|Split=10|Leaf=5|5Fold'\n",
    "\n",
    "# Console output\n",
    "print(\"\\n--- DecisionTree_Recall_Tuned Summary ---\")\n",
    "print(f\"Mean Accuracy : {mean_acc:.4f}\")\n",
    "print(f\"Mean Precision: {mean_prec:.4f}\")\n",
    "print(f\"Mean Recall   : {mean_rec:.4f}\")\n",
    "print(f\"Mean F1 Score : {mean_f1:.4f}\")\n",
    "\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# Step 10: Save to CSV\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "result_df = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "\n",
    "result_df.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ee992bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.7034, Precision=0.2308,  Recall=0.2069, F1=0.2182\n",
      "Fold 2: Accuracy=0.7103, Precision=0.2174,  Recall=0.1724, F1=0.1923\n",
      "Fold 3: Accuracy=0.7241, Precision=0.3333,  Recall=0.3793, F1=0.3548\n",
      "Fold 4: Accuracy=0.6966, Precision=0.3409,  Recall=0.5000, F1=0.4054\n",
      "Fold 5: Accuracy=0.6875, Precision=0.1923,  Recall=0.1724, F1=0.1818\n",
      "\n",
      "--- DecisionTree_MaxRecall Summary ---\n",
      "Mean Accuracy : 0.7044\n",
      "Mean Precision: 0.2629\n",
      "Mean Recall   : 0.2862\n",
      "Mean F1 Score : 0.2705\n",
      "\n",
      "CSV Row Format:\n",
      "DecisionTree-MaxRecall,Depth=None|Split=2|Leaf=1|Thresh=0.25|5Fold,0.7044,0.2629,0.2862,0.2705\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Step 1: Data setup\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "categorical_cols = ['Gender', 'Religion', 'Branch', 'Section-1', 'Section-2', 'Section-3']\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Step 2: Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# Step 3: Flexible (deep) DecisionTreeClassifier\n",
    "pipeline = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('model', DecisionTreeClassifier(\n",
    "        class_weight='balanced',\n",
    "        max_depth=None,             # no limit\n",
    "        min_samples_split=2,        # fine splits\n",
    "        min_samples_leaf=1,         # small leaves allowed\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Step 4: Cross-validation config\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n",
    "\n",
    "# Step 5: Threshold\n",
    "threshold = 0.25  # aggressive threshold to maximize recall\n",
    "\n",
    "# Step 6: CV loop\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_proba = pipeline.predict_proba(X_val)[:, 1]\n",
    "    y_pred = (y_proba >= threshold).astype(int)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f},  Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# Step 7: Aggregate results\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# Step 8: Metadata\n",
    "model_name = 'DecisionTree-MaxRecall'\n",
    "model_desc = 'Depth=None|Split=2|Leaf=1|Thresh=0.25|5Fold'\n",
    "\n",
    "print(\"\\n--- DecisionTree_MaxRecall Summary ---\")\n",
    "print(f\"Mean Accuracy : {mean_acc:.4f}\")\n",
    "print(f\"Mean Precision: {mean_prec:.4f}\")\n",
    "print(f\"Mean Recall   : {mean_rec:.4f}\")\n",
    "print(f\"Mean F1 Score : {mean_f1:.4f}\")\n",
    "\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# Step 9: Save to CSV\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "result_df = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "result_df.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a643a2d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.5241, Precision=0.2297, Recall=0.5862, F1=0.3301\n",
      "Fold 2: Accuracy=0.6483, Precision=0.2105, Recall=0.2759, F1=0.2388\n",
      "Fold 3: Accuracy=0.6000, Precision=0.2899, Recall=0.6897, F1=0.4082\n",
      "Fold 4: Accuracy=0.5724, Precision=0.2333, Recall=0.4667, F1=0.3111\n",
      "Fold 5: Accuracy=0.5208, Precision=0.2297, Recall=0.5862, F1=0.3301\n",
      "\n",
      "--- DecisionTree_SMOTE Summary ---\n",
      "Mean Accuracy : 0.5731\n",
      "Mean Precision: 0.2386\n",
      "Mean Recall   : 0.5209\n",
      "Mean F1 Score : 0.3237\n",
      "\n",
      "CSV Row Format:\n",
      "DecisionTree-SMOTE,Thresh=0.35|Depth=6|Split=10|Leaf=5|5Fold|SMOTE,0.5731,0.2386,0.5209,0.3237\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Step 1: Data setup\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# Step 2: Column types\n",
    "categorical_cols = ['Gender', 'Religion', 'Branch', 'Section-1', 'Section-2', 'Section-3']\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Step 3: Preprocessing\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# Step 4: SMOTE setup\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "# Step 5: Recall-tuned DecisionTree\n",
    "pipeline = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('model', DecisionTreeClassifier(\n",
    "        max_depth=6,\n",
    "        min_samples_split=10,\n",
    "        min_samples_leaf=5,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Step 6: CV setup\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n",
    "\n",
    "# Step 7: Custom threshold\n",
    "threshold = 0.35\n",
    "\n",
    "# Step 8: Cross-validation with SMOTE\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    # Apply SMOTE to training data\n",
    "    X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "    X_train_smote, y_train_smote = smote.fit_resample(X_train_preprocessed, y_train)\n",
    "\n",
    "    # Fit the model on SMOTE-resampled data\n",
    "    pipeline.named_steps['model'].fit(X_train_smote, y_train_smote)\n",
    "\n",
    "    # Transform validation data\n",
    "    X_val_preprocessed = preprocessor.transform(X_val)\n",
    "    y_proba = pipeline.named_steps['model'].predict_proba(X_val_preprocessed)[:, 1]\n",
    "    y_pred = (y_proba >= threshold).astype(int)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# Step 9: Mean metrics\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# Step 10: Model info\n",
    "model_name = 'DecisionTree-SMOTE'\n",
    "model_desc = f'Thresh=0.35|Depth=6|Split=10|Leaf=5|5Fold|SMOTE'\n",
    "\n",
    "# Console output\n",
    "print(\"\\n--- DecisionTree_SMOTE Summary ---\")\n",
    "print(f\"Mean Accuracy : {mean_acc:.4f}\")\n",
    "print(f\"Mean Precision: {mean_prec:.4f}\")\n",
    "print(f\"Mean Recall   : {mean_rec:.4f}\")\n",
    "print(f\"Mean F1 Score : {mean_f1:.4f}\")\n",
    "\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# Step 11: Save to CSV\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "result_df = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "\n",
    "result_df.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a761db51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.6690, Precision=0.3061, Recall=0.5172, F1=0.3846\n",
      "Fold 2: Accuracy=0.6207, Precision=0.2174, Recall=0.3448, F1=0.2667\n",
      "Fold 3: Accuracy=0.6345, Precision=0.3125, Recall=0.6897, F1=0.4301\n",
      "Fold 4: Accuracy=0.5241, Precision=0.2593, Recall=0.7000, F1=0.3784\n",
      "Fold 5: Accuracy=0.5208, Precision=0.2436, Recall=0.6552, F1=0.3551\n",
      "\n",
      "--- DecisionTree_SMOTE_RecallOptimized Summary ---\n",
      "Mean Accuracy : 0.5938\n",
      "Mean Precision: 0.2678\n",
      "Mean Recall   : 0.5814\n",
      "Mean F1 Score : 0.3630\n",
      "\n",
      "CSV Row Format:\n",
      "DecisionTree-SMOTE-RecallOptimized,Thresh=0.25|Depth=6|Split=10|Leaf=3|5Fold|SMOTE_0.8,0.5938,0.2678,0.5814,0.3630\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Step 1: Data setup\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# Step 2: Column types\n",
    "categorical_cols = ['Gender', 'Religion', 'Branch', 'Section-1', 'Section-2', 'Section-3']\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Step 3: Preprocessing\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# Step 4: SMOTE setup with adjusted sampling strategy\n",
    "smote = SMOTE(sampling_strategy=0.8, random_state=42)\n",
    "\n",
    "# Step 5: Recall-optimized DecisionTree\n",
    "pipeline = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('model', DecisionTreeClassifier(\n",
    "        max_depth=6,\n",
    "        min_samples_split=10,\n",
    "        min_samples_leaf=3,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Step 6: CV setup\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n",
    "\n",
    "# Step 7: Lowered threshold for higher recall\n",
    "threshold = 0.25\n",
    "\n",
    "# Step 8: Cross-validation with SMOTE\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    # Apply SMOTE to training data\n",
    "    X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "    X_train_smote, y_train_smote = smote.fit_resample(X_train_preprocessed, y_train)\n",
    "\n",
    "    # Fit the model on SMOTE-resampled data\n",
    "    pipeline.named_steps['model'].fit(X_train_smote, y_train_smote)\n",
    "\n",
    "    # Transform validation data\n",
    "    X_val_preprocessed = preprocessor.transform(X_val)\n",
    "    y_proba = pipeline.named_steps['model'].predict_proba(X_val_preprocessed)[:, 1]\n",
    "    y_pred = (y_proba >= threshold).astype(int)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# Step 9: Mean metrics\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# Step 10: Model info\n",
    "model_name = 'DecisionTree-SMOTE-RecallOptimized'\n",
    "model_desc = f'Thresh=0.25|Depth=6|Split=10|Leaf=3|5Fold|SMOTE_0.8'\n",
    "\n",
    "# Console output\n",
    "print(\"\\n--- DecisionTree_SMOTE_RecallOptimized Summary ---\")\n",
    "print(f\"Mean Accuracy : {mean_acc:.4f}\")\n",
    "print(f\"Mean Precision: {mean_prec:.4f}\")\n",
    "print(f\"Mean Recall   : {mean_rec:.4f}\")\n",
    "print(f\"Mean F1 Score : {mean_f1:.4f}\")\n",
    "\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# Step 11: Save to CSV\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "result_df = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "\n",
    "result_df.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58706e3",
   "metadata": {},
   "source": [
    "# RandomForestClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9de4e23a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.8069, Precision=0.6000,  Recall=0.1034, F1=0.1765\n",
      "Fold 2: Accuracy=0.7931, Precision=0.0000,  Recall=0.0000, F1=0.0000\n",
      "Fold 3: Accuracy=0.8069, Precision=0.6667,  Recall=0.0690, F1=0.1250\n",
      "Fold 4: Accuracy=0.7793, Precision=0.3750,  Recall=0.1000, F1=0.1579\n",
      "Fold 5: Accuracy=0.7708, Precision=0.0000,  Recall=0.0000, F1=0.0000\n",
      "\n",
      "--- RandomForestClassifier Summary ---\n",
      "Mean Accuracy : 0.7914\n",
      "Mean Precision: 0.3283\n",
      "Mean Recall   : 0.0545\n",
      "Mean F1 Score : 0.0919\n",
      "\n",
      "CSV Row Format:\n",
      "RandomForestClassifier-Balanced,OneHot+Scaler+5Fold-Stratified,0.7914,0.3283,0.0545,0.0919\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Step 1: Prepare data\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# Step 2: Column categories\n",
    "categorical_cols = ['Gender', 'Religion', 'Branch', 'Section-1', 'Section-2', 'Section-3']\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Step 3: Preprocessing\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# Step 4: Pipeline with Random Forest\n",
    "pipeline = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('model', RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=None,\n",
    "        class_weight='balanced',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Step 5: Cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_val)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f},  Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# Step 6: Averages\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# Step 7: Model description\n",
    "model_name = 'RandomForestClassifier-Balanced'\n",
    "model_desc = 'OneHot+Scaler+5Fold-Stratified'\n",
    "\n",
    "# Console summary\n",
    "print(\"\\n--- RandomForestClassifier Summary ---\")\n",
    "print(f\"Mean Accuracy : {mean_acc:.4f}\")\n",
    "print(f\"Mean Precision: {mean_prec:.4f}\")\n",
    "print(f\"Mean Recall   : {mean_rec:.4f}\")\n",
    "print(f\"Mean F1 Score : {mean_f1:.4f}\")\n",
    "\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# Step 8: Save to CSV\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "result_df = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "\n",
    "# Append to CSV, add header only if file doesn't exist\n",
    "result_df.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c8d374e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.6414, Precision=0.2830, Recall=0.5172, F1=0.3659\n",
      "Fold 2: Accuracy=0.6414, Precision=0.2653, Recall=0.4483, F1=0.3333\n",
      "Fold 3: Accuracy=0.5862, Precision=0.3038, Recall=0.8276, F1=0.4444\n",
      "Fold 4: Accuracy=0.5724, Precision=0.3000, Recall=0.8000, F1=0.4364\n",
      "Fold 5: Accuracy=0.5417, Precision=0.2533, Recall=0.6552, F1=0.3654\n",
      "\n",
      "--- Average Metrics Summary ---\n",
      "Name                          : RandomForest-SMOTE-Threshold0.3\n",
      "Description                   : OneHot+Scaler+SMOTE+RF+Threshold=0.3\n",
      "Accuracy                      : 0.5966\n",
      "Precision                     : 0.2811\n",
      "Recall                        : 0.6497\n",
      "F1 Score                      : 0.3891\n",
      "\n",
      "CSV Row Format:\n",
      "RandomForest-SMOTE-Threshold0.3,OneHot+Scaler+SMOTE+RF+Threshold=0.3,0.5966,0.2811,0.6497,0.3891\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "import warnings\n",
    "import csv\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Step 1: Copy and split data\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)  # convert bool to 0/1\n",
    "\n",
    "# Step 2: Column categorization\n",
    "categorical_cols = ['Gender', 'Religion', 'Branch', 'Section-1', 'Section-2', 'Section-3']\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Step 3: Preprocessing\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# Step 4: Full pipeline with SMOTE + RandomForest\n",
    "pipeline = ImbPipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('model', RandomForestClassifier(\n",
    "        n_estimators=200,\n",
    "        max_depth=None,\n",
    "        class_weight='balanced',\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Step 5: 5-Fold Stratified CV\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Metrics storage\n",
    "accuracy_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "\n",
    "threshold = 0.3  # Custom threshold to maximize recall\n",
    "\n",
    "# Step 6: Loop through CV\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_proba = pipeline.predict_proba(X_val)[:, 1]  # Get probability for class 1\n",
    "\n",
    "    y_pred = (y_proba >= threshold).astype(int)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# Step 7: Average metrics\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# Model info\n",
    "model_name = 'RandomForest-SMOTE-Threshold0.3'\n",
    "model_desc = 'OneHot+Scaler+SMOTE+RF+Threshold=0.3'\n",
    "\n",
    "# Print: CSV-style with labels and formatting\n",
    "print(\"\\n--- Average Metrics Summary ---\")\n",
    "print(f\"{'Name':<30}: {model_name}\")\n",
    "print(f\"{'Description':<30}: {model_desc}\")\n",
    "print(f\"{'Accuracy':<30}: {mean_acc:.4f}\")\n",
    "print(f\"{'Precision':<30}: {mean_prec:.4f}\")\n",
    "print(f\"{'Recall':<30}: {mean_rec:.4f}\")\n",
    "print(f\"{'F1 Score':<30}: {mean_f1:.4f}\")\n",
    "\n",
    "# Also print as CSV row\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# Step 8: Write to file if not already present\n",
    "output_path = 'risk_model_metrics.csv'\n",
    "write_header = not os.path.exists(output_path)\n",
    "\n",
    "with open(output_path, mode='a', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    if write_header:\n",
    "        writer.writerow(['Name', 'Desc', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
    "    writer.writerow([model_name, model_desc, f\"{mean_acc:.4f}\", f\"{mean_prec:.4f}\", f\"{mean_rec:.4f}\", f\"{mean_f1:.4f}\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf804d22",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "66ba5f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.7517, Precision=0.2941,  Recall=0.1724, F1=0.2174\n",
      "Fold 2: Accuracy=0.7793, Precision=0.3333,  Recall=0.1034, F1=0.1579\n",
      "Fold 3: Accuracy=0.7379, Precision=0.3333,  Recall=0.3103, F1=0.3214\n",
      "Fold 4: Accuracy=0.7655, Precision=0.4000,  Recall=0.2667, F1=0.3200\n",
      "Fold 5: Accuracy=0.7153, Precision=0.3125,  Recall=0.3448, F1=0.3279\n",
      "\n",
      "--- XGBoost Summary ---\n",
      "Mean Accuracy : 0.7500\n",
      "Mean Precision: 0.3347\n",
      "Mean Recall   : 0.2395\n",
      "Mean F1 Score : 0.2689\n",
      "\n",
      "CSV Row Format:\n",
      "XGBoost-Balanced,OneHot+Scaler+5Fold-Stratified,0.7500,0.3347,0.2395,0.2689\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Step 1: Prepare data\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# Step 2: Column categories\n",
    "categorical_cols = ['Gender', 'Religion', 'Branch', 'Section-1', 'Section-2', 'Section-3']\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Step 3: Preprocessing\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# Step 4: XGBoost Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('model', XGBClassifier(\n",
    "        objective='binary:logistic',\n",
    "        eval_metric='logloss',\n",
    "        scale_pos_weight=np.sum(y == 0) / np.sum(y == 1),  # Handles class imbalance\n",
    "        use_label_encoder=False,\n",
    "        n_estimators=100,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.1,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Step 5: Cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_val)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f},  Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# Step 6: Averages\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# Step 7: Model description\n",
    "model_name = 'XGBoost-Balanced'\n",
    "model_desc = 'OneHot+Scaler+5Fold-Stratified'\n",
    "\n",
    "# Console summary\n",
    "print(\"\\n--- XGBoost Summary ---\")\n",
    "print(f\"Mean Accuracy : {mean_acc:.4f}\")\n",
    "print(f\"Mean Precision: {mean_prec:.4f}\")\n",
    "print(f\"Mean Recall   : {mean_rec:.4f}\")\n",
    "print(f\"Mean F1 Score : {mean_f1:.4f}\")\n",
    "\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# Step 8: Save to CSV\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "result_df = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "\n",
    "# Append to CSV, add header only if file doesn't exist\n",
    "result_df.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3b66f051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.6621, Precision=0.2222, Recall=0.2759, F1=0.2462\n",
      "Fold 2: Accuracy=0.7379, Precision=0.3636, Recall=0.4138, F1=0.3871\n",
      "Fold 3: Accuracy=0.6483, Precision=0.2963, Recall=0.5517, F1=0.3855\n",
      "Fold 4: Accuracy=0.7103, Precision=0.3966, Recall=0.7667, F1=0.5227\n",
      "Fold 5: Accuracy=0.5972, Precision=0.2623, Recall=0.5517, F1=0.3556\n",
      "\n",
      "--- Average Metrics Summary ---\n",
      "Name                          : XGBoost-SMOTE-Threshold0.25\n",
      "Description                   : OneHot+Scaler+SMOTE+XGB+Threshold=0.25\n",
      "Accuracy                      : 0.6712\n",
      "Precision                     : 0.3082\n",
      "Recall                        : 0.5120\n",
      "F1 Score                      : 0.3794\n",
      "\n",
      "CSV Row Format:\n",
      "XGBoost-SMOTE-Threshold0.25,OneHot+Scaler+SMOTE+XGB+Threshold=0.25,0.6712,0.3082,0.5120,0.3794\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from xgboost import XGBClassifier\n",
    "import warnings\n",
    "import csv\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Step 1: Copy and split data\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# Step 2: Column categorization\n",
    "categorical_cols = ['Gender', 'Religion', 'Branch', 'Section-1', 'Section-2', 'Section-3']\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Step 3: Preprocessing\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# Step 4: Pipeline with XGBoost + SMOTE\n",
    "pipeline = ImbPipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('model', XGBClassifier(\n",
    "        use_label_encoder=False,\n",
    "        eval_metric='logloss',\n",
    "        scale_pos_weight=4,  # 80:20 class balance\n",
    "        n_estimators=200,\n",
    "        max_depth=5,\n",
    "        learning_rate=0.1,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Step 5: Stratified 5-Fold CV\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Step 6: Metrics storage\n",
    "accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n",
    "\n",
    "# Threshold for classification\n",
    "threshold = 0.25\n",
    "\n",
    "# Step 7: CV loop\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_proba = pipeline.predict_proba(X_val)[:, 1]\n",
    "    y_pred = (y_proba >= threshold).astype(int)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# Step 8: Average metrics\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# Model info\n",
    "model_name = 'XGBoost-SMOTE-Threshold0.25'\n",
    "model_desc = 'OneHot+Scaler+SMOTE+XGB+Threshold=0.25'\n",
    "\n",
    "# Step 9: Print metrics\n",
    "print(\"\\n--- Average Metrics Summary ---\")\n",
    "print(f\"{'Name':<30}: {model_name}\")\n",
    "print(f\"{'Description':<30}: {model_desc}\")\n",
    "print(f\"{'Accuracy':<30}: {mean_acc:.4f}\")\n",
    "print(f\"{'Precision':<30}: {mean_prec:.4f}\")\n",
    "print(f\"{'Recall':<30}: {mean_rec:.4f}\")\n",
    "print(f\"{'F1 Score':<30}: {mean_f1:.4f}\")\n",
    "\n",
    "# Also print as CSV row\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# Step 10: Write to file if not already present\n",
    "output_path = 'risk_model_metrics.csv'\n",
    "write_header = not os.path.exists(output_path)\n",
    "\n",
    "with open(output_path, mode='a', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    if write_header:\n",
    "        writer.writerow(['Name', 'Desc', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
    "    writer.writerow([model_name, model_desc, f\"{mean_acc:.4f}\", f\"{mean_prec:.4f}\", f\"{mean_rec:.4f}\", f\"{mean_f1:.4f}\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "23024535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 324 candidates, totalling 1620 fits\n",
      "Best Parameters: {'model__colsample_bytree': 0.8, 'model__learning_rate': 0.01, 'model__max_depth': 4, 'model__min_child_weight': 5, 'model__n_estimators': 100, 'model__subsample': 0.8}\n",
      "Fold 1: Accuracy=0.2000, Precision=0.2000, Recall=1.0000, F1=0.3333, Best Threshold=0.10\n",
      "Fold 2: Accuracy=0.2000, Precision=0.2000, Recall=1.0000, F1=0.3333, Best Threshold=0.10\n",
      "Fold 3: Accuracy=0.2000, Precision=0.2000, Recall=1.0000, F1=0.3333, Best Threshold=0.10\n",
      "Fold 4: Accuracy=0.2069, Precision=0.2069, Recall=1.0000, F1=0.3429, Best Threshold=0.10\n",
      "Fold 5: Accuracy=0.2014, Precision=0.2014, Recall=1.0000, F1=0.3353, Best Threshold=0.10\n",
      "\n",
      "--- Fine-Tuned XGBoost Summary ---\n",
      "Mean Accuracy : 0.2017\n",
      "Mean Precision: 0.2017\n",
      "Mean Recall   : 1.0000\n",
      "Mean F1 Score : 0.3356\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Step 1: Prepare data\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "categorical_cols = ['Gender', 'Religion', 'Branch', 'Section-1', 'Section-2', 'Section-3']\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Step 2: Preprocessing\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# Step 3: Pipeline with SMOTE\n",
    "pipeline = ImbPipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('model', XGBClassifier(\n",
    "        objective='binary:logistic',\n",
    "        use_label_encoder=False,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Step 4: Hyperparameter Optimization\n",
    "param_grid = {\n",
    "    'model__n_estimators': [100, 200, 300],\n",
    "    'model__max_depth': [4, 6, 8],\n",
    "    'model__learning_rate': [0.01, 0.1, 0.2],\n",
    "    'model__min_child_weight': [1, 3, 5],\n",
    "    'model__subsample': [0.8, 1.0],\n",
    "    'model__colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    scoring='f1',\n",
    "    cv=cv,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Step 5: Dynamic Threshold Tuning\n",
    "best_model = grid_search.best_estimator_\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "\n",
    "accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n",
    "thresholds = np.linspace(0.1, 0.9, 9)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    best_model.fit(X_train, y_train)\n",
    "    y_proba = best_model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    # Dynamic threshold tuning for recall\n",
    "    recalls = [recall_score(y_val, (y_proba >= t).astype(int)) for t in thresholds]\n",
    "    best_threshold = thresholds[np.argmax(recalls)]\n",
    "\n",
    "    y_pred = (y_proba >= best_threshold).astype(int)\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}, F1={f1:.4f}, Best Threshold={best_threshold:.2f}\")\n",
    "\n",
    "# Step 6: Aggregate Results\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# Step 7: Summary\n",
    "model_name = 'XGBoost-SMOTE-FineTuned'\n",
    "model_desc = f'OptimizedParams|DynamicThresh={best_threshold:.2f}|OneHot+Scaler'\n",
    "\n",
    "print(\"\\n--- Fine-Tuned XGBoost Summary ---\")\n",
    "print(f\"Mean Accuracy : {mean_acc:.4f}\")\n",
    "print(f\"Mean Precision: {mean_prec:.4f}\")\n",
    "print(f\"Mean Recall   : {mean_rec:.4f}\")\n",
    "print(f\"Mean F1 Score : {mean_f1:.4f}\")\n",
    "\n",
    "# Step 8: Save to CSV\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "result_df = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "result_df.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9cc6f567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 972 candidates, totalling 4860 fits\n",
      "Best Parameters: {'model__colsample_bytree': 0.8, 'model__learning_rate': 0.01, 'model__max_depth': 4, 'model__min_child_weight': 5, 'model__n_estimators': 300, 'model__scale_pos_weight': 6, 'model__subsample': 0.8}\n",
      "Fold 1: Accuracy=0.5448, Precision=0.2716, Recall=0.7586, F1=0.4000, Best Threshold=0.50\n",
      "Fold 2: Accuracy=0.5862, Precision=0.3038, Recall=0.8276, F1=0.4444, Best Threshold=0.40\n",
      "Fold 3: Accuracy=0.7241, Precision=0.3878, Recall=0.6552, F1=0.4872, Best Threshold=0.80\n",
      "Fold 4: Accuracy=0.5931, Precision=0.3294, Recall=0.9333, F1=0.4870, Best Threshold=0.60\n",
      "Fold 5: Accuracy=0.4722, Precision=0.2577, Recall=0.8621, F1=0.3968, Best Threshold=0.40\n",
      "\n",
      "--- Fine-Tuned XGBoost Summary ---\n",
      "Mean Accuracy : 0.5841\n",
      "Mean Precision: 0.3101\n",
      "Mean Recall   : 0.8074\n",
      "Mean F1 Score : 0.4431\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Step 1: Prepare data\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "categorical_cols = ['Gender', 'Religion', 'Branch', 'Section-1', 'Section-2', 'Section-3']\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Step 2: Preprocessing\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# Step 3: Pipeline with SMOTE\n",
    "pipeline = ImbPipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('model', XGBClassifier(\n",
    "        objective='binary:logistic',\n",
    "        use_label_encoder=False,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Step 4: Hyperparameter Optimization\n",
    "param_grid = {\n",
    "    'model__n_estimators': [200, 300, 400],\n",
    "    'model__max_depth': [4, 6, 8],\n",
    "    'model__learning_rate': [0.01, 0.05, 0.1],\n",
    "    'model__min_child_weight': [1, 3, 5],\n",
    "    'model__subsample': [0.8, 1.0],\n",
    "    'model__colsample_bytree': [0.8, 1.0],\n",
    "    'model__scale_pos_weight': [4, 5, 6]  # Adjusted for imbalance\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    scoring='balanced_accuracy',  # Balances true positive/negative rates\n",
    "    cv=cv,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Step 5: Dynamic Threshold Tuning\n",
    "best_model = grid_search.best_estimator_\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "\n",
    "accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n",
    "thresholds = np.linspace(0.1, 0.9, 9)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    best_model.fit(X_train, y_train)\n",
    "    y_proba = best_model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    # Dynamic threshold tuning for F1\n",
    "    f1_scores = [f1_score(y_val, (y_proba >= t).astype(int)) for t in thresholds]\n",
    "    best_threshold = thresholds[np.argmax(f1_scores)]\n",
    "\n",
    "    y_pred = (y_proba >= best_threshold).astype(int)\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}, F1={f1:.4f}, Best Threshold={best_threshold:.2f}\")\n",
    "\n",
    "# Step 6: Aggregate Results\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# Step 7: Summary\n",
    "model_name = 'XGBoost-SMOTE-FineTuned-Balanced'\n",
    "model_desc = f'OptimizedParams|DynamicThresh={best_threshold:.2f}|OneHot+Scaler'\n",
    "\n",
    "print(\"\\n--- Fine-Tuned XGBoost Summary ---\")\n",
    "print(f\"Mean Accuracy : {mean_acc:.4f}\")\n",
    "print(f\"Mean Precision: {mean_prec:.4f}\")\n",
    "print(f\"Mean Recall   : {mean_rec:.4f}\")\n",
    "print(f\"Mean F1 Score : {mean_f1:.4f}\")\n",
    "\n",
    "# Step 8: Save to CSV\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "result_df = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "result_df.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b84066a",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5a727782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.7379, Precision=0.2353,  Recall=0.1379, F1=0.1739\n",
      "Fold 2: Accuracy=0.7724, Precision=0.3000,  Recall=0.1034, F1=0.1538\n",
      "Fold 3: Accuracy=0.7862, Precision=0.4615,  Recall=0.4138, F1=0.4364\n",
      "Fold 4: Accuracy=0.7655, Precision=0.4333,  Recall=0.4333, F1=0.4333\n",
      "Fold 5: Accuracy=0.7292, Precision=0.3438,  Recall=0.3793, F1=0.3607\n",
      "\n",
      "--- LightGBM Summary ---\n",
      "Mean Accuracy : 0.7582\n",
      "Mean Precision: 0.3548\n",
      "Mean Recall   : 0.2936\n",
      "Mean F1 Score : 0.3116\n",
      "\n",
      "CSV Row Format:\n",
      "LightGBM-Balanced,OneHot+Scaler+5Fold-Stratified+VerboseOff,0.7582,0.3548,0.2936,0.3116\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Step 1: Prepare data\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# Optional: Check constant columns\n",
    "constant_cols = [col for col in X.columns if X[col].nunique() <= 1]\n",
    "if constant_cols:\n",
    "    print(\"Warning: Constant columns detected:\", constant_cols)\n",
    "\n",
    "# Step 2: Column categories\n",
    "categorical_cols = ['Gender', 'Religion', 'Branch', 'Section-1', 'Section-2', 'Section-3']\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Step 3: Preprocessing\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', drop='if_binary', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# Step 4: LightGBM Pipeline (optimized to suppress warnings)\n",
    "pipeline = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('model', LGBMClassifier(\n",
    "        objective='binary',\n",
    "        class_weight='balanced',\n",
    "        n_estimators=100,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.1,\n",
    "        min_split_gain=0.01,\n",
    "        min_child_samples=20,\n",
    "        min_data_in_leaf=20,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        verbose=-1,              # suppress LightGBM internal logs\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Step 5: Cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_val)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f},  Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# Step 6: Averages\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# Step 7: Model description\n",
    "model_name = 'LightGBM-Balanced'\n",
    "model_desc = 'OneHot+Scaler+5Fold-Stratified+VerboseOff'\n",
    "\n",
    "# Console summary\n",
    "print(\"\\n--- LightGBM Summary ---\")\n",
    "print(f\"Mean Accuracy : {mean_acc:.4f}\")\n",
    "print(f\"Mean Precision: {mean_prec:.4f}\")\n",
    "print(f\"Mean Recall   : {mean_rec:.4f}\")\n",
    "print(f\"Mean F1 Score : {mean_f1:.4f}\")\n",
    "\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# Step 8: Save to CSV\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "result_df = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "\n",
    "result_df.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1ba0076c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Tuned LightGBM Model Scores:\n",
      "Accuracy : 0.6505\n",
      "Precision: 0.3251\n",
      "Recall   : 0.6772\n",
      "F1 Score : 0.4348\n",
      "Best Parameters: OrderedDict({'model__colsample_bytree': 0.8282702832860589, 'model__learning_rate': 0.011375727095304279, 'model__max_depth': 9, 'model__min_child_samples': 100, 'model__min_split_gain': 0.2, 'model__n_estimators': 100, 'model__subsample': 0.6})\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Integer, Real\n",
    "\n",
    "# Load your real df_clean before this step\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "categorical_cols = ['Gender', 'Religion', 'Branch', 'Section-1', 'Section-2', 'Section-3']\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', drop='if_binary', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('model', LGBMClassifier(objective='binary', class_weight='balanced', verbose=-1, random_state=42))\n",
    "])\n",
    "\n",
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision': make_scorer(precision_score, zero_division=0),\n",
    "    'recall': make_scorer(recall_score),\n",
    "    'f1': make_scorer(f1_score)\n",
    "}\n",
    "\n",
    "param_space = {\n",
    "    'model__n_estimators': Integer(100, 500),\n",
    "    'model__max_depth': Integer(3, 12),\n",
    "    'model__learning_rate': Real(0.01, 0.3, prior='log-uniform'),\n",
    "    'model__min_child_samples': Integer(10, 100),\n",
    "    'model__min_split_gain': Real(0.0, 0.2),\n",
    "    'model__subsample': Real(0.6, 1.0),\n",
    "    'model__colsample_bytree': Real(0.6, 1.0)\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "opt = BayesSearchCV(\n",
    "    estimator=pipeline,\n",
    "    search_spaces=param_space,\n",
    "    scoring=scoring,\n",
    "    refit='recall',\n",
    "    n_iter=40,\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=0,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "opt.fit(X, y)\n",
    "\n",
    "best_model = opt.best_estimator_\n",
    "cv_results = cross_validate(best_model, X, y, cv=cv, scoring=scoring)\n",
    "\n",
    "print(\"Final Tuned LightGBM Model Scores:\")\n",
    "print(f\"Accuracy : {np.mean(cv_results['test_accuracy']):.4f}\")\n",
    "print(f\"Precision: {np.mean(cv_results['test_precision']):.4f}\")\n",
    "print(f\"Recall   : {np.mean(cv_results['test_recall']):.4f}\")\n",
    "print(f\"F1 Score : {np.mean(cv_results['test_f1']):.4f}\")\n",
    "print(\"Best Parameters:\", opt.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2340a2b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No threshold met all conditions. Using default 0.5.\n",
      "\n",
      "--- Threshold-Tuned LightGBM Results ---\n",
      "Threshold   : 0.5000\n",
      "Accuracy    : 0.6464\n",
      "Precision   : 0.3179\n",
      "Recall      : 0.6575\n",
      "F1 Score    : 0.4286\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    precision_recall_curve\n",
    ")\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Step 1: Prepare data\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# Step 2: Column categories\n",
    "categorical_cols = ['Gender', 'Religion', 'Branch', 'Section-1', 'Section-2', 'Section-3']\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Step 3: Preprocessing\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', drop='if_binary', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# Step 4: LightGBM Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('model', LGBMClassifier(\n",
    "        objective='binary',\n",
    "        class_weight='balanced',\n",
    "        learning_rate=0.01,\n",
    "        max_depth=12,\n",
    "        min_child_samples=100,\n",
    "        min_split_gain=0.2,\n",
    "        n_estimators=100,\n",
    "        subsample=0.8664,\n",
    "        colsample_bytree=1.0,\n",
    "        verbose=-1,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Step 5: Cross-validation predictions\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "y_probs = cross_val_predict(pipeline, X, y, cv=cv, method='predict_proba')[:, 1]\n",
    "y_true = y.copy()  # true labels for all folds\n",
    "\n",
    "# Step 6: Find optimal threshold\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_true, y_probs)\n",
    "valid = [(p, r, t) for p, r, t in zip(precisions, recalls, thresholds) if r >= 0.85 and p > 0.50]\n",
    "\n",
    "if valid:\n",
    "    best_prec, best_rec, best_thresh = max(valid, key=lambda x: 2*x[0]*x[1]/(x[0]+x[1]))\n",
    "else:\n",
    "    best_thresh = 0.5  # fallback\n",
    "    best_prec = precision_score(y_true, y_probs >= best_thresh, zero_division=0)\n",
    "    best_rec = recall_score(y_true, y_probs >= best_thresh)\n",
    "    best_f1 = f1_score(y_true, y_probs >= best_thresh)\n",
    "    print(\"No threshold met all conditions. Using default 0.5.\")\n",
    "\n",
    "# Step 7: Final metrics at optimal threshold\n",
    "y_pred_final = (y_probs >= best_thresh).astype(int)\n",
    "final_acc = accuracy_score(y_true, y_pred_final)\n",
    "final_prec = precision_score(y_true, y_pred_final, zero_division=0)\n",
    "final_rec = recall_score(y_true, y_pred_final)\n",
    "final_f1 = f1_score(y_true, y_pred_final)\n",
    "\n",
    "# Step 8: Print results\n",
    "print(\"\\n--- Threshold-Tuned LightGBM Results ---\")\n",
    "print(f\"Threshold   : {best_thresh:.4f}\")\n",
    "print(f\"Accuracy    : {final_acc:.4f}\")\n",
    "print(f\"Precision   : {final_prec:.4f}\")\n",
    "print(f\"Recall      : {final_rec:.4f}\")\n",
    "print(f\"F1 Score    : {final_f1:.4f}\")\n",
    "\n",
    "# Step 9: Save to CSV\n",
    "model_name = 'LightGBM-Tuned-Threshold'\n",
    "model_desc = 'BayesOpt+Threshold@{:.4f}'.format(best_thresh)\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "\n",
    "result_df = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(final_acc, 4),\n",
    "    'Precision': round(final_prec, 4),\n",
    "    'Recall': round(final_rec, 4),\n",
    "    'F1 Score': round(final_f1, 4)\n",
    "}])\n",
    "result_df.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "675c6094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.2000, Precision=0.2000, Recall=1.0000, F1=0.3333, Threshold=0.0004\n",
      "Fold 2: Accuracy=0.2000, Precision=0.2000, Recall=1.0000, F1=0.3333, Threshold=0.0002\n",
      "Fold 3: Accuracy=0.2000, Precision=0.2000, Recall=1.0000, F1=0.3333, Threshold=0.0003\n",
      "Fold 4: Accuracy=0.2069, Precision=0.2069, Recall=1.0000, F1=0.3429, Threshold=0.0002\n",
      "Fold 5: Accuracy=0.2014, Precision=0.2014, Recall=1.0000, F1=0.3353, Threshold=0.0001\n",
      "\n",
      "--- LightGBM Tuned Summary ---\n",
      "Mean Accuracy : 0.2017\n",
      "Mean Precision: 0.2017\n",
      "Mean Recall   : 1.0000\n",
      "Mean F1 Score : 0.3356\n",
      "\n",
      "CSV Row Format:\n",
      "LightGBM-Tuned-HighRecall,OneHot+Scaler+5Fold-Stratified+ThresholdTuned+VerboseOff,0.2017,0.2017,1.0000,0.3356\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "# Step 1: Prepare data\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# Optional: Check constant columns\n",
    "constant_cols = [col for col in X.columns if X[col].nunique() <= 1]\n",
    "if constant_cols:\n",
    "    print(\"Warning: Constant columns detected:\", constant_cols)\n",
    "\n",
    "# Step 2: Column categories\n",
    "categorical_cols = ['Gender', 'Religion', 'Branch', 'Section-1', 'Section-2', 'Section-3']\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Step 3: Preprocessing\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', drop='if_binary', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# Step 4: LightGBM Pipeline with tuned parameters\n",
    "pipeline = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('model', LGBMClassifier(\n",
    "        objective='binary',\n",
    "        class_weight='balanced',\n",
    "        n_estimators=200,           # Increased to allow more learning\n",
    "        max_depth=8,                # Slightly deeper trees\n",
    "        learning_rate=0.05,         # Lower for better convergence\n",
    "        min_split_gain=0.01,\n",
    "        min_child_samples=10,       # Lowered to capture smaller patterns\n",
    "        min_data_in_leaf=10,        # Lowered to reduce overfitting\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.7,      # Slightly reduced to increase diversity\n",
    "        scale_pos_weight=3,         # Increase to prioritize positive class (tune based on imbalance)\n",
    "        verbose=-1,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Step 5: Cross-validation with threshold tuning\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    # Fit the pipeline\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # Get probability scores for threshold tuning\n",
    "    y_prob = pipeline.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    # Find optimal threshold for recall >= 0.85\n",
    "    precisions, recalls, thresholds = precision_recall_curve(y_val, y_prob)\n",
    "    threshold = thresholds[np.argmax(recalls >= 0.85)] if np.any(recalls >= 0.85) else 0.5\n",
    "\n",
    "    # Apply threshold to predictions\n",
    "    y_pred = (y_prob >= threshold).astype(int)\n",
    "\n",
    "    # Calculate metrics\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}, F1={f1:.4f}, Threshold={threshold:.4f}\")\n",
    "\n",
    "# Step 6: Averages\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# Step 7: Model description\n",
    "model_name = 'LightGBM-Tuned-HighRecall'\n",
    "model_desc = 'OneHot+Scaler+5Fold-Stratified+ThresholdTuned+VerboseOff'\n",
    "\n",
    "# Console summary\n",
    "print(\"\\n--- LightGBM Tuned Summary ---\")\n",
    "print(f\"Mean Accuracy : {mean_acc:.4f}\")\n",
    "print(f\"Mean Precision: {mean_prec:.4f}\")\n",
    "print(f\"Mean Recall   : {mean_rec:.4f}\")\n",
    "print(f\"Mean F1 Score : {mean_f1:.4f}\")\n",
    "\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# Step 8: Save to CSV\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "result_df = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "\n",
    "result_df.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "262e550f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-01 04:26:15,712] A new study created in memory with name: no-name-ccd38343-7614-49fc-b43a-42b60dcb5f99\n",
      "Best trial: 0. Best value: 0.301149:   2%|▏         | 1/50 [00:01<01:16,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-01 04:26:17,269] Trial 0 finished with value: 0.3011494252873563 and parameters: {'n_estimators': 256, 'learning_rate': 0.06437650153461226, 'max_depth': 12, 'num_leaves': 66, 'min_child_samples': 23, 'subsample': 0.82604903292285, 'colsample_bytree': 0.9172348942662111}. Best is trial 0 with value: 0.3011494252873563.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.690345:   4%|▍         | 2/50 [00:02<01:00,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-01 04:26:18,305] Trial 1 finished with value: 0.6903448275862069 and parameters: {'n_estimators': 143, 'learning_rate': 0.01808390820589944, 'max_depth': 11, 'num_leaves': 22, 'min_child_samples': 20, 'subsample': 0.8533956585674802, 'colsample_bytree': 0.7413428977530838}. Best is trial 1 with value: 0.6903448275862069.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.690345:   6%|▌         | 3/50 [00:03<00:58,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-01 04:26:19,528] Trial 2 finished with value: 0.31448275862068964 and parameters: {'n_estimators': 230, 'learning_rate': 0.09490829908620897, 'max_depth': 7, 'num_leaves': 69, 'min_child_samples': 26, 'subsample': 0.7043700852313121, 'colsample_bytree': 0.9179080509729569}. Best is trial 1 with value: 0.6903448275862069.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.690345:   8%|▊         | 4/50 [00:05<01:05,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-01 04:26:21,248] Trial 3 finished with value: 0.3142528735632184 and parameters: {'n_estimators': 286, 'learning_rate': 0.07011957499760184, 'max_depth': 6, 'num_leaves': 59, 'min_child_samples': 11, 'subsample': 0.7628592796896877, 'colsample_bytree': 0.9187635684711521}. Best is trial 1 with value: 0.6903448275862069.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.690345:  10%|█         | 5/50 [00:06<01:03,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-01 04:26:22,621] Trial 4 finished with value: 0.3009195402298851 and parameters: {'n_estimators': 217, 'learning_rate': 0.08884873859360634, 'max_depth': 6, 'num_leaves': 22, 'min_child_samples': 14, 'subsample': 0.7577044373483421, 'colsample_bytree': 0.7540381818719516}. Best is trial 1 with value: 0.6903448275862069.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.690345:  12%|█▏        | 6/50 [00:08<00:57,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-01 04:26:23,737] Trial 5 finished with value: 0.39011494252873563 and parameters: {'n_estimators': 203, 'learning_rate': 0.0765694748745873, 'max_depth': 4, 'num_leaves': 23, 'min_child_samples': 12, 'subsample': 0.8878669508278185, 'colsample_bytree': 0.9961610099842072}. Best is trial 1 with value: 0.6903448275862069.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.690345:  14%|█▍        | 7/50 [00:09<01:02,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-01 04:26:25,456] Trial 6 finished with value: 0.23264367816091952 and parameters: {'n_estimators': 280, 'learning_rate': 0.14708325566076003, 'max_depth': 10, 'num_leaves': 67, 'min_child_samples': 10, 'subsample': 0.8318916767543824, 'colsample_bytree': 0.7949832788634643}. Best is trial 1 with value: 0.6903448275862069.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.690345:  16%|█▌        | 8/50 [00:10<00:56,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-01 04:26:26,555] Trial 7 finished with value: 0.43747126436781614 and parameters: {'n_estimators': 300, 'learning_rate': 0.0663820255144424, 'max_depth': 5, 'num_leaves': 36, 'min_child_samples': 40, 'subsample': 0.8056741899938368, 'colsample_bytree': 0.9061351497769191}. Best is trial 1 with value: 0.6903448275862069.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.690345:  18%|█▊        | 9/50 [00:11<00:50,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-01 04:26:27,528] Trial 8 finished with value: 0.492183908045977 and parameters: {'n_estimators': 270, 'learning_rate': 0.053894458938217586, 'max_depth': 5, 'num_leaves': 26, 'min_child_samples': 40, 'subsample': 0.6326447027034466, 'colsample_bytree': 0.8947308390329576}. Best is trial 1 with value: 0.6903448275862069.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.690345:  20%|██        | 10/50 [00:12<00:44,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-01 04:26:28,401] Trial 9 finished with value: 0.526896551724138 and parameters: {'n_estimators': 123, 'learning_rate': 0.06012116638667669, 'max_depth': 5, 'num_leaves': 54, 'min_child_samples': 26, 'subsample': 0.9131746913691114, 'colsample_bytree': 0.8908414088009055}. Best is trial 1 with value: 0.6903448275862069.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.896552:  22%|██▏       | 11/50 [00:13<00:39,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-01 04:26:29,221] Trial 10 finished with value: 0.8965517241379309 and parameters: {'n_estimators': 127, 'learning_rate': 0.010023945390530739, 'max_depth': 9, 'num_leaves': 41, 'min_child_samples': 48, 'subsample': 0.9854607315417959, 'colsample_bytree': 0.6329137223173084}. Best is trial 10 with value: 0.8965517241379309.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.896552:  24%|██▍       | 12/50 [00:14<00:37,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-01 04:26:30,086] Trial 11 finished with value: 0.8896551724137931 and parameters: {'n_estimators': 134, 'learning_rate': 0.010040509389580114, 'max_depth': 9, 'num_leaves': 36, 'min_child_samples': 46, 'subsample': 0.9997720747869486, 'colsample_bytree': 0.6189320053321874}. Best is trial 10 with value: 0.8965517241379309.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.896552:  26%|██▌       | 13/50 [00:15<00:34,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-01 04:26:30,951] Trial 12 finished with value: 0.8347126436781609 and parameters: {'n_estimators': 164, 'learning_rate': 0.01279391662304418, 'max_depth': 9, 'num_leaves': 43, 'min_child_samples': 49, 'subsample': 0.9996349420605923, 'colsample_bytree': 0.6032097258107726}. Best is trial 10 with value: 0.8965517241379309.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.896552:  28%|██▊       | 14/50 [00:15<00:31,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-01 04:26:31,685] Trial 13 finished with value: 0.7526436781609196 and parameters: {'n_estimators': 100, 'learning_rate': 0.034464405095131115, 'max_depth': 9, 'num_leaves': 40, 'min_child_samples': 47, 'subsample': 0.977137828934699, 'colsample_bytree': 0.600035516540646}. Best is trial 10 with value: 0.8965517241379309.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.896552:  30%|███       | 15/50 [00:16<00:31,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-01 04:26:32,662] Trial 14 finished with value: 0.5744827586206898 and parameters: {'n_estimators': 177, 'learning_rate': 0.03488134573888141, 'max_depth': 8, 'num_leaves': 80, 'min_child_samples': 36, 'subsample': 0.938541016173177, 'colsample_bytree': 0.6772109407688273}. Best is trial 10 with value: 0.8965517241379309.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.896552:  32%|███▏      | 16/50 [00:17<00:29,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-01 04:26:33,434] Trial 15 finished with value: 0.4579310344827586 and parameters: {'n_estimators': 131, 'learning_rate': 0.11382165054907883, 'max_depth': 10, 'num_leaves': 36, 'min_child_samples': 45, 'subsample': 0.9574888540722462, 'colsample_bytree': 0.6660275983994575}. Best is trial 10 with value: 0.8965517241379309.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.896552:  34%|███▍      | 17/50 [00:18<00:28,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-01 04:26:34,310] Trial 16 finished with value: 0.656551724137931 and parameters: {'n_estimators': 100, 'learning_rate': 0.03597378347650326, 'max_depth': 8, 'num_leaves': 47, 'min_child_samples': 33, 'subsample': 0.8919632567305815, 'colsample_bytree': 0.6675198105463968}. Best is trial 10 with value: 0.8965517241379309.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.896552:  36%|███▌      | 18/50 [00:19<00:27,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-01 04:26:35,135] Trial 17 finished with value: 0.8206896551724139 and parameters: {'n_estimators': 168, 'learning_rate': 0.011174408699458266, 'max_depth': 12, 'num_leaves': 31, 'min_child_samples': 43, 'subsample': 0.9955820344401161, 'colsample_bytree': 0.7194674355565469}. Best is trial 10 with value: 0.8965517241379309.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.896552:  38%|███▊      | 19/50 [00:20<00:25,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-01 04:26:35,903] Trial 18 finished with value: 0.6225287356321839 and parameters: {'n_estimators': 152, 'learning_rate': 0.04325444025575257, 'max_depth': 10, 'num_leaves': 52, 'min_child_samples': 50, 'subsample': 0.9356355038652007, 'colsample_bytree': 0.6456530811400094}. Best is trial 10 with value: 0.8965517241379309.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.896552:  40%|████      | 20/50 [00:20<00:24,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-01 04:26:36,700] Trial 19 finished with value: 0.8347126436781609 and parameters: {'n_estimators': 183, 'learning_rate': 0.02418209160578063, 'max_depth': 3, 'num_leaves': 31, 'min_child_samples': 37, 'subsample': 0.6169117773914566, 'colsample_bytree': 0.8285229687377085}. Best is trial 10 with value: 0.8965517241379309.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.896552:  42%|████▏     | 21/50 [00:21<00:25,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-01 04:26:37,680] Trial 20 finished with value: 0.4650574712643678 and parameters: {'n_estimators': 120, 'learning_rate': 0.11247884289664764, 'max_depth': 7, 'num_leaves': 44, 'min_child_samples': 43, 'subsample': 0.8635951395284581, 'colsample_bytree': 0.7020138882766398}. Best is trial 10 with value: 0.8965517241379309.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.896552:  44%|████▍     | 22/50 [00:22<00:25,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-01 04:26:38,642] Trial 21 finished with value: 0.8760919540229886 and parameters: {'n_estimators': 156, 'learning_rate': 0.01056028413140151, 'max_depth': 9, 'num_leaves': 42, 'min_child_samples': 50, 'subsample': 0.9938078603537503, 'colsample_bytree': 0.6043904227522199}. Best is trial 10 with value: 0.8965517241379309.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.896552:  46%|████▌     | 23/50 [00:23<00:24,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-01 04:26:39,523] Trial 22 finished with value: 0.7388505747126436 and parameters: {'n_estimators': 140, 'learning_rate': 0.024907780651501184, 'max_depth': 9, 'num_leaves': 36, 'min_child_samples': 50, 'subsample': 0.9648366443824572, 'colsample_bytree': 0.628819089172487}. Best is trial 10 with value: 0.8965517241379309.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.896552:  48%|████▊     | 24/50 [00:24<00:24,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-01 04:26:40,606] Trial 23 finished with value: 0.5673563218390804 and parameters: {'n_estimators': 154, 'learning_rate': 0.04950609032227429, 'max_depth': 11, 'num_leaves': 48, 'min_child_samples': 46, 'subsample': 0.9258722594969274, 'colsample_bytree': 0.6330975573661031}. Best is trial 10 with value: 0.8965517241379309.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.896552:  50%|█████     | 25/50 [00:25<00:24,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-01 04:26:41,635] Trial 24 finished with value: 0.8965517241379309 and parameters: {'n_estimators': 123, 'learning_rate': 0.010153345920538799, 'max_depth': 8, 'num_leaves': 30, 'min_child_samples': 41, 'subsample': 0.9972267280097399, 'colsample_bytree': 0.6909565632459731}. Best is trial 10 with value: 0.8965517241379309.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.896552:  52%|█████▏    | 26/50 [00:26<00:23,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-01 04:26:42,627] Trial 25 finished with value: 0.7452873563218391 and parameters: {'n_estimators': 114, 'learning_rate': 0.024015167891955964, 'max_depth': 8, 'num_leaves': 29, 'min_child_samples': 41, 'subsample': 0.9577202833450273, 'colsample_bytree': 0.6931051118545206}. Best is trial 10 with value: 0.8965517241379309.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.896552:  54%|█████▍    | 27/50 [00:27<00:23,  1.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-01 04:26:43,687] Trial 26 finished with value: 0.6016091954022988 and parameters: {'n_estimators': 188, 'learning_rate': 0.028525673830945026, 'max_depth': 7, 'num_leaves': 38, 'min_child_samples': 34, 'subsample': 0.8893198649514282, 'colsample_bytree': 0.7742695434573026}. Best is trial 10 with value: 0.8965517241379309.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.896552:  56%|█████▌    | 28/50 [00:28<00:21,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-01 04:26:44,603] Trial 27 finished with value: 0.5335632183908047 and parameters: {'n_estimators': 135, 'learning_rate': 0.04154315069656632, 'max_depth': 11, 'num_leaves': 32, 'min_child_samples': 30, 'subsample': 0.9671029912928988, 'colsample_bytree': 0.6483127291975785}. Best is trial 10 with value: 0.8965517241379309.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.896552:  58%|█████▊    | 29/50 [00:29<00:19,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-01 04:26:45,441] Trial 28 finished with value: 0.39701149425287363 and parameters: {'n_estimators': 115, 'learning_rate': 0.14412643001842457, 'max_depth': 8, 'num_leaves': 28, 'min_child_samples': 44, 'subsample': 0.9172701178344453, 'colsample_bytree': 0.7200586830674648}. Best is trial 10 with value: 0.8965517241379309.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.896552:  60%|██████    | 30/50 [00:30<00:17,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-01 04:26:46,145] Trial 29 finished with value: 0.8142528735632183 and parameters: {'n_estimators': 108, 'learning_rate': 0.018467766994660018, 'max_depth': 10, 'num_leaves': 58, 'min_child_samples': 38, 'subsample': 0.6665249785484801, 'colsample_bytree': 0.6324469317744353}. Best is trial 10 with value: 0.8965517241379309.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.896552:  62%|██████▏   | 31/50 [00:31<00:16,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-01 04:26:47,084] Trial 30 finished with value: 0.492183908045977 and parameters: {'n_estimators': 244, 'learning_rate': 0.04835855391205511, 'max_depth': 12, 'num_leaves': 46, 'min_child_samples': 47, 'subsample': 0.947006857179135, 'colsample_bytree': 0.8490803518057596}. Best is trial 10 with value: 0.8965517241379309.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.896552:  64%|██████▍   | 32/50 [00:32<00:16,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-01 04:26:47,984] Trial 31 finished with value: 0.8554022988505748 and parameters: {'n_estimators': 152, 'learning_rate': 0.011605765014589741, 'max_depth': 9, 'num_leaves': 41, 'min_child_samples': 48, 'subsample': 0.9971738150599714, 'colsample_bytree': 0.6015177446917139}. Best is trial 10 with value: 0.8965517241379309.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 32. Best value: 0.903448:  66%|██████▌   | 33/50 [00:33<00:15,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-01 04:26:48,974] Trial 32 finished with value: 0.903448275862069 and parameters: {'n_estimators': 130, 'learning_rate': 0.010621023535327288, 'max_depth': 9, 'num_leaves': 34, 'min_child_samples': 42, 'subsample': 0.9841645797653351, 'colsample_bytree': 0.6196231066172242}. Best is trial 32 with value: 0.903448275862069.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 32. Best value: 0.903448:  68%|██████▊   | 34/50 [00:34<00:14,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-01 04:26:49,884] Trial 33 finished with value: 0.7593103448275862 and parameters: {'n_estimators': 131, 'learning_rate': 0.019943177470395868, 'max_depth': 8, 'num_leaves': 33, 'min_child_samples': 42, 'subsample': 0.976678563851465, 'colsample_bytree': 0.6683038860307566}. Best is trial 32 with value: 0.903448275862069.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 32. Best value: 0.903448:  70%|███████   | 35/50 [00:35<00:14,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-01 04:26:50,874] Trial 34 finished with value: 0.6772413793103448 and parameters: {'n_estimators': 142, 'learning_rate': 0.032838154113451236, 'max_depth': 11, 'num_leaves': 26, 'min_child_samples': 45, 'subsample': 0.7598470303650058, 'colsample_bytree': 0.6956550108376216}. Best is trial 32 with value: 0.903448275862069.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 32. Best value: 0.903448:  72%|███████▏  | 36/50 [00:36<00:12,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-01 04:26:51,757] Trial 35 finished with value: 0.8071264367816091 and parameters: {'n_estimators': 128, 'learning_rate': 0.018695511323302206, 'max_depth': 6, 'num_leaves': 35, 'min_child_samples': 39, 'subsample': 0.9050920125375487, 'colsample_bytree': 0.6232724420552638}. Best is trial 32 with value: 0.903448275862069.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 32. Best value: 0.903448:  74%|███████▍  | 37/50 [00:37<00:12,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-01 04:26:52,927] Trial 36 finished with value: 0.5128735632183907 and parameters: {'n_estimators': 194, 'learning_rate': 0.02797547518849041, 'max_depth': 7, 'num_leaves': 22, 'min_child_samples': 21, 'subsample': 0.9774956792398325, 'colsample_bytree': 0.7463902500521108}. Best is trial 32 with value: 0.903448275862069.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 32. Best value: 0.903448:  76%|███████▌  | 38/50 [00:38<00:13,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-01 04:26:54,395] Trial 37 finished with value: 0.6427586206896552 and parameters: {'n_estimators': 207, 'learning_rate': 0.017067388587060903, 'max_depth': 10, 'num_leaves': 39, 'min_child_samples': 27, 'subsample': 0.8556024243094462, 'colsample_bytree': 0.6515705389876062}. Best is trial 32 with value: 0.903448275862069.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 32. Best value: 0.903448:  78%|███████▊  | 39/50 [00:39<00:12,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-01 04:26:55,411] Trial 38 finished with value: 0.4036781609195403 and parameters: {'n_estimators': 165, 'learning_rate': 0.08841897722914073, 'max_depth': 9, 'num_leaves': 26, 'min_child_samples': 36, 'subsample': 0.7382368125033923, 'colsample_bytree': 0.7164958763720084}. Best is trial 32 with value: 0.903448275862069.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 32. Best value: 0.903448:  80%|████████  | 40/50 [00:40<00:10,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-01 04:26:56,361] Trial 39 finished with value: 0.40344827586206905 and parameters: {'n_estimators': 109, 'learning_rate': 0.10439413631216209, 'max_depth': 7, 'num_leaves': 20, 'min_child_samples': 16, 'subsample': 0.9409922414422591, 'colsample_bytree': 0.6219295664282746}. Best is trial 32 with value: 0.903448275862069.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 32. Best value: 0.903448:  82%|████████▏ | 41/50 [00:41<00:09,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-01 04:26:57,310] Trial 40 finished with value: 0.4517241379310345 and parameters: {'n_estimators': 147, 'learning_rate': 0.057827574600614384, 'max_depth': 8, 'num_leaves': 29, 'min_child_samples': 32, 'subsample': 0.7907857438795558, 'colsample_bytree': 0.9928730546776857}. Best is trial 32 with value: 0.903448275862069.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 32. Best value: 0.903448:  84%|████████▍ | 42/50 [00:42<00:07,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-01 04:26:58,071] Trial 41 finished with value: 0.8896551724137931 and parameters: {'n_estimators': 125, 'learning_rate': 0.010402523607873523, 'max_depth': 9, 'num_leaves': 43, 'min_child_samples': 48, 'subsample': 0.9820332072991466, 'colsample_bytree': 0.6192268154877639}. Best is trial 32 with value: 0.903448275862069.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 32. Best value: 0.903448:  86%|████████▌ | 43/50 [00:42<00:05,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-01 04:26:58,659] Trial 42 finished with value: 0.7802298850574713 and parameters: {'n_estimators': 124, 'learning_rate': 0.019244675122659705, 'max_depth': 9, 'num_leaves': 38, 'min_child_samples': 47, 'subsample': 0.9694358119789922, 'colsample_bytree': 0.6531380334361534}. Best is trial 32 with value: 0.903448275862069.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 32. Best value: 0.903448:  88%|████████▊ | 44/50 [00:43<00:04,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-01 04:26:59,361] Trial 43 finished with value: 0.7795402298850576 and parameters: {'n_estimators': 139, 'learning_rate': 0.01561221253687503, 'max_depth': 10, 'num_leaves': 45, 'min_child_samples': 42, 'subsample': 0.9847196399401844, 'colsample_bytree': 0.6835375588010741}. Best is trial 32 with value: 0.903448275862069.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 32. Best value: 0.903448:  90%|█████████ | 45/50 [00:44<00:03,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-01 04:27:00,017] Trial 44 finished with value: 0.8965517241379309 and parameters: {'n_estimators': 119, 'learning_rate': 0.010692475883850697, 'max_depth': 9, 'num_leaves': 50, 'min_child_samples': 45, 'subsample': 0.9430012140366565, 'colsample_bytree': 0.6179436459912624}. Best is trial 32 with value: 0.903448275862069.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 32. Best value: 0.903448:  92%|█████████▏| 46/50 [00:45<00:03,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-01 04:27:00,875] Trial 45 finished with value: 0.608735632183908 and parameters: {'n_estimators': 225, 'learning_rate': 0.02898857367631682, 'max_depth': 11, 'num_leaves': 63, 'min_child_samples': 45, 'subsample': 0.952142802536817, 'colsample_bytree': 0.6408224940841254}. Best is trial 32 with value: 0.903448275862069.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 32. Best value: 0.903448:  94%|█████████▍| 47/50 [00:45<00:02,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-01 04:27:01,574] Trial 46 finished with value: 0.6836781609195401 and parameters: {'n_estimators': 110, 'learning_rate': 0.04193561838556148, 'max_depth': 8, 'num_leaves': 54, 'min_child_samples': 41, 'subsample': 0.8311982648653845, 'colsample_bytree': 0.6151412051875033}. Best is trial 32 with value: 0.903448275862069.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 32. Best value: 0.903448:  96%|█████████▌| 48/50 [00:46<00:01,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-01 04:27:02,318] Trial 47 finished with value: 0.5742528735632184 and parameters: {'n_estimators': 116, 'learning_rate': 0.07112920750200813, 'max_depth': 9, 'num_leaves': 51, 'min_child_samples': 43, 'subsample': 0.8695736860236924, 'colsample_bytree': 0.6694016794253184}. Best is trial 32 with value: 0.903448275862069.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 32. Best value: 0.903448:  98%|█████████▊| 49/50 [00:47<00:00,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-01 04:27:03,189] Trial 48 finished with value: 0.6770114942528735 and parameters: {'n_estimators': 171, 'learning_rate': 0.022679364415264837, 'max_depth': 10, 'num_leaves': 76, 'min_child_samples': 38, 'subsample': 0.9054879050284438, 'colsample_bytree': 0.6507775342510063}. Best is trial 32 with value: 0.903448275862069.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 32. Best value: 0.903448: 100%|██████████| 50/50 [00:48<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-01 04:27:03,856] Trial 49 finished with value: 0.7181609195402298 and parameters: {'n_estimators': 100, 'learning_rate': 0.037622818727067055, 'max_depth': 7, 'num_leaves': 57, 'min_child_samples': 46, 'subsample': 0.9297999210096541, 'colsample_bytree': 0.7678147302453205}. Best is trial 32 with value: 0.903448275862069.\n",
      "Fold 1: Accuracy=0.8000, Precision=0.0000, Recall=0.0000, F1=0.0000, Threshold=0.50\n",
      "Fold 2: Accuracy=0.8000, Precision=0.0000, Recall=0.0000, F1=0.0000, Threshold=0.50\n",
      "Fold 3: Accuracy=0.8069, Precision=1.0000, Recall=0.0345, F1=0.0667, Threshold=0.50\n",
      "Fold 4: Accuracy=0.7793, Precision=0.2500, Recall=0.0333, F1=0.0588, Threshold=0.50\n",
      "Fold 5: Accuracy=0.7986, Precision=0.5000, Recall=0.0345, F1=0.0645, Threshold=0.50\n",
      "\n",
      "--- Final LightGBM Optimized ---\n",
      "Mean Accuracy : 0.7970\n",
      "Mean Precision: 0.3500\n",
      "Mean Recall   : 0.0205\n",
      "Mean F1 Score : 0.0380\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import optuna\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "# Step 1: Prepare data\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# Check constant columns\n",
    "constant_cols = [col for col in X.columns if X[col].nunique() <= 1]\n",
    "if constant_cols:\n",
    "    print(\"Warning: Constant columns detected:\", constant_cols)\n",
    "\n",
    "# Step 2: Column types\n",
    "categorical_cols = ['Gender', 'Religion', 'Branch', 'Section-1', 'Section-2', 'Section-3']\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Step 3: Preprocessor\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', drop='if_binary', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# Step 4: Classifier wrapper for threshold tuning\n",
    "class ThresholdLGBMClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, **params):\n",
    "        self.model = LGBMClassifier(**params)\n",
    "        self.threshold = 0.5\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.model.fit(X, y)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        probas = self.model.predict_proba(X)[:, 1]\n",
    "        return (probas >= self.threshold).astype(int)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return self.model.predict_proba(X)\n",
    "\n",
    "# Step 5: Objective function for Optuna\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 300),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.15),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 20, 80),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 10, 50),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 1.0),\n",
    "        \"class_weight\": \"balanced\",\n",
    "        \"random_state\": 42,\n",
    "        \"verbose\": -1\n",
    "    }\n",
    "\n",
    "    model = ThresholdLGBMClassifier(**params)\n",
    "    pipeline = Pipeline([('prep', preprocessor), ('clf', model)])\n",
    "    \n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    recalls = []\n",
    "\n",
    "    for train_idx, val_idx in cv.split(X, y):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        probas = pipeline.predict_proba(X_val)[:, 1]\n",
    "\n",
    "        # Find best threshold to maximize recall >= 0.85\n",
    "        best_recall, best_thresh = 0, 0.5\n",
    "        for thresh in np.arange(0.3, 0.8, 0.02):\n",
    "            preds = (probas >= thresh).astype(int)\n",
    "            rec = recall_score(y_val, preds)\n",
    "            if rec > best_recall:\n",
    "                best_recall, best_thresh = rec, thresh\n",
    "\n",
    "        model.threshold = best_thresh\n",
    "        preds = (probas >= best_thresh).astype(int)\n",
    "\n",
    "        recalls.append(recall_score(y_val, preds))\n",
    "\n",
    "    return np.mean(recalls)\n",
    "\n",
    "# Step 6: Tune with Optuna\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=50, show_progress_bar=True)\n",
    "best_params = study.best_trial.params\n",
    "\n",
    "# Step 7: Final Evaluation\n",
    "model = ThresholdLGBMClassifier(**best_params)\n",
    "pipeline = Pipeline([('prep', preprocessor), ('clf', model)])\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    probas = pipeline.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    # Best threshold for this fold\n",
    "    best_thresh, best_f1 = 0.5, 0\n",
    "    for thresh in np.arange(0.3, 0.8, 0.01):\n",
    "        preds = (probas >= thresh).astype(int)\n",
    "        rec = recall_score(y_val, preds)\n",
    "        prec = precision_score(y_val, preds, zero_division=0)\n",
    "        f1_val = f1_score(y_val, preds)\n",
    "        if rec >= 0.85 and prec > 0.5 and f1_val > best_f1:\n",
    "            best_f1, best_thresh = f1_val, thresh\n",
    "\n",
    "    model.threshold = best_thresh\n",
    "    y_pred = pipeline.predict(X_val)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}, F1={f1:.4f}, Threshold={best_thresh:.2f}\")\n",
    "\n",
    "# Final metrics\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "print(\"\\n--- Final LightGBM Optimized ---\")\n",
    "print(f\"Mean Accuracy : {mean_acc:.4f}\")\n",
    "print(f\"Mean Precision: {mean_prec:.4f}\")\n",
    "print(f\"Mean Recall   : {mean_rec:.4f}\")\n",
    "print(f\"Mean F1 Score : {mean_f1:.4f}\")\n",
    "\n",
    "# CSV logging\n",
    "model_name = 'LightGBM-Optuna-Threshold'\n",
    "model_desc = 'Optuna+ThresholdTuning+5Fold'\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "result_df = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "result_df.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec73b938",
   "metadata": {},
   "source": [
    "# CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e8057ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.7172, Precision=0.2273,  Recall=0.1724, F1=0.1961\n",
      "Fold 2: Accuracy=0.7379, Precision=0.2353,  Recall=0.1379, F1=0.1739\n",
      "Fold 3: Accuracy=0.8069, Precision=0.5238,  Recall=0.3793, F1=0.4400\n",
      "Fold 4: Accuracy=0.7103, Precision=0.3235,  Recall=0.3667, F1=0.3438\n",
      "Fold 5: Accuracy=0.7014, Precision=0.2667,  Recall=0.2759, F1=0.2712\n",
      "\n",
      "--- CatBoost Summary ---\n",
      "Mean Accuracy : 0.7348\n",
      "Mean Precision: 0.3153\n",
      "Mean Recall   : 0.2664\n",
      "Mean F1 Score : 0.2850\n",
      "\n",
      "CSV Row Format:\n",
      "CatBoost-Balanced,OneHot+Scaler+5Fold-Stratified+VerboseOff,0.7348,0.3153,0.2664,0.2850\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Step 1: Prepare data\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# Optional: Check constant columns\n",
    "constant_cols = [col for col in X.columns if X[col].nunique() <= 1]\n",
    "if constant_cols:\n",
    "    print(\"Warning: Constant columns detected:\", constant_cols)\n",
    "\n",
    "# Step 2: Column categories\n",
    "categorical_cols = ['Gender', 'Religion', 'Branch', 'Section-1', 'Section-2', 'Section-3']\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Step 3: Preprocessing\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', drop='if_binary', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# Step 4: CatBoost Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('model', CatBoostClassifier(\n",
    "        iterations=100,\n",
    "        learning_rate=0.1,\n",
    "        depth=6,\n",
    "        auto_class_weights='Balanced',\n",
    "        verbose=0,  # suppress CatBoost internal logs\n",
    "        random_seed=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Step 5: Cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_val)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f},  Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# Step 6: Averages\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# Step 7: Model description\n",
    "model_name = 'CatBoost-Balanced'\n",
    "model_desc = 'OneHot+Scaler+5Fold-Stratified+VerboseOff'\n",
    "\n",
    "# Console summary\n",
    "print(\"\\n--- CatBoost Summary ---\")\n",
    "print(f\"Mean Accuracy : {mean_acc:.4f}\")\n",
    "print(f\"Mean Precision: {mean_prec:.4f}\")\n",
    "print(f\"Mean Recall   : {mean_rec:.4f}\")\n",
    "print(f\"Mean F1 Score : {mean_f1:.4f}\")\n",
    "\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# Step 8: Save to CSV\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "result_df = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "\n",
    "result_df.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "73991d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.7655, Precision=0.3077,  Recall=0.1379, F1=0.1905\n",
      "Fold 2: Accuracy=0.7724, Precision=0.3000,  Recall=0.1034, F1=0.1538\n",
      "Fold 3: Accuracy=0.7793, Precision=0.4286,  Recall=0.3103, F1=0.3600\n",
      "Fold 4: Accuracy=0.7448, Precision=0.3158,  Recall=0.2000, F1=0.2449\n",
      "Fold 5: Accuracy=0.7361, Precision=0.3043,  Recall=0.2414, F1=0.2692\n",
      "\n",
      "--- CatBoost Tuned Summary ---\n",
      "Mean Accuracy : 0.7596\n",
      "Mean Precision: 0.3313\n",
      "Mean Recall   : 0.1986\n",
      "Mean F1 Score : 0.2437\n",
      "\n",
      "CSV Row Format:\n",
      "CatBoost-Tuned,OneHot+Scaler+5Fold+Depth8+LR0.05+BagTemp1.0,0.7596,0.3313,0.1986,0.2437\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Step 1: Prepare data\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# Optional: Check constant columns\n",
    "constant_cols = [col for col in X.columns if X[col].nunique() <= 1]\n",
    "if constant_cols:\n",
    "    print(\"Warning: Constant columns detected:\", constant_cols)\n",
    "\n",
    "# Step 2: Column categories\n",
    "categorical_cols = ['Gender', 'Religion', 'Branch', 'Section-1', 'Section-2', 'Section-3']\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Step 3: Preprocessing\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', drop='if_binary', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# Step 4: Tuned CatBoost Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('model', CatBoostClassifier(\n",
    "        iterations=300,\n",
    "        learning_rate=0.05,\n",
    "        depth=8,\n",
    "        l2_leaf_reg=5,\n",
    "        border_count=128,\n",
    "        bagging_temperature=1.0,\n",
    "        auto_class_weights='Balanced',\n",
    "        random_seed=42,\n",
    "        verbose=0\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Step 5: Cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_val)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f},  Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# Step 6: Averages\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# Step 7: Model description\n",
    "model_name = 'CatBoost-Tuned'\n",
    "model_desc = 'OneHot+Scaler+5Fold+Depth8+LR0.05+BagTemp1.0'\n",
    "\n",
    "# Console summary\n",
    "print(\"\\n--- CatBoost Tuned Summary ---\")\n",
    "print(f\"Mean Accuracy : {mean_acc:.4f}\")\n",
    "print(f\"Mean Precision: {mean_prec:.4f}\")\n",
    "print(f\"Mean Recall   : {mean_rec:.4f}\")\n",
    "print(f\"Mean F1 Score : {mean_f1:.4f}\")\n",
    "\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# Step 8: Save to CSV\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "result_df = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "\n",
    "result_df.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "507c491c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.7586, Precision=0.2500,  Recall=0.1034, F1=0.1463\n",
      "Fold 2: Accuracy=0.7793, Precision=0.2000,  Recall=0.0345, F1=0.0588\n",
      "Fold 3: Accuracy=0.8207, Precision=0.6000,  Recall=0.3103, F1=0.4091\n",
      "Fold 4: Accuracy=0.7655, Precision=0.3750,  Recall=0.2000, F1=0.2609\n",
      "Fold 5: Accuracy=0.7431, Precision=0.3182,  Recall=0.2414, F1=0.2745\n",
      "\n",
      "--- CatBoost Aggressive Summary ---\n",
      "Mean Accuracy : 0.7734\n",
      "Mean Precision: 0.3486\n",
      "Mean Recall   : 0.1779\n",
      "Mean F1 Score : 0.2299\n",
      "\n",
      "CSV Row Format:\n",
      "CatBoost-Aggressive,OneHot+Scaler+500Iter+LR0.03+Depth10+Bag0.25,0.7734,0.3486,0.1779,0.2299\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Prepare data\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# Optional: Check constant columns\n",
    "constant_cols = [col for col in X.columns if X[col].nunique() <= 1]\n",
    "if constant_cols:\n",
    "    print(\"Warning: Constant columns detected:\", constant_cols)\n",
    "\n",
    "# Define column types\n",
    "categorical_cols = ['Gender', 'Religion', 'Branch', 'Section-1', 'Section-2', 'Section-3']\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Preprocessing\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', drop='if_binary', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# Aggressively Tuned CatBoost\n",
    "pipeline = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('model', CatBoostClassifier(\n",
    "        iterations=500,\n",
    "        learning_rate=0.03,\n",
    "        depth=10,\n",
    "        l2_leaf_reg=3,\n",
    "        border_count=128,\n",
    "        bagging_temperature=0.25,\n",
    "        auto_class_weights='Balanced',\n",
    "        random_seed=42,\n",
    "        verbose=0\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_val)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f},  Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# Averages\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# Description\n",
    "model_name = 'CatBoost-Aggressive'\n",
    "model_desc = 'OneHot+Scaler+500Iter+LR0.03+Depth10+Bag0.25'\n",
    "\n",
    "print(\"\\n--- CatBoost Aggressive Summary ---\")\n",
    "print(f\"Mean Accuracy : {mean_acc:.4f}\")\n",
    "print(f\"Mean Precision: {mean_prec:.4f}\")\n",
    "print(f\"Mean Recall   : {mean_rec:.4f}\")\n",
    "print(f\"Mean F1 Score : {mean_f1:.4f}\")\n",
    "\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# Save to CSV\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "result_df = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "\n",
    "result_df.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0a769b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.7862, Precision=0.4167, Recall=0.1724, F1=0.2439\n",
      "Fold 2: Accuracy=0.7931, Precision=0.4444, Recall=0.1379, F1=0.2105\n",
      "Fold 3: Accuracy=0.8000, Precision=0.5000, Recall=0.2414, F1=0.3256\n",
      "Fold 4: Accuracy=0.7862, Precision=0.4667, Recall=0.2333, F1=0.3111\n",
      "Fold 5: Accuracy=0.7639, Precision=0.3333, Recall=0.1724, F1=0.2273\n",
      "\n",
      "--- CatBoost Bayesian Tuning Summary ---\n",
      "Mean Accuracy : 0.7859\n",
      "Mean Precision: 0.4322\n",
      "Mean Recall   : 0.1915\n",
      "Mean F1 Score : 0.2637\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer\n",
    "\n",
    "# Prepare data\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# Constant column check\n",
    "constant_cols = [col for col in X.columns if X[col].nunique() <= 1]\n",
    "if constant_cols:\n",
    "    print(\"Warning: Constant columns detected:\", constant_cols)\n",
    "\n",
    "# Categorical and numerical columns\n",
    "categorical_cols = ['Gender', 'Religion', 'Branch', 'Section-1', 'Section-2', 'Section-3']\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Preprocessing\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', drop='if_binary', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# Define CatBoost with default settings (will be tuned)\n",
    "cat_model = CatBoostClassifier(\n",
    "    auto_class_weights='Balanced',\n",
    "    random_seed=42,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Create pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('model', cat_model)\n",
    "])\n",
    "\n",
    "# Define parameter search space\n",
    "param_space = {\n",
    "    'model__iterations': Integer(300, 800),\n",
    "    'model__learning_rate': Real(0.01, 0.2, prior='log-uniform'),\n",
    "    'model__depth': Integer(4, 10),\n",
    "    'model__l2_leaf_reg': Real(1, 10),\n",
    "    'model__bagging_temperature': Real(0, 1.0),\n",
    "    'model__border_count': Integer(32, 254)\n",
    "}\n",
    "\n",
    "# Setup Bayesian optimization with 5-fold stratified CV\n",
    "opt = BayesSearchCV(\n",
    "    estimator=pipeline,\n",
    "    search_spaces=param_space,\n",
    "    scoring='accuracy',\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    n_iter=32,\n",
    "    n_jobs=-1,\n",
    "    verbose=0,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the search\n",
    "opt.fit(X, y)\n",
    "\n",
    "# Extract best pipeline and evaluate manually\n",
    "best_pipeline = opt.best_estimator_\n",
    "\n",
    "# Manual 5-Fold Eval\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "acc_list, prec_list, rec_list, f1_list = [], [], [], []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    best_pipeline.fit(X_train, y_train)\n",
    "    y_pred = best_pipeline.predict(X_val)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    acc_list.append(acc)\n",
    "    prec_list.append(prec)\n",
    "    rec_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# Averages\n",
    "mean_acc = np.mean(acc_list)\n",
    "mean_prec = np.mean(prec_list)\n",
    "mean_rec = np.mean(rec_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "model_name = 'CatBoost-BayesTuned'\n",
    "model_desc = 'OneHot+Scaler+BayesSearch+5Fold'\n",
    "\n",
    "print(\"\\n--- CatBoost Bayesian Tuning Summary ---\")\n",
    "print(f\"Mean Accuracy : {mean_acc:.4f}\")\n",
    "print(f\"Mean Precision: {mean_prec:.4f}\")\n",
    "print(f\"Mean Recall   : {mean_rec:.4f}\")\n",
    "print(f\"Mean F1 Score : {mean_f1:.4f}\")\n",
    "\n",
    "# Save to CSV\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "result_df = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "result_df.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395d5dd5",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "686a2696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.6690, Precision=0.2791, Recall=0.4138, F1=0.3333\n",
      "Fold 2: Accuracy=0.7172, Precision=0.3235, Recall=0.3793, F1=0.3492\n",
      "Fold 3: Accuracy=0.6759, Precision=0.3500, Recall=0.7241, F1=0.4719\n",
      "Fold 4: Accuracy=0.6069, Precision=0.2923, Recall=0.6333, F1=0.4000\n",
      "Fold 5: Accuracy=0.5764, Precision=0.2333, Recall=0.4828, F1=0.3146\n",
      "\n",
      "--- SVM (RBF) Summary ---\n",
      "Name                          : SVC-RBF-Pipeline\n",
      "Description                   : OneHot+Scaler+5Fold+Balanced\n",
      "Accuracy                      : 0.6491\n",
      "Precision                     : 0.2956\n",
      "Recall                        : 0.5267\n",
      "F1 Score                      : 0.3738\n",
      "\n",
      "CSV Row Format:\n",
      "SVC-RBF-Pipeline,OneHot+Scaler+5Fold+Balanced,0.6491,0.2956,0.5267,0.3738\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Data setup\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# Identify column types\n",
    "categorical_cols = ['Gender', 'Religion', 'Branch', 'Section-1', 'Section-2', 'Section-3']\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Preprocessing\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', drop='if_binary', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# SVM model inside pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('model', SVC(kernel='rbf', class_weight='balanced', probability=True, random_state=42))\n",
    "])\n",
    "\n",
    "# CV setup\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n",
    "\n",
    "# Cross-validation loop\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_val)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# Mean scores\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# Model info\n",
    "model_name = 'SVC-RBF-Pipeline'\n",
    "model_desc = 'OneHot+Scaler+5Fold+Balanced'\n",
    "\n",
    "print(\"\\n--- SVM (RBF) Summary ---\")\n",
    "print(f\"{'Name':<30}: {model_name}\")\n",
    "print(f\"{'Description':<30}: {model_desc}\")\n",
    "print(f\"{'Accuracy':<30}: {mean_acc:.4f}\")\n",
    "print(f\"{'Precision':<30}: {mean_prec:.4f}\")\n",
    "print(f\"{'Recall':<30}: {mean_rec:.4f}\")\n",
    "print(f\"{'F1 Score':<30}: {mean_f1:.4f}\")\n",
    "\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# Save to CSV\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "new_row = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "\n",
    "new_row.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ac3d4ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.8000, Precision=0.0000, Recall=0.0000, F1=0.0000\n",
      "Fold 2: Accuracy=0.8000, Precision=0.0000, Recall=0.0000, F1=0.0000\n",
      "Fold 3: Accuracy=0.8000, Precision=0.0000, Recall=0.0000, F1=0.0000\n",
      "Fold 4: Accuracy=0.7931, Precision=0.0000, Recall=0.0000, F1=0.0000\n",
      "Fold 5: Accuracy=0.7986, Precision=0.0000, Recall=0.0000, F1=0.0000\n",
      "\n",
      "--- Tuned SVM (RBF) Summary ---\n",
      "Mean Accuracy : 0.7983\n",
      "Mean Precision: 0.0000\n",
      "Mean Recall   : 0.0000\n",
      "Mean F1 Score : 0.0000\n",
      "\n",
      "CSV Row Format:\n",
      "SVC-BayesTuned,OneHot+Scaler+BayesSearch+RBF+Balanced,0.7983,0.0000,0.0000,0.0000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Step 1: Data setup\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# Step 2: Column types\n",
    "categorical_cols = ['Gender', 'Religion', 'Branch', 'Section-1', 'Section-2', 'Section-3']\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Step 3: Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', drop='if_binary', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# Step 4: SVC pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('model', SVC(probability=True, random_state=42))\n",
    "])\n",
    "\n",
    "# Step 5: Define search space\n",
    "param_space = {\n",
    "    'model__C': Real(0.1, 100, prior='log-uniform'),\n",
    "    'model__gamma': Real(1e-4, 1.0, prior='log-uniform'),\n",
    "    'model__kernel': ['rbf'],\n",
    "    'model__class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "# Step 6: Bayesian optimization\n",
    "opt = BayesSearchCV(\n",
    "    estimator=pipeline,\n",
    "    search_spaces=param_space,\n",
    "    scoring='accuracy',\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    n_iter=32,\n",
    "    n_jobs=-1,\n",
    "    verbose=0,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Step 7: Fit optimizer\n",
    "opt.fit(X, y)\n",
    "best_pipeline = opt.best_estimator_\n",
    "\n",
    "# Step 8: Manual evaluation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "acc_list, prec_list, rec_list, f1_list = [], [], [], []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    best_pipeline.fit(X_train, y_train)\n",
    "    y_pred = best_pipeline.predict(X_val)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    acc_list.append(acc)\n",
    "    prec_list.append(prec)\n",
    "    rec_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# Step 9: Aggregate metrics\n",
    "mean_acc = np.mean(acc_list)\n",
    "mean_prec = np.mean(prec_list)\n",
    "mean_rec = np.mean(rec_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "model_name = 'SVC-BayesTuned'\n",
    "model_desc = 'OneHot+Scaler+BayesSearch+RBF+Balanced'\n",
    "\n",
    "print(\"\\n--- Tuned SVM (RBF) Summary ---\")\n",
    "print(f\"Mean Accuracy : {mean_acc:.4f}\")\n",
    "print(f\"Mean Precision: {mean_prec:.4f}\")\n",
    "print(f\"Mean Recall   : {mean_rec:.4f}\")\n",
    "print(f\"Mean F1 Score : {mean_f1:.4f}\")\n",
    "\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# Step 10: Save to CSV\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "result_df = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "\n",
    "result_df.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "51a6935a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.8000, Precision=0.0000, Recall=0.0000, F1=0.0000\n",
      "Fold 2: Accuracy=0.8000, Precision=0.0000, Recall=0.0000, F1=0.0000\n",
      "Fold 3: Accuracy=0.8000, Precision=0.0000, Recall=0.0000, F1=0.0000\n",
      "Fold 4: Accuracy=0.7931, Precision=0.0000, Recall=0.0000, F1=0.0000\n",
      "Fold 5: Accuracy=0.7986, Precision=0.0000, Recall=0.0000, F1=0.0000\n",
      "\n",
      "--- Tuned SVM (RBF) Summary ---\n",
      "Mean Accuracy : 0.7983\n",
      "Mean Precision: 0.0000\n",
      "Mean Recall   : 0.0000\n",
      "Mean F1 Score : 0.0000\n",
      "\n",
      "CSV Row Format:\n",
      "SVC-BayesTuned,OneHot+Scaler+BayesSearch+RBF+Balanced,0.7983,0.0000,0.0000,0.0000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Step 1: Data setup\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# Step 2: Column types\n",
    "categorical_cols = ['Gender', 'Religion', 'Branch', 'Section-1', 'Section-2', 'Section-3']\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Step 3: Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', drop='if_binary', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# Step 4: SVC pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('model', SVC(probability=True, random_state=42))\n",
    "])\n",
    "\n",
    "# Step 5: Define search space\n",
    "param_space = {\n",
    "    'model__C': Real(0.1, 100, prior='log-uniform'),\n",
    "    'model__gamma': Real(1e-4, 1.0, prior='log-uniform'),\n",
    "    'model__kernel': ['rbf'],\n",
    "    'model__class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "# Step 6: Bayesian optimization\n",
    "opt = BayesSearchCV(\n",
    "    estimator=pipeline,\n",
    "    search_spaces=param_space,\n",
    "    scoring='accuracy',\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    n_iter=32,\n",
    "    n_jobs=-1,\n",
    "    verbose=0,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Step 7: Fit optimizer\n",
    "opt.fit(X, y)\n",
    "best_pipeline = opt.best_estimator_\n",
    "\n",
    "# Step 8: Manual evaluation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "acc_list, prec_list, rec_list, f1_list = [], [], [], []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    best_pipeline.fit(X_train, y_train)\n",
    "    y_pred = best_pipeline.predict(X_val)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    acc_list.append(acc)\n",
    "    prec_list.append(prec)\n",
    "    rec_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# Step 9: Aggregate metrics\n",
    "mean_acc = np.mean(acc_list)\n",
    "mean_prec = np.mean(prec_list)\n",
    "mean_rec = np.mean(rec_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "model_name = 'SVC-BayesTuned'\n",
    "model_desc = 'OneHot+Scaler+BayesSearch+RBF+Balanced'\n",
    "\n",
    "print(\"\\n--- Tuned SVM (RBF) Summary ---\")\n",
    "print(f\"Mean Accuracy : {mean_acc:.4f}\")\n",
    "print(f\"Mean Precision: {mean_prec:.4f}\")\n",
    "print(f\"Mean Recall   : {mean_rec:.4f}\")\n",
    "print(f\"Mean F1 Score : {mean_f1:.4f}\")\n",
    "\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# Step 10: Save to CSV\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "result_df = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "\n",
    "result_df.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b53f9c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.2138, Precision=0.2028, Recall=1.0000, F1=0.3372\n",
      "Fold 2: Accuracy=0.2138, Precision=0.2028, Recall=1.0000, F1=0.3372\n",
      "Fold 3: Accuracy=0.2000, Precision=0.2000, Recall=1.0000, F1=0.3333\n",
      "Fold 4: Accuracy=0.2069, Precision=0.2069, Recall=1.0000, F1=0.3429\n",
      "Fold 5: Accuracy=0.7917, Precision=0.0000, Recall=0.0000, F1=0.0000\n",
      "\n",
      "--- Tuned SVM (RBF) Summary ---\n",
      "Mean Accuracy : 0.3252\n",
      "Mean Precision: 0.1625\n",
      "Mean Recall   : 0.8000\n",
      "Mean F1 Score : 0.2701\n",
      "\n",
      "CSV Row Format:\n",
      "SVC-BayesTuned-Recall,OneHot+Scaler+BayesSearch+RBF+Balanced+RecallOpt,0.3252,0.1625,0.8000,0.2701\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Step 1: Data setup\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# Step 2: Column types\n",
    "categorical_cols = ['Gender', 'Religion', 'Branch', 'Section-1', 'Section-2', 'Section-3']\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Step 3: Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', drop='if_binary', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# Step 4: SVC pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('model', SVC(probability=True, random_state=42))\n",
    "])\n",
    "\n",
    "# Step 5: Define search space for BayesSearchCV\n",
    "param_space = {\n",
    "    'model__C': Real(0.1, 100, prior='log-uniform'),\n",
    "    'model__gamma': Real(1e-4, 1.0, prior='log-uniform'),\n",
    "    'model__kernel': ['rbf'],\n",
    "    'model__class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "# Step 6: Bayesian optimization focused on RECALL\n",
    "opt = BayesSearchCV(\n",
    "    estimator=pipeline,\n",
    "    search_spaces=param_space,\n",
    "    scoring='recall',  # prioritize recall\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    n_iter=32,\n",
    "    n_jobs=-1,\n",
    "    verbose=0,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Step 7: Fit optimizer\n",
    "opt.fit(X, y)\n",
    "best_pipeline = opt.best_estimator_\n",
    "\n",
    "# Step 8: Manual evaluation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "acc_list, prec_list, rec_list, f1_list = [], [], [], []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    best_pipeline.fit(X_train, y_train)\n",
    "    y_pred = best_pipeline.predict(X_val)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    acc_list.append(acc)\n",
    "    prec_list.append(prec)\n",
    "    rec_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# Step 9: Aggregate metrics\n",
    "mean_acc = np.mean(acc_list)\n",
    "mean_prec = np.mean(prec_list)\n",
    "mean_rec = np.mean(rec_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "model_name = 'SVC-BayesTuned-Recall'\n",
    "model_desc = 'OneHot+Scaler+BayesSearch+RBF+Balanced+RecallOpt'\n",
    "\n",
    "print(\"\\n--- Tuned SVM (RBF) Summary ---\")\n",
    "print(f\"Mean Accuracy : {mean_acc:.4f}\")\n",
    "print(f\"Mean Precision: {mean_prec:.4f}\")\n",
    "print(f\"Mean Recall   : {mean_rec:.4f}\")\n",
    "print(f\"Mean F1 Score : {mean_f1:.4f}\")\n",
    "\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# Step 10: Save to CSV\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "result_df = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "\n",
    "result_df.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09e7176",
   "metadata": {},
   "source": [
    "# Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ebbca60a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.7724, Precision=0.3000, Recall=0.1034, F1=0.1538\n",
      "Fold 2: Accuracy=0.8138, Precision=0.7500, Recall=0.1034, F1=0.1818\n",
      "Fold 3: Accuracy=0.8069, Precision=0.5455, Recall=0.2069, F1=0.3000\n",
      "Fold 4: Accuracy=0.8138, Precision=0.6667, Recall=0.2000, F1=0.3077\n",
      "Fold 5: Accuracy=0.7847, Precision=0.4000, Recall=0.1379, F1=0.2051\n",
      "\n",
      "--- Model Summary ---\n",
      "Name                          : Bagging-DecisionTree\n",
      "Description                   : Bagging-with-Preprocessing-5Fold\n",
      "Accuracy                      : 0.7983\n",
      "Precision                     : 0.5324\n",
      "Recall                        : 0.1503\n",
      "F1 Score                      : 0.2297\n",
      "\n",
      "CSV Row Format:\n",
      "Bagging-DecisionTree,Bagging-with-Preprocessing-5Fold,0.7983,0.5324,0.1503,0.2297\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Data\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# Identify columns\n",
    "categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "# Preprocessor\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# Bagging Classifier pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocess', preprocessor),\n",
    "    ('model', BaggingClassifier(\n",
    "        estimator=DecisionTreeClassifier(),\n",
    "        n_estimators=50,\n",
    "        max_samples=0.8,\n",
    "        max_features=1.0,\n",
    "        bootstrap=True,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "# CV setup\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Metric storage\n",
    "accuracy_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "\n",
    "# 5-Fold Evaluation\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_val)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# Final metrics\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# Model info\n",
    "model_name = 'Bagging-DecisionTree'\n",
    "model_desc = 'Bagging-with-Preprocessing-5Fold'\n",
    "\n",
    "print(\"\\n--- Model Summary ---\")\n",
    "print(f\"{'Name':<30}: {model_name}\")\n",
    "print(f\"{'Description':<30}: {model_desc}\")\n",
    "print(f\"{'Accuracy':<30}: {mean_acc:.4f}\")\n",
    "print(f\"{'Precision':<30}: {mean_prec:.4f}\")\n",
    "print(f\"{'Recall':<30}: {mean_rec:.4f}\")\n",
    "print(f\"{'F1 Score':<30}: {mean_f1:.4f}\")\n",
    "\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# Save to CSV\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "new_row = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "new_row.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fc1f299b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.7931, Precision=0.4444, Recall=0.1379, F1=0.2105\n",
      "Fold 2: Accuracy=0.8000, Precision=0.5000, Recall=0.1034, F1=0.1714\n",
      "Fold 3: Accuracy=0.8207, Precision=0.5652, Recall=0.4483, F1=0.5000\n",
      "Fold 4: Accuracy=0.7793, Precision=0.4375, Recall=0.2333, F1=0.3043\n",
      "Fold 5: Accuracy=0.7847, Precision=0.4375, Recall=0.2414, F1=0.3111\n",
      "\n",
      "--- Final Tuned Model Summary ---\n",
      "Name                          : Bagging+DT-Tuned\n",
      "Description                   : BayesCV-Tuned-Recall-Max-5Fold\n",
      "Accuracy                      : 0.7956\n",
      "Precision                     : 0.4769\n",
      "Recall                        : 0.2329\n",
      "F1 Score                      : 0.2995\n",
      "\n",
      "CSV Row Format:\n",
      "Bagging+DT-Tuned,BayesCV-Tuned-Recall-Max-5Fold,0.7956,0.4769,0.2329,0.2995\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Data\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# Columns\n",
    "categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "# Preprocessor\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# Full pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocess', preprocessor),\n",
    "    ('model', BaggingClassifier(\n",
    "        estimator=DecisionTreeClassifier(),\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Parameter search space for Bagging + Decision Tree\n",
    "search_space = {\n",
    "    'model__n_estimators': Integer(10, 100),\n",
    "    'model__max_samples': Real(0.5, 1.0),\n",
    "    'model__max_features': Real(0.5, 1.0),\n",
    "    'model__estimator__max_depth': Integer(2, 20),\n",
    "    'model__estimator__min_samples_split': Integer(2, 10),\n",
    "    'model__estimator__min_samples_leaf': Integer(1, 10)\n",
    "}\n",
    "\n",
    "# BayesSearchCV setup (recall as scoring metric)\n",
    "bayes_search = BayesSearchCV(\n",
    "    estimator=pipeline,\n",
    "    search_spaces=search_space,\n",
    "    scoring=make_scorer(recall_score),\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    n_iter=30,\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Fit\n",
    "bayes_search.fit(X, y)\n",
    "\n",
    "# Best model\n",
    "best_model = bayes_search.best_estimator_\n",
    "\n",
    "# 5-Fold Evaluation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    best_model.fit(X_train, y_train)\n",
    "    y_pred = best_model.predict(X_val)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# Final metrics\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# Metadata\n",
    "model_name = 'Bagging+DT-Tuned'\n",
    "model_desc = 'BayesCV-Tuned-Recall-Max-5Fold'\n",
    "\n",
    "print(\"\\n--- Final Tuned Model Summary ---\")\n",
    "print(f\"{'Name':<30}: {model_name}\")\n",
    "print(f\"{'Description':<30}: {model_desc}\")\n",
    "print(f\"{'Accuracy':<30}: {mean_acc:.4f}\")\n",
    "print(f\"{'Precision':<30}: {mean_prec:.4f}\")\n",
    "print(f\"{'Recall':<30}: {mean_rec:.4f}\")\n",
    "print(f\"{'F1 Score':<30}: {mean_f1:.4f}\")\n",
    "\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# Save to CSV\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "new_row = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "new_row.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "83dd842e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.7931, Precision=0.4444, Recall=0.1379, F1=0.2105\n",
      "Fold 2: Accuracy=0.8000, Precision=0.5000, Recall=0.1034, F1=0.1714\n",
      "Fold 3: Accuracy=0.8207, Precision=0.5652, Recall=0.4483, F1=0.5000\n",
      "Fold 4: Accuracy=0.7793, Precision=0.4375, Recall=0.2333, F1=0.3043\n",
      "Fold 5: Accuracy=0.7847, Precision=0.4375, Recall=0.2414, F1=0.3111\n",
      "\n",
      "--- Final Tuned Model Summary ---\n",
      "Name                          : Bagging+DT-Tuned\n",
      "Description                   : BayesCV-Tuned-Recall-Max-5Fold\n",
      "Accuracy                      : 0.7956\n",
      "Precision                     : 0.4769\n",
      "Recall                        : 0.2329\n",
      "F1 Score                      : 0.2995\n",
      "\n",
      "CSV Row Format:\n",
      "Bagging+DT-Tuned,BayesCV-Tuned-Recall-Max-5Fold,0.7956,0.4769,0.2329,0.2995\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Data\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# Columns\n",
    "categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "# Preprocessor\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# Full pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocess', preprocessor),\n",
    "    ('model', BaggingClassifier(\n",
    "        estimator=DecisionTreeClassifier(),\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Parameter search space for Bagging + Decision Tree\n",
    "search_space = {\n",
    "    'model__n_estimators': Integer(10, 100),\n",
    "    'model__max_samples': Real(0.5, 1.0),\n",
    "    'model__max_features': Real(0.5, 1.0),\n",
    "    'model__estimator__max_depth': Integer(2, 20),\n",
    "    'model__estimator__min_samples_split': Integer(2, 10),\n",
    "    'model__estimator__min_samples_leaf': Integer(1, 10)\n",
    "}\n",
    "\n",
    "# BayesSearchCV setup (recall as scoring metric)\n",
    "bayes_search = BayesSearchCV(\n",
    "    estimator=pipeline,\n",
    "    search_spaces=search_space,\n",
    "    scoring=make_scorer(recall_score),\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    n_iter=30,\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Fit\n",
    "bayes_search.fit(X, y)\n",
    "\n",
    "# Best model\n",
    "best_model = bayes_search.best_estimator_\n",
    "\n",
    "# 5-Fold Evaluation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    best_model.fit(X_train, y_train)\n",
    "    y_pred = best_model.predict(X_val)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# Final metrics\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# Metadata\n",
    "model_name = 'Bagging+DT-Tuned'\n",
    "model_desc = 'BayesCV-Tuned-Recall-Max-5Fold'\n",
    "\n",
    "print(\"\\n--- Final Tuned Model Summary ---\")\n",
    "print(f\"{'Name':<30}: {model_name}\")\n",
    "print(f\"{'Description':<30}: {model_desc}\")\n",
    "print(f\"{'Accuracy':<30}: {mean_acc:.4f}\")\n",
    "print(f\"{'Precision':<30}: {mean_prec:.4f}\")\n",
    "print(f\"{'Recall':<30}: {mean_rec:.4f}\")\n",
    "print(f\"{'F1 Score':<30}: {mean_f1:.4f}\")\n",
    "\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# Save to CSV\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "new_row = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "new_row.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "62fa9965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.7103, Precision=0.3488, Recall=0.5172, F1=0.4167\n",
      "Fold 2: Accuracy=0.7379, Precision=0.3846, Recall=0.5172, F1=0.4412\n",
      "Fold 3: Accuracy=0.6621, Precision=0.3529, Recall=0.8276, F1=0.4948\n",
      "Fold 4: Accuracy=0.6759, Precision=0.3768, Recall=0.8667, F1=0.5253\n",
      "Fold 5: Accuracy=0.5833, Precision=0.2687, Recall=0.6207, F1=0.3750\n",
      "\n",
      "--- Final Tuned Bagging Model Summary ---\n",
      "Name                          : Bagging+DT-Balanced-Tuned\n",
      "Description                   : BaggingDT+Balanced+BayesCV-Recall\n",
      "Accuracy                      : 0.6739\n",
      "Precision                     : 0.3464\n",
      "Recall                        : 0.6699\n",
      "F1 Score                      : 0.4506\n",
      "\n",
      "CSV Row Format:\n",
      "Bagging+DT-Balanced-Tuned,BaggingDT+Balanced+BayesCV-Recall,0.6739,0.3464,0.6699,0.4506\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- Data Setup ---\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "# --- Preprocessing ---\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# --- Pipeline ---\n",
    "pipeline = Pipeline([\n",
    "    ('preprocess', preprocessor),\n",
    "    ('model', BaggingClassifier(\n",
    "        estimator=DecisionTreeClassifier(class_weight='balanced'),\n",
    "        n_estimators=50,\n",
    "        max_samples=0.8,\n",
    "        max_features=1.0,\n",
    "        bootstrap=True,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "# --- Search Space ---\n",
    "search_space = {\n",
    "    'model__n_estimators': Integer(20, 100),\n",
    "    'model__max_samples': Real(0.4, 1.0),\n",
    "    'model__max_features': Real(0.4, 1.0),\n",
    "    'model__estimator__max_depth': Integer(3, 20),\n",
    "    'model__estimator__min_samples_split': Integer(2, 15),\n",
    "    'model__estimator__min_samples_leaf': Integer(1, 10)\n",
    "}\n",
    "\n",
    "# --- Tuning ---\n",
    "bayes_search = BayesSearchCV(\n",
    "    estimator=pipeline,\n",
    "    search_spaces=search_space,\n",
    "    scoring=make_scorer(recall_score),\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    n_iter=30,\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# --- Fit ---\n",
    "bayes_search.fit(X, y)\n",
    "best_model = bayes_search.best_estimator_\n",
    "\n",
    "# --- Cross-Validation Evaluation ---\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    best_model.fit(X_train, y_train)\n",
    "    y_pred = best_model.predict(X_val)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# --- Final Metrics ---\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# --- Output ---\n",
    "model_name = 'Bagging+DT-Balanced-Tuned'\n",
    "model_desc = 'BaggingDT+Balanced+BayesCV-Recall'\n",
    "\n",
    "print(\"\\n--- Final Tuned Bagging Model Summary ---\")\n",
    "print(f\"{'Name':<30}: {model_name}\")\n",
    "print(f\"{'Description':<30}: {model_desc}\")\n",
    "print(f\"{'Accuracy':<30}: {mean_acc:.4f}\")\n",
    "print(f\"{'Precision':<30}: {mean_prec:.4f}\")\n",
    "print(f\"{'Recall':<30}: {mean_rec:.4f}\")\n",
    "print(f\"{'F1 Score':<30}: {mean_f1:.4f}\")\n",
    "\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# --- Save to CSV ---\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "new_row = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "new_row.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65502245",
   "metadata": {},
   "source": [
    "# AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b4dab5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.7586, Precision=0.2000, Recall=0.0690, F1=0.1026\n",
      "Fold 2: Accuracy=0.7931, Precision=0.4286, Recall=0.1034, F1=0.1667\n",
      "Fold 3: Accuracy=0.8276, Precision=0.6667, Recall=0.2759, F1=0.3902\n",
      "Fold 4: Accuracy=0.8069, Precision=0.6000, Recall=0.2000, F1=0.3000\n",
      "Fold 5: Accuracy=0.7639, Precision=0.3684, Recall=0.2414, F1=0.2917\n",
      "\n",
      "--- Model Summary ---\n",
      "Name                          : AdaBoostClassifier\n",
      "Description                   : AdaBoost-5Fold-Preprocessed\n",
      "Accuracy                      : 0.7900\n",
      "Precision                     : 0.4527\n",
      "Recall                        : 0.1779\n",
      "F1 Score                      : 0.2502\n",
      "\n",
      "CSV Row Format:\n",
      "AdaBoostClassifier,AdaBoost-5Fold-Preprocessed,0.7900,0.4527,0.1779,0.2502\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Data setup\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# Identify categorical and numerical columns\n",
    "categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "# Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols),\n",
    "        ('num', StandardScaler(), numerical_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# AdaBoost model pipeline\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocess', preprocessor),\n",
    "    ('classifier', AdaBoostClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# CV setup\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Metric storage\n",
    "accuracy_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "\n",
    "# 5-Fold Evaluation\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# Final metrics\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# Model info\n",
    "model_name = 'AdaBoostClassifier'\n",
    "model_desc = 'AdaBoost-5Fold-Preprocessed'\n",
    "\n",
    "# Print formatted summary\n",
    "print(\"\\n--- Model Summary ---\")\n",
    "print(f\"{'Name':<30}: {model_name}\")\n",
    "print(f\"{'Description':<30}: {model_desc}\")\n",
    "print(f\"{'Accuracy':<30}: {mean_acc:.4f}\")\n",
    "print(f\"{'Precision':<30}: {mean_prec:.4f}\")\n",
    "print(f\"{'Recall':<30}: {mean_rec:.4f}\")\n",
    "print(f\"{'F1 Score':<30}: {mean_f1:.4f}\")\n",
    "\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# Save to CSV (append row, create file if not exists)\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "new_row = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "new_row.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "17154eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.7793, Precision=0.3636, Recall=0.1379, F1=0.2000\n",
      "Fold 2: Accuracy=0.7862, Precision=0.3750, Recall=0.1034, F1=0.1622\n",
      "Fold 3: Accuracy=0.7793, Precision=0.4000, Recall=0.2069, F1=0.2727\n",
      "Fold 4: Accuracy=0.7655, Precision=0.4091, Recall=0.3000, F1=0.3462\n",
      "Fold 5: Accuracy=0.7847, Precision=0.4444, Recall=0.2759, F1=0.3404\n",
      "\n",
      "--- Tuned AdaBoost Summary ---\n",
      "Name                          : AdaBoostClassifier-Tuned\n",
      "Description                   : AdaBoost-Tuned-SAMME-OrderedDict({'classifier__learning_rate': 1.0, 'classifier__n_estimators': 182})\n",
      "Accuracy                      : 0.7790\n",
      "Precision                     : 0.3984\n",
      "Recall                        : 0.2048\n",
      "F1 Score                      : 0.2643\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Integer, Real\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Data setup\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# Categorical and numerical columns\n",
    "categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "# Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# AdaBoost pipeline\n",
    "pipe = Pipeline([\n",
    "    ('preprocess', preprocessor),\n",
    "    ('classifier', AdaBoostClassifier(algorithm='SAMME', random_state=42))\n",
    "])\n",
    "\n",
    "# Hyperparameter search space (no 'SAMME.R')\n",
    "search_space = {\n",
    "    'classifier__n_estimators': Integer(50, 300),\n",
    "    'classifier__learning_rate': Real(0.01, 1.0, prior='log-uniform')\n",
    "}\n",
    "\n",
    "# CV and tuner\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "opt = BayesSearchCV(\n",
    "    pipe,\n",
    "    search_spaces=search_space,\n",
    "    scoring='recall',\n",
    "    n_iter=25,\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=0,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the tuner\n",
    "opt.fit(X, y)\n",
    "\n",
    "# Final best model\n",
    "best_model = opt.best_estimator_\n",
    "\n",
    "# CV metric evaluation using best model\n",
    "accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    best_model.fit(X_train, y_train)\n",
    "    y_pred = best_model.predict(X_val)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# Final averages\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# Model info\n",
    "model_name = 'AdaBoostClassifier-Tuned'\n",
    "model_desc = f\"AdaBoost-Tuned-SAMME-{opt.best_params_}\"\n",
    "\n",
    "# Print summary\n",
    "print(\"\\n--- Tuned AdaBoost Summary ---\")\n",
    "print(f\"{'Name':<30}: {model_name}\")\n",
    "print(f\"{'Description':<30}: {model_desc}\")\n",
    "print(f\"{'Accuracy':<30}: {mean_acc:.4f}\")\n",
    "print(f\"{'Precision':<30}: {mean_prec:.4f}\")\n",
    "print(f\"{'Recall':<30}: {mean_rec:.4f}\")\n",
    "print(f\"{'F1 Score':<30}: {mean_f1:.4f}\")\n",
    "\n",
    "# CSV write\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "new_row = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "new_row.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0376e20f",
   "metadata": {},
   "source": [
    "# BalancedBaggingClassifier with a DecisionTreeClassifier(max_depth=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8996deb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.7103, Precision=0.3415, Recall=0.4828, F1=0.4000\n",
      "Fold 2: Accuracy=0.7586, Precision=0.4118, Recall=0.4828, F1=0.4444\n",
      "Fold 3: Accuracy=0.6069, Precision=0.2879, Recall=0.6552, F1=0.4000\n",
      "Fold 4: Accuracy=0.7103, Precision=0.3966, Recall=0.7667, F1=0.5227\n",
      "Fold 5: Accuracy=0.6111, Precision=0.2787, Recall=0.5862, F1=0.3778\n",
      "\n",
      "--- Model Summary ---\n",
      "Name                          : BalancedBagging-DecisionTree\n",
      "Description                   : Bagging+Balanced+DT(max_depth=6)+5Fold\n",
      "Accuracy                      : 0.6795\n",
      "Precision                     : 0.3433\n",
      "Recall                        : 0.5947\n",
      "F1 Score                      : 0.4290\n",
      "\n",
      "CSV Row Format:\n",
      "BalancedBagging-DecisionTree,Bagging+Balanced+DT(max_depth=6)+5Fold,0.6795,0.3433,0.5947,0.4290\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Assume df_clean is preloaded\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# Preprocessing (same as your other pipelines)\n",
    "categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "numeric_cols = X.select_dtypes(include=['number']).columns.tolist()\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols),\n",
    "    ('num', StandardScaler(), numeric_cols)\n",
    "])\n",
    "\n",
    "# Classifier setup\n",
    "base_estimator = DecisionTreeClassifier(max_depth=6, random_state=42)\n",
    "clf = BalancedBaggingClassifier(\n",
    "    estimator=base_estimator,\n",
    "    n_estimators=50,\n",
    "    sampling_strategy='auto',\n",
    "    replacement=False,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', clf)\n",
    "])\n",
    "\n",
    "# Cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "accuracy_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_val)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# Aggregate results\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# Model metadata\n",
    "model_name = 'BalancedBagging-DecisionTree'\n",
    "model_desc = 'Bagging+Balanced+DT(max_depth=6)+5Fold'\n",
    "\n",
    "print(\"\\n--- Model Summary ---\")\n",
    "print(f\"{'Name':<30}: {model_name}\")\n",
    "print(f\"{'Description':<30}: {model_desc}\")\n",
    "print(f\"{'Accuracy':<30}: {mean_acc:.4f}\")\n",
    "print(f\"{'Precision':<30}: {mean_prec:.4f}\")\n",
    "print(f\"{'Recall':<30}: {mean_rec:.4f}\")\n",
    "print(f\"{'F1 Score':<30}: {mean_f1:.4f}\")\n",
    "\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# Save results\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "new_row = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "new_row.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d06555",
   "metadata": {},
   "source": [
    "# EasyEnsembleClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3397a732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.6690, Precision=0.3137, Recall=0.5517, F1=0.4000\n",
      "Fold 2: Accuracy=0.7172, Precision=0.3571, Recall=0.5172, F1=0.4225\n",
      "Fold 3: Accuracy=0.5931, Precision=0.2857, Recall=0.6897, F1=0.4040\n",
      "Fold 4: Accuracy=0.6069, Precision=0.3247, Recall=0.8333, F1=0.4673\n",
      "Fold 5: Accuracy=0.5486, Precision=0.2429, Recall=0.5862, F1=0.3434\n",
      "\n",
      "--- Model Summary ---\n",
      "Name                          : EasyEnsembleClassifier\n",
      "Description                   : Ensemble+Undersampling+AdaBoost+5Fold\n",
      "Accuracy                      : 0.6270\n",
      "Precision                     : 0.3048\n",
      "Recall                        : 0.6356\n",
      "F1 Score                      : 0.4075\n",
      "\n",
      "CSV Row Format:\n",
      "EasyEnsembleClassifier,Ensemble+Undersampling+AdaBoost+5Fold,0.6270,0.3048,0.6356,0.4075\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from imblearn.ensemble import EasyEnsembleClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Dataset\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# Feature columns\n",
    "categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "numeric_cols = X.select_dtypes(include=['number']).columns.tolist()\n",
    "\n",
    "# Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols),\n",
    "    ('num', StandardScaler(), numeric_cols)\n",
    "])\n",
    "\n",
    "# Classifier: EasyEnsemble with default AdaBoost base\n",
    "clf = EasyEnsembleClassifier(\n",
    "    n_estimators=10,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Full pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', clf)\n",
    "])\n",
    "\n",
    "# Stratified K-Fold CV\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Metrics\n",
    "accuracy_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_val)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# Aggregate metrics\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# Metadata\n",
    "model_name = 'EasyEnsembleClassifier'\n",
    "model_desc = 'Ensemble+Undersampling+AdaBoost+5Fold'\n",
    "\n",
    "print(\"\\n--- Model Summary ---\")\n",
    "print(f\"{'Name':<30}: {model_name}\")\n",
    "print(f\"{'Description':<30}: {model_desc}\")\n",
    "print(f\"{'Accuracy':<30}: {mean_acc:.4f}\")\n",
    "print(f\"{'Precision':<30}: {mean_prec:.4f}\")\n",
    "print(f\"{'Recall':<30}: {mean_rec:.4f}\")\n",
    "print(f\"{'F1 Score':<30}: {mean_f1:.4f}\")\n",
    "\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# Save to CSV\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "new_row = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "new_row.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1424f5bb",
   "metadata": {},
   "source": [
    "# EasyEnsembleClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f4e7cf45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Threshold=0.40, Accuracy=0.4276, Precision=0.2500, Recall=0.9310, F1=0.3942\n",
      "Fold 2: Threshold=0.50, Accuracy=0.6966, Precision=0.3469, Recall=0.5862, F1=0.4359\n",
      "Fold 3: Threshold=0.50, Accuracy=0.6000, Precision=0.2899, Recall=0.6897, F1=0.4082\n",
      "Fold 4: Threshold=0.50, Accuracy=0.6552, Precision=0.3571, Recall=0.8333, F1=0.5000\n",
      "Fold 5: Threshold=0.50, Accuracy=0.5833, Precision=0.2754, Recall=0.6552, F1=0.3878\n",
      "\n",
      "--- Model Summary ---\n",
      "Name                          : EasyEnsembleClassifier+ThresholdTuning\n",
      "Description                   : EEC-ThresholdTuning-5Fold\n",
      "Accuracy                      : 0.5925\n",
      "Precision                     : 0.3039\n",
      "Recall                        : 0.7391\n",
      "F1 Score                      : 0.4252\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from imblearn.ensemble import EasyEnsembleClassifier\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Target and features\n",
    "current_df = df_clean.copy()  # Ensure `df_clean` is already cleaned\n",
    "X = current_df.drop(columns=['Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# CV setup\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Metric storage\n",
    "accuracy_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "\n",
    "# Initialize EasyEnsembleClassifier\n",
    "base_model = EasyEnsembleClassifier(random_state=42, n_estimators=10)\n",
    "\n",
    "# Preprocessing for categorical and numeric features\n",
    "categorical_features = X.select_dtypes(include=['object']).columns\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Feature selection\n",
    "feature_selector = SelectFromModel(estimator=RandomForestClassifier(random_state=42), max_features=20)\n",
    "\n",
    "# Threshold tuning range\n",
    "thresholds = np.linspace(0.1, 0.5, 5)\n",
    "\n",
    "# Pipeline setup\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('feature_selection', feature_selector),\n",
    "    ('classifier', base_model)\n",
    "])\n",
    "\n",
    "# 5-Fold Evaluation\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_probs = pipeline.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    # Threshold tuning\n",
    "    best_metrics = {'acc': 0, 'prec': 0, 'rec': 0, 'f1': 0, 'threshold': 0}\n",
    "    for thresh in thresholds:\n",
    "        y_pred = (y_probs >= thresh).astype(int)\n",
    "        acc = accuracy_score(y_val, y_pred)\n",
    "        prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "        rec = recall_score(y_val, y_pred)\n",
    "        f1 = f1_score(y_val, y_pred)\n",
    "        \n",
    "        if f1 > best_metrics['f1']:\n",
    "            best_metrics = {'acc': acc, 'prec': prec, 'rec': rec, 'f1': f1, 'threshold': thresh}\n",
    "    \n",
    "    accuracy_list.append(best_metrics['acc'])\n",
    "    precision_list.append(best_metrics['prec'])\n",
    "    recall_list.append(best_metrics['rec'])\n",
    "    f1_list.append(best_metrics['f1'])\n",
    "    \n",
    "    print(f\"Fold {fold}: Threshold={best_metrics['threshold']:.2f}, Accuracy={best_metrics['acc']:.4f}, \"\n",
    "          f\"Precision={best_metrics['prec']:.4f}, Recall={best_metrics['rec']:.4f}, F1={best_metrics['f1']:.4f}\")\n",
    "\n",
    "# Final metrics\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# Model info\n",
    "model_name = 'EasyEnsembleClassifier+ThresholdTuning'\n",
    "model_desc = 'EEC-ThresholdTuning-5Fold'\n",
    "\n",
    "# Print formatted summary\n",
    "print(\"\\n--- Model Summary ---\")\n",
    "print(f\"{'Name':<30}: {model_name}\")\n",
    "print(f\"{'Description':<30}: {model_desc}\")\n",
    "print(f\"{'Accuracy':<30}: {mean_acc:.4f}\")\n",
    "print(f\"{'Precision':<30}: {mean_prec:.4f}\")\n",
    "print(f\"{'Recall':<30}: {mean_rec:.4f}\")\n",
    "print(f\"{'F1 Score':<30}: {mean_f1:.4f}\")\n",
    "\n",
    "# Save to CSV\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "new_row = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "\n",
    "new_row.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fef45b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold=0.10 | Accuracy=0.2017, Precision=0.2017, Recall=1.0000, F1=0.3356\n",
      "Threshold=0.15 | Accuracy=0.2017, Precision=0.2017, Recall=1.0000, F1=0.3356\n",
      "Threshold=0.20 | Accuracy=0.2017, Precision=0.2017, Recall=1.0000, F1=0.3356\n",
      "Threshold=0.25 | Accuracy=0.2030, Precision=0.2019, Recall=1.0000, F1=0.3360\n",
      "Threshold=0.30 | Accuracy=0.2459, Precision=0.2113, Recall=1.0000, F1=0.3488\n",
      "Threshold=0.35 | Accuracy=0.3080, Precision=0.2258, Recall=1.0000, F1=0.3684\n",
      "Threshold=0.40 | Accuracy=0.3522, Precision=0.2349, Recall=0.9793, F1=0.3788\n",
      "Threshold=0.45 | Accuracy=0.4848, Precision=0.2653, Recall=0.8761, F1=0.4067\n",
      "Threshold=0.50 | Accuracy=0.6491, Precision=0.3220, Recall=0.6563, F1=0.4283\n",
      "\n",
      "No threshold met strict criteria. Falling back to best F1 score.\n",
      "\n",
      "--- Best Threshold Tuned Model Summary ---\n",
      "Name                          : EasyEnsemble-Top20Feat+Thresh\n",
      "Description                   : 5Fold-EEC+Top20Selector+ThreshTuned-0.50\n",
      "Accuracy                      : 0.6491\n",
      "Precision                     : 0.3220\n",
      "Recall                        : 0.6563\n",
      "F1 Score                      : 0.4283\n",
      "\n",
      "CSV Row Format:\n",
      "EasyEnsemble-Top20Feat+Thresh,5Fold-EEC+Top20Selector+ThreshTuned-0.50,0.6491,0.3220,0.6563,0.4283\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.ensemble import EasyEnsembleClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- Custom Transformer for Top 20 Features ---\n",
    "class TopFeatureSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, model, k=20):\n",
    "        self.model = model\n",
    "        self.k = k\n",
    "        self.top_indices = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.model.fit(X, y)\n",
    "        if hasattr(self.model, \"feature_importances_\"):\n",
    "            importances = self.model.feature_importances_\n",
    "        else:\n",
    "            raise AttributeError(\"Model must have feature_importances_\")\n",
    "        self.top_indices = np.argsort(importances)[::-1][:self.k]\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[:, self.top_indices]\n",
    "\n",
    "# --- Load data ---\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# --- Identify column types ---\n",
    "categorical_cols = X.select_dtypes(include='object').columns.tolist()\n",
    "numerical_cols = X.select_dtypes(include=np.number).columns.tolist()\n",
    "\n",
    "# --- Preprocessing ---\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# --- Pipeline components ---\n",
    "rf_for_selection = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "top_k_selector = TopFeatureSelector(model=rf_for_selection, k=20)\n",
    "\n",
    "model = EasyEnsembleClassifier(\n",
    "    n_estimators=10,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('selector', top_k_selector),\n",
    "    ('model', model)\n",
    "])\n",
    "\n",
    "# --- CV and threshold tuning ---\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "thresholds = np.arange(0.1, 0.51, 0.05)\n",
    "\n",
    "best_metrics = {'threshold': 0, 'accuracy': 0, 'precision': 0, 'recall': 0, 'f1': 0}\n",
    "\n",
    "# Try all thresholds\n",
    "for threshold in thresholds:\n",
    "    acc_list, prec_list, rec_list, f1_list = [], [], [], []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        y_proba = pipeline.predict_proba(X_val)[:, 1]\n",
    "        y_pred = (y_proba >= threshold).astype(int)\n",
    "\n",
    "        acc = accuracy_score(y_val, y_pred)\n",
    "        prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "        rec = recall_score(y_val, y_pred)\n",
    "        f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "        acc_list.append(acc)\n",
    "        prec_list.append(prec)\n",
    "        rec_list.append(rec)\n",
    "        f1_list.append(f1)\n",
    "\n",
    "    mean_acc = np.mean(acc_list)\n",
    "    mean_prec = np.mean(prec_list)\n",
    "    mean_rec = np.mean(rec_list)\n",
    "    mean_f1 = np.mean(f1_list)\n",
    "\n",
    "    print(f\"Threshold={threshold:.2f} | Accuracy={mean_acc:.4f}, Precision={mean_prec:.4f}, Recall={mean_rec:.4f}, F1={mean_f1:.4f}\")\n",
    "\n",
    "    if (\n",
    "        mean_rec > best_metrics['recall'] and\n",
    "        mean_prec > 0.6 and\n",
    "        mean_f1 > 0.7 and\n",
    "        mean_acc > 0.8\n",
    "    ):\n",
    "        best_metrics.update({\n",
    "            'threshold': threshold,\n",
    "            'accuracy': mean_acc,\n",
    "            'precision': mean_prec,\n",
    "            'recall': mean_rec,\n",
    "            'f1': mean_f1\n",
    "        })\n",
    "\n",
    "# --- Fallback if no threshold met all strict criteria ---\n",
    "if best_metrics['f1'] == 0:\n",
    "    print(\"\\nNo threshold met strict criteria. Falling back to best F1 score.\")\n",
    "    best_f1 = 0\n",
    "    for threshold in thresholds:\n",
    "        acc_list, prec_list, rec_list, f1_list = [], [], [], []\n",
    "\n",
    "        for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "            X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "            pipeline.fit(X_train, y_train)\n",
    "            y_proba = pipeline.predict_proba(X_val)[:, 1]\n",
    "            y_pred = (y_proba >= threshold).astype(int)\n",
    "\n",
    "            acc_list.append(accuracy_score(y_val, y_pred))\n",
    "            prec_list.append(precision_score(y_val, y_pred, zero_division=0))\n",
    "            rec_list.append(recall_score(y_val, y_pred))\n",
    "            f1_list.append(f1_score(y_val, y_pred))\n",
    "\n",
    "        mean_f1 = np.mean(f1_list)\n",
    "        if mean_f1 > best_f1:\n",
    "            best_f1 = mean_f1\n",
    "            best_metrics.update({\n",
    "                'threshold': threshold,\n",
    "                'accuracy': np.mean(acc_list),\n",
    "                'precision': np.mean(prec_list),\n",
    "                'recall': np.mean(rec_list),\n",
    "                'f1': mean_f1\n",
    "            })\n",
    "\n",
    "# --- Reporting ---\n",
    "model_name = 'EasyEnsemble-Top20Feat+Thresh'\n",
    "model_desc = f'5Fold-EEC+Top20Selector+ThreshTuned-{best_metrics[\"threshold\"]:.2f}'\n",
    "\n",
    "print(\"\\n--- Best Threshold Tuned Model Summary ---\")\n",
    "print(f\"{'Name':<30}: {model_name}\")\n",
    "print(f\"{'Description':<30}: {model_desc}\")\n",
    "print(f\"{'Accuracy':<30}: {best_metrics['accuracy']:.4f}\")\n",
    "print(f\"{'Precision':<30}: {best_metrics['precision']:.4f}\")\n",
    "print(f\"{'Recall':<30}: {best_metrics['recall']:.4f}\")\n",
    "print(f\"{'F1 Score':<30}: {best_metrics['f1']:.4f}\")\n",
    "\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{best_metrics['accuracy']:.4f},{best_metrics['precision']:.4f},{best_metrics['recall']:.4f},{best_metrics['f1']:.4f}\")\n",
    "\n",
    "# --- Save results ---\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "new_row = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(best_metrics['accuracy'], 4),\n",
    "    'Precision': round(best_metrics['precision'], 4),\n",
    "    'Recall': round(best_metrics['recall'], 4),\n",
    "    'F1 Score': round(best_metrics['f1'], 4)\n",
    "}])\n",
    "new_row.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca243728",
   "metadata": {},
   "source": [
    "# BalancedBaggingClassifier + LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c1e6dd3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold=0.10 | Accuracy=0.4019, Precision=0.2461, Recall=0.9517, F1=0.3910\n",
      "Threshold=0.15 | Accuracy=0.4557, Precision=0.2591, Recall=0.9039, F1=0.4024\n",
      "Threshold=0.20 | Accuracy=0.4957, Precision=0.2696, Recall=0.8625, F1=0.4099\n",
      "Threshold=0.25 | Accuracy=0.5358, Precision=0.2777, Recall=0.8005, F1=0.4107\n",
      "Threshold=0.30 | Accuracy=0.5634, Precision=0.2841, Recall=0.7593, F1=0.4120\n",
      "Threshold=0.35 | Accuracy=0.5993, Precision=0.2997, Recall=0.7248, F1=0.4213\n",
      "Threshold=0.40 | Accuracy=0.6214, Precision=0.3018, Recall=0.6630, F1=0.4114\n",
      "Threshold=0.45 | Accuracy=0.6491, Precision=0.3142, Recall=0.6218, F1=0.4129\n",
      "Threshold=0.50 | Accuracy=0.6684, Precision=0.3048, Recall=0.5062, F1=0.3758\n",
      "\n",
      "No threshold met strict criteria. Falling back to best F1 score.\n",
      "\n",
      "--- Best Threshold Tuned Model Summary ---\n",
      "Name                          : BalancedBagging-LGBM\n",
      "Description                   : 5Fold-BBC+LGBM-ThresholdTuned-0.35\n",
      "Accuracy                      : 0.5993\n",
      "Precision                     : 0.2997\n",
      "Recall                        : 0.7248\n",
      "F1 Score                      : 0.4213\n",
      "\n",
      "CSV Row Format:\n",
      "BalancedBagging-LGBM,5Fold-BBC+LGBM-ThresholdTuned-0.35,0.5993,0.2997,0.7248,0.4213\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from lightgbm import LGBMClassifier\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- Data setup ---\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# --- Column types ---\n",
    "categorical_cols = X.select_dtypes(include='object').columns.tolist()\n",
    "numerical_cols = X.select_dtypes(include=np.number).columns.tolist()\n",
    "\n",
    "# --- Preprocessing ---\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# --- Classifier setup ---\n",
    "lgbm = LGBMClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.1,\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "bbc = BalancedBaggingClassifier(\n",
    "    estimator=lgbm,\n",
    "    n_estimators=10,\n",
    "    sampling_strategy='auto',\n",
    "    replacement=False,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# --- Full pipeline ---\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', bbc)\n",
    "])\n",
    "\n",
    "# --- Evaluation ---\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "thresholds = np.arange(0.1, 0.51, 0.05)\n",
    "best_metrics = {'threshold': 0, 'accuracy': 0, 'precision': 0, 'recall': 0, 'f1': 0}\n",
    "\n",
    "for threshold in thresholds:\n",
    "    acc_list, prec_list, rec_list, f1_list = [], [], [], []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        y_proba = pipeline.predict_proba(X_val)[:, 1]\n",
    "        y_pred = (y_proba >= threshold).astype(int)\n",
    "\n",
    "        acc_list.append(accuracy_score(y_val, y_pred))\n",
    "        prec_list.append(precision_score(y_val, y_pred, zero_division=0))\n",
    "        rec_list.append(recall_score(y_val, y_pred))\n",
    "        f1_list.append(f1_score(y_val, y_pred))\n",
    "\n",
    "    mean_acc = np.mean(acc_list)\n",
    "    mean_prec = np.mean(prec_list)\n",
    "    mean_rec = np.mean(rec_list)\n",
    "    mean_f1 = np.mean(f1_list)\n",
    "\n",
    "    print(f\"Threshold={threshold:.2f} | Accuracy={mean_acc:.4f}, Precision={mean_prec:.4f}, Recall={mean_rec:.4f}, F1={mean_f1:.4f}\")\n",
    "\n",
    "    if (\n",
    "        mean_rec > best_metrics['recall'] and\n",
    "        mean_prec > 0.6 and\n",
    "        mean_f1 > 0.7 and\n",
    "        mean_acc > 0.8\n",
    "    ):\n",
    "        best_metrics.update({\n",
    "            'threshold': threshold,\n",
    "            'accuracy': mean_acc,\n",
    "            'precision': mean_prec,\n",
    "            'recall': mean_rec,\n",
    "            'f1': mean_f1\n",
    "        })\n",
    "\n",
    "# --- Fallback to best F1 if no strict threshold matched ---\n",
    "if best_metrics['f1'] == 0:\n",
    "    print(\"\\nNo threshold met strict criteria. Falling back to best F1 score.\")\n",
    "    best_f1 = 0\n",
    "    for threshold in thresholds:\n",
    "        acc_list, prec_list, rec_list, f1_list = [], [], [], []\n",
    "\n",
    "        for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "            X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "            pipeline.fit(X_train, y_train)\n",
    "            y_proba = pipeline.predict_proba(X_val)[:, 1]\n",
    "            y_pred = (y_proba >= threshold).astype(int)\n",
    "\n",
    "            acc_list.append(accuracy_score(y_val, y_pred))\n",
    "            prec_list.append(precision_score(y_val, y_pred, zero_division=0))\n",
    "            rec_list.append(recall_score(y_val, y_pred))\n",
    "            f1_list.append(f1_score(y_val, y_pred))\n",
    "\n",
    "        mean_f1 = np.mean(f1_list)\n",
    "        if mean_f1 > best_f1:\n",
    "            best_f1 = mean_f1\n",
    "            best_metrics.update({\n",
    "                'threshold': threshold,\n",
    "                'accuracy': np.mean(acc_list),\n",
    "                'precision': np.mean(prec_list),\n",
    "                'recall': np.mean(rec_list),\n",
    "                'f1': mean_f1\n",
    "            })\n",
    "\n",
    "# --- Reporting ---\n",
    "model_name = 'BalancedBagging-LGBM'\n",
    "model_desc = f'5Fold-BBC+LGBM-ThresholdTuned-{best_metrics[\"threshold\"]:.2f}'\n",
    "\n",
    "print(\"\\n--- Best Threshold Tuned Model Summary ---\")\n",
    "print(f\"{'Name':<30}: {model_name}\")\n",
    "print(f\"{'Description':<30}: {model_desc}\")\n",
    "print(f\"{'Accuracy':<30}: {best_metrics['accuracy']:.4f}\")\n",
    "print(f\"{'Precision':<30}: {best_metrics['precision']:.4f}\")\n",
    "print(f\"{'Recall':<30}: {best_metrics['recall']:.4f}\")\n",
    "print(f\"{'F1 Score':<30}: {best_metrics['f1']:.4f}\")\n",
    "\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{best_metrics['accuracy']:.4f},{best_metrics['precision']:.4f},{best_metrics['recall']:.4f},{best_metrics['f1']:.4f}\")\n",
    "\n",
    "# --- Save to CSV ---\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "new_row = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(best_metrics['accuracy'], 4),\n",
    "    'Precision': round(best_metrics['precision'], 4),\n",
    "    'Recall': round(best_metrics['recall'], 4),\n",
    "    'F1 Score': round(best_metrics['f1'], 4)\n",
    "}])\n",
    "new_row.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79697540",
   "metadata": {},
   "source": [
    "# StackingClassifier with Threshold Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "eb8d4db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold=0.10 | Accuracy=0.4364, Precision=0.2368, Recall=0.8071, F1=0.3655\n",
      "Threshold=0.15 | Accuracy=0.5676, Precision=0.2712, Recall=0.6701, F1=0.3848\n",
      "Threshold=0.20 | Accuracy=0.6532, Precision=0.3174, Recall=0.5949, F1=0.4107\n",
      "Threshold=0.25 | Accuracy=0.6988, Precision=0.3353, Recall=0.4589, F1=0.3843\n",
      "Threshold=0.30 | Accuracy=0.7209, Precision=0.3338, Recall=0.3563, F1=0.3411\n",
      "Threshold=0.35 | Accuracy=0.7320, Precision=0.3234, Recall=0.2883, F1=0.3022\n",
      "Threshold=0.40 | Accuracy=0.7625, Precision=0.3769, Recall=0.2405, F1=0.2896\n",
      "Threshold=0.45 | Accuracy=0.7790, Precision=0.4052, Recall=0.1784, F1=0.2443\n",
      "Threshold=0.50 | Accuracy=0.7901, Precision=0.4481, Recall=0.1237, F1=0.1867\n",
      "\n",
      "No threshold met strict criteria. Falling back to best F1 score.\n",
      "\n",
      "--- Best Threshold Tuned Model Summary ---\n",
      "Name                          : Stacking-CatLGBMSVCBBC\n",
      "Description                   : StackingCatLGBMSVCBBC+LogRegMeta+ThreshTuned-0.20\n",
      "Accuracy                      : 0.6532\n",
      "Precision                     : 0.3174\n",
      "Recall                        : 0.5949\n",
      "F1 Score                      : 0.4107\n",
      "\n",
      "CSV Row Format:\n",
      "Stacking-CatLGBMSVCBBC,StackingCatLGBMSVCBBC+LogRegMeta+ThreshTuned-0.20,0.6532,0.3174,0.5949,0.4107\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.svm import SVC\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- Data prep ---\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "categorical_cols = X.select_dtypes(include='object').columns.tolist()\n",
    "numerical_cols = X.select_dtypes(include=np.number).columns.tolist()\n",
    "\n",
    "# --- Preprocessing ---\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# --- Base models ---\n",
    "cat = CatBoostClassifier(verbose=0, random_state=42)\n",
    "lgbm = LGBMClassifier(n_estimators=100, max_depth=5, learning_rate=0.1, random_state=42)\n",
    "svc = SVC(kernel='rbf', C=1, probability=True, random_state=42)\n",
    "bbc = BalancedBaggingClassifier(\n",
    "    estimator=DecisionTreeClassifier(max_depth=6, random_state=42),\n",
    "    n_estimators=10,\n",
    "    sampling_strategy='auto',\n",
    "    replacement=False,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# --- Meta model ---\n",
    "meta_model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# --- Stacking ---\n",
    "stacking_model = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('cat', cat),\n",
    "        ('lgbm', lgbm),\n",
    "        ('svc', svc),\n",
    "        ('bbc', bbc)\n",
    "    ],\n",
    "    final_estimator=meta_model,\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    passthrough=True\n",
    ")\n",
    "\n",
    "# --- Full pipeline ---\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', stacking_model)\n",
    "])\n",
    "\n",
    "# --- CV + Threshold tuning ---\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "thresholds = np.arange(0.1, 0.51, 0.05)\n",
    "best_metrics = {'threshold': 0, 'accuracy': 0, 'precision': 0, 'recall': 0, 'f1': 0}\n",
    "\n",
    "for threshold in thresholds:\n",
    "    acc_list, prec_list, rec_list, f1_list = [], [], [], []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        y_proba = pipeline.predict_proba(X_val)[:, 1]\n",
    "        y_pred = (y_proba >= threshold).astype(int)\n",
    "\n",
    "        acc_list.append(accuracy_score(y_val, y_pred))\n",
    "        prec_list.append(precision_score(y_val, y_pred, zero_division=0))\n",
    "        rec_list.append(recall_score(y_val, y_pred))\n",
    "        f1_list.append(f1_score(y_val, y_pred))\n",
    "\n",
    "    mean_acc = np.mean(acc_list)\n",
    "    mean_prec = np.mean(prec_list)\n",
    "    mean_rec = np.mean(rec_list)\n",
    "    mean_f1 = np.mean(f1_list)\n",
    "\n",
    "    print(f\"Threshold={threshold:.2f} | Accuracy={mean_acc:.4f}, Precision={mean_prec:.4f}, Recall={mean_rec:.4f}, F1={mean_f1:.4f}\")\n",
    "\n",
    "    if (\n",
    "        mean_rec > best_metrics['recall'] and\n",
    "        mean_prec > 0.6 and\n",
    "        mean_f1 > 0.7 and\n",
    "        mean_acc > 0.8\n",
    "    ):\n",
    "        best_metrics.update({\n",
    "            'threshold': threshold,\n",
    "            'accuracy': mean_acc,\n",
    "            'precision': mean_prec,\n",
    "            'recall': mean_rec,\n",
    "            'f1': mean_f1\n",
    "        })\n",
    "\n",
    "# --- Fallback: best F1 if strict criteria fail ---\n",
    "if best_metrics['f1'] == 0:\n",
    "    print(\"\\nNo threshold met strict criteria. Falling back to best F1 score.\")\n",
    "    best_f1 = 0\n",
    "    for threshold in thresholds:\n",
    "        acc_list, prec_list, rec_list, f1_list = [], [], [], []\n",
    "\n",
    "        for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "            X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "            pipeline.fit(X_train, y_train)\n",
    "            y_proba = pipeline.predict_proba(X_val)[:, 1]\n",
    "            y_pred = (y_proba >= threshold).astype(int)\n",
    "\n",
    "            acc_list.append(accuracy_score(y_val, y_pred))\n",
    "            prec_list.append(precision_score(y_val, y_pred, zero_division=0))\n",
    "            rec_list.append(recall_score(y_val, y_pred))\n",
    "            f1_list.append(f1_score(y_val, y_pred))\n",
    "\n",
    "        mean_f1 = np.mean(f1_list)\n",
    "        if mean_f1 > best_f1:\n",
    "            best_f1 = mean_f1\n",
    "            best_metrics.update({\n",
    "                'threshold': threshold,\n",
    "                'accuracy': np.mean(acc_list),\n",
    "                'precision': np.mean(prec_list),\n",
    "                'recall': np.mean(rec_list),\n",
    "                'f1': mean_f1\n",
    "            })\n",
    "\n",
    "# --- Reporting ---\n",
    "model_name = 'Stacking-CatLGBMSVCBBC'\n",
    "model_desc = f'StackingCatLGBMSVCBBC+LogRegMeta+ThreshTuned-{best_metrics[\"threshold\"]:.2f}'\n",
    "\n",
    "print(\"\\n--- Best Threshold Tuned Model Summary ---\")\n",
    "print(f\"{'Name':<30}: {model_name}\")\n",
    "print(f\"{'Description':<30}: {model_desc}\")\n",
    "print(f\"{'Accuracy':<30}: {best_metrics['accuracy']:.4f}\")\n",
    "print(f\"{'Precision':<30}: {best_metrics['precision']:.4f}\")\n",
    "print(f\"{'Recall':<30}: {best_metrics['recall']:.4f}\")\n",
    "print(f\"{'F1 Score':<30}: {best_metrics['f1']:.4f}\")\n",
    "\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{best_metrics['accuracy']:.4f},{best_metrics['precision']:.4f},{best_metrics['recall']:.4f},{best_metrics['f1']:.4f}\")\n",
    "\n",
    "# --- Save to CSV ---\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "new_row = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(best_metrics['accuracy'], 4),\n",
    "    'Precision': round(best_metrics['precision'], 4),\n",
    "    'Recall': round(best_metrics['recall'], 4),\n",
    "    'F1 Score': round(best_metrics['f1'], 4)\n",
    "}])\n",
    "new_row.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6537e310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.7862, Precision=0.3333, Recall=0.0690, F1=0.1143\n",
      "Fold 2: Accuracy=0.8069, Precision=0.6000, Recall=0.1034, F1=0.1765\n",
      "Fold 3: Accuracy=0.8276, Precision=0.7500, Recall=0.2069, F1=0.3243\n",
      "Fold 4: Accuracy=0.7793, Precision=0.4286, Recall=0.2000, F1=0.2727\n",
      "Fold 5: Accuracy=0.7639, Precision=0.3077, Recall=0.1379, F1=0.1905\n",
      "\n",
      "--- Ensemble Model Summary ---\n",
      "Name                          : ManualSoftVoting-Cat+Ada+SVC\n",
      "Description                   : ManualSoftVoting-Weights[1,2,2]-Thresh0.45\n",
      "Accuracy                      : 0.7928\n",
      "Precision                     : 0.4839\n",
      "Recall                        : 0.1434\n",
      "F1 Score                      : 0.2157\n",
      "\n",
      "CSV Row Format:\n",
      "ManualSoftVoting-Cat+Ada+SVC,ManualSoftVoting-Weights[1,2,2]-Thresh0.45,0.7928,0.4839,0.1434,0.2157\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from catboost import CatBoostClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- Prepare Data ---\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# --- Preprocessing ---\n",
    "categorical_cols = X.select_dtypes(include='object').columns.tolist()\n",
    "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# --- Models ---\n",
    "svc = Pipeline([\n",
    "    ('pre', preprocessor),\n",
    "    ('model', SVC(\n",
    "        kernel='rbf',\n",
    "        C=10, gamma=0.01,\n",
    "        probability=True,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "adaboost = Pipeline([\n",
    "    ('pre', preprocessor),\n",
    "    ('model', AdaBoostClassifier(\n",
    "        n_estimators=150,\n",
    "        learning_rate=0.6,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "catboost = Pipeline([\n",
    "    ('pre', preprocessor),\n",
    "    ('model', CatBoostClassifier(\n",
    "        iterations=250,\n",
    "        learning_rate=0.04,\n",
    "        depth=6,\n",
    "        l2_leaf_reg=3,\n",
    "        verbose=0,\n",
    "        random_seed=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# --- CV Setup ---\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n",
    "\n",
    "# --- Weights & Threshold ---\n",
    "weights = [1, 2, 2]  # svc, adaboost, catboost\n",
    "threshold = 0.45\n",
    "\n",
    "# --- 5-Fold Evaluation ---\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    svc.fit(X_train, y_train)\n",
    "    adaboost.fit(X_train, y_train)\n",
    "    catboost.fit(X_train, y_train)\n",
    "\n",
    "    svc_proba = svc.predict_proba(X_val)[:, 1]\n",
    "    ada_proba = adaboost.predict_proba(X_val)[:, 1]\n",
    "    cat_proba = catboost.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    # Manual soft voting\n",
    "    blended_proba = (\n",
    "        weights[0] * svc_proba +\n",
    "        weights[1] * ada_proba +\n",
    "        weights[2] * cat_proba\n",
    "    ) / sum(weights)\n",
    "\n",
    "    y_pred = (blended_proba >= threshold).astype(int)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# --- Final Metrics ---\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "model_name = 'ManualSoftVoting-Cat+Ada+SVC'\n",
    "model_desc = 'ManualSoftVoting-Weights[1,2,2]-Thresh0.45'\n",
    "\n",
    "print(\"\\n--- Ensemble Model Summary ---\")\n",
    "print(f\"{'Name':<30}: {model_name}\")\n",
    "print(f\"{'Description':<30}: {model_desc}\")\n",
    "print(f\"{'Accuracy':<30}: {mean_acc:.4f}\")\n",
    "print(f\"{'Precision':<30}: {mean_prec:.4f}\")\n",
    "print(f\"{'Recall':<30}: {mean_rec:.4f}\")\n",
    "print(f\"{'F1 Score':<30}: {mean_f1:.4f}\")\n",
    "\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# --- Save to CSV ---\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "new_row = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "new_row.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ee746262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.7793, Precision=0.4118, Recall=0.2414, F1=0.3043\n",
      "Fold 2: Accuracy=0.7862, Precision=0.4000, Recall=0.1379, F1=0.2051\n",
      "Fold 3: Accuracy=0.7931, Precision=0.4800, Recall=0.4138, F1=0.4444\n",
      "Fold 4: Accuracy=0.7310, Precision=0.3200, Recall=0.2667, F1=0.2909\n",
      "Fold 5: Accuracy=0.7292, Precision=0.3438, Recall=0.3793, F1=0.3607\n",
      "\n",
      "--- Ensemble Model Summary ---\n",
      "Name                          : Stacking-XGB+EasyEnsemble\n",
      "Description                   : Base[XGB,Easy],Meta[LogReg],Thresh0.45\n",
      "Accuracy                      : 0.7638\n",
      "Precision                     : 0.3911\n",
      "Recall                        : 0.2878\n",
      "F1 Score                      : 0.3211\n",
      "\n",
      "CSV Row Format:\n",
      "Stacking-XGB+EasyEnsemble,Base[XGB,Easy],Meta[LogReg],Thresh0.45,0.7638,0.3911,0.2878,0.3211\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from imblearn.ensemble import EasyEnsembleClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- Prepare Data ---\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# --- Preprocessing ---\n",
    "categorical_cols = X.select_dtypes(include='object').columns.tolist()\n",
    "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# --- Models ---\n",
    "xgb = Pipeline([\n",
    "    ('pre', preprocessor),\n",
    "    ('model', XGBClassifier(\n",
    "        n_estimators=150,\n",
    "        max_depth=5,\n",
    "        learning_rate=0.08,\n",
    "        subsample=0.85,\n",
    "        colsample_bytree=0.8,\n",
    "        scale_pos_weight=3,  # important for recall\n",
    "        eval_metric='logloss',\n",
    "        use_label_encoder=False,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "easy = Pipeline([\n",
    "    ('pre', preprocessor),\n",
    "    ('model', EasyEnsembleClassifier(\n",
    "        n_estimators=10,\n",
    "        sampling_strategy='auto',\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# --- Meta-Classifier ---\n",
    "meta_clf = LogisticRegression(C=1.0, class_weight='balanced', solver='liblinear', random_state=42)\n",
    "\n",
    "# --- CV Setup ---\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n",
    "threshold = 0.45  # Tune this if needed\n",
    "\n",
    "# --- 5-Fold Manual Stacking ---\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    xgb.fit(X_train, y_train)\n",
    "    easy.fit(X_train, y_train)\n",
    "\n",
    "    xgb_proba = xgb.predict_proba(X_val)[:, 1]\n",
    "    easy_proba = easy.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    # Stack probabilities for meta-classifier\n",
    "    meta_X_train = np.vstack((xgb.predict_proba(X_train)[:, 1], easy.predict_proba(X_train)[:, 1])).T\n",
    "    meta_y_train = y_train\n",
    "\n",
    "    meta_X_val = np.vstack((xgb_proba, easy_proba)).T\n",
    "\n",
    "    meta_clf.fit(meta_X_train, meta_y_train)\n",
    "    meta_proba = meta_clf.predict_proba(meta_X_val)[:, 1]\n",
    "    y_pred = (meta_proba >= threshold).astype(int)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# --- Final Metrics ---\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "model_name = 'Stacking-XGB+EasyEnsemble'\n",
    "model_desc = 'Base[XGB,Easy],Meta[LogReg],Thresh0.45'\n",
    "\n",
    "print(\"\\n--- Ensemble Model Summary ---\")\n",
    "print(f\"{'Name':<30}: {model_name}\")\n",
    "print(f\"{'Description':<30}: {model_desc}\")\n",
    "print(f\"{'Accuracy':<30}: {mean_acc:.4f}\")\n",
    "print(f\"{'Precision':<30}: {mean_prec:.4f}\")\n",
    "print(f\"{'Recall':<30}: {mean_rec:.4f}\")\n",
    "print(f\"{'F1 Score':<30}: {mean_f1:.4f}\")\n",
    "\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# --- Save to CSV ---\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "new_row = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "new_row.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "47291cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Threshold=0.50, Accuracy=0.6690, Precision=0.2979, Recall=0.4828, F1=0.3684\n",
      "Fold 2: Threshold=0.50, Accuracy=0.7310, Precision=0.3684, Recall=0.4828, F1=0.4179\n",
      "Fold 3: Threshold=0.40, Accuracy=0.5448, Precision=0.2771, Recall=0.7931, F1=0.4107\n",
      "Fold 4: Threshold=0.40, Accuracy=0.5517, Precision=0.2989, Recall=0.8667, F1=0.4444\n",
      "Fold 5: Threshold=0.20, Accuracy=0.3611, Precision=0.2261, Recall=0.8966, F1=0.3611\n",
      "\n",
      "--- Model Summary ---\n",
      "Name                          : Stacking-XGB+EEC\n",
      "Description                   : Hybrid-Stacking-XGB-EasyEnsemble-MetaLR\n",
      "Accuracy                      : 0.5715\n",
      "Precision                     : 0.2937\n",
      "Recall                        : 0.7044\n",
      "F1 Score                      : 0.4005\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.ensemble import EasyEnsembleClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- Data prep ---\n",
    "current_df = df_clean.copy()  # Make sure df_clean is defined already\n",
    "X = current_df.drop(columns=['Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# Column types\n",
    "categorical_features = X.select_dtypes(include=['object']).columns.tolist()\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "# Preprocessing\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', StandardScaler(), numeric_features),\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "])\n",
    "\n",
    "# --- Base Learners ---\n",
    "xgb = XGBClassifier(\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss',\n",
    "    scale_pos_weight=(y == 0).sum() / (y == 1).sum(),\n",
    "    max_depth=4,\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=100,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "eec = EasyEnsembleClassifier(\n",
    "    n_estimators=10,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# --- Meta Learner ---\n",
    "meta_clf = LogisticRegression(C=1.0, class_weight='balanced', random_state=42)\n",
    "\n",
    "# --- Stacking Classifier ---\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('xgb', xgb),\n",
    "        ('eec', eec)\n",
    "    ],\n",
    "    final_estimator=meta_clf,\n",
    "    passthrough=True,\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# --- Final Pipeline ---\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', stacking_clf)\n",
    "])\n",
    "\n",
    "# --- Thresholds and Metrics ---\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "thresholds = np.linspace(0.1, 0.5, 5)\n",
    "\n",
    "accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_probs = pipeline.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    best_metrics = {'acc': 0, 'prec': 0, 'rec': 0, 'f1': 0, 'threshold': 0}\n",
    "    for thresh in thresholds:\n",
    "        y_pred = (y_probs >= thresh).astype(int)\n",
    "        acc = accuracy_score(y_val, y_pred)\n",
    "        prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "        rec = recall_score(y_val, y_pred)\n",
    "        f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "        if f1 > best_metrics['f1']:\n",
    "            best_metrics = {'acc': acc, 'prec': prec, 'rec': rec, 'f1': f1, 'threshold': thresh}\n",
    "\n",
    "    accuracy_list.append(best_metrics['acc'])\n",
    "    precision_list.append(best_metrics['prec'])\n",
    "    recall_list.append(best_metrics['rec'])\n",
    "    f1_list.append(best_metrics['f1'])\n",
    "\n",
    "    print(f\"Fold {fold}: Threshold={best_metrics['threshold']:.2f}, \"\n",
    "          f\"Accuracy={best_metrics['acc']:.4f}, Precision={best_metrics['prec']:.4f}, \"\n",
    "          f\"Recall={best_metrics['rec']:.4f}, F1={best_metrics['f1']:.4f}\")\n",
    "\n",
    "# --- Summary ---\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "model_name = 'Stacking-XGB+EEC'\n",
    "model_desc = 'Hybrid-Stacking-XGB-EasyEnsemble-MetaLR'\n",
    "\n",
    "print(\"\\n--- Model Summary ---\")\n",
    "print(f\"{'Name':<30}: {model_name}\")\n",
    "print(f\"{'Description':<30}: {model_desc}\")\n",
    "print(f\"{'Accuracy':<30}: {mean_acc:.4f}\")\n",
    "print(f\"{'Precision':<30}: {mean_prec:.4f}\")\n",
    "print(f\"{'Recall':<30}: {mean_rec:.4f}\")\n",
    "print(f\"{'F1 Score':<30}: {mean_f1:.4f}\")\n",
    "\n",
    "# Save to CSV\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "new_row = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "new_row.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e463b381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Threshold=0.50, Accuracy=0.6690, Precision=0.2979, Recall=0.4828, F1=0.3684\n",
      "Fold 2: Threshold=0.50, Accuracy=0.7310, Precision=0.3684, Recall=0.4828, F1=0.4179\n",
      "Fold 3: Threshold=0.40, Accuracy=0.5448, Precision=0.2771, Recall=0.7931, F1=0.4107\n",
      "Fold 4: Threshold=0.40, Accuracy=0.5517, Precision=0.2989, Recall=0.8667, F1=0.4444\n",
      "Fold 5: Threshold=0.20, Accuracy=0.3611, Precision=0.2261, Recall=0.8966, F1=0.3611\n",
      "\n",
      "--- Model Summary ---\n",
      "Name                          : Stacking-XGB+EEC\n",
      "Description                   : Hybrid-Stacking-XGB-EasyEnsemble-MetaLR\n",
      "Accuracy                      : 0.5715\n",
      "Precision                     : 0.2937\n",
      "Recall                        : 0.7044\n",
      "F1 Score                      : 0.4005\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.ensemble import EasyEnsembleClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- Data prep ---\n",
    "current_df = df_clean.copy()  # Make sure df_clean is defined already\n",
    "X = current_df.drop(columns=['Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# Column types\n",
    "categorical_features = X.select_dtypes(include=['object']).columns.tolist()\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "# Preprocessing\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', StandardScaler(), numeric_features),\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "])\n",
    "\n",
    "# --- Base Learners ---\n",
    "xgb = XGBClassifier(\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss',\n",
    "    scale_pos_weight=(y == 0).sum() / (y == 1).sum(),\n",
    "    max_depth=4,\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=100,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "eec = EasyEnsembleClassifier(\n",
    "    n_estimators=10,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# --- Meta Learner ---\n",
    "meta_clf = LogisticRegression(C=1.0, class_weight='balanced', random_state=42)\n",
    "\n",
    "# --- Stacking Classifier ---\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('xgb', xgb),\n",
    "        ('eec', eec)\n",
    "    ],\n",
    "    final_estimator=meta_clf,\n",
    "    passthrough=True,\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# --- Final Pipeline ---\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', stacking_clf)\n",
    "])\n",
    "\n",
    "# --- Thresholds and Metrics ---\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "thresholds = np.linspace(0.1, 0.5, 5)\n",
    "\n",
    "accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_probs = pipeline.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    best_metrics = {'acc': 0, 'prec': 0, 'rec': 0, 'f1': 0, 'threshold': 0}\n",
    "    for thresh in thresholds:\n",
    "        y_pred = (y_probs >= thresh).astype(int)\n",
    "        acc = accuracy_score(y_val, y_pred)\n",
    "        prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "        rec = recall_score(y_val, y_pred)\n",
    "        f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "        if f1 > best_metrics['f1']:\n",
    "            best_metrics = {'acc': acc, 'prec': prec, 'rec': rec, 'f1': f1, 'threshold': thresh}\n",
    "\n",
    "    accuracy_list.append(best_metrics['acc'])\n",
    "    precision_list.append(best_metrics['prec'])\n",
    "    recall_list.append(best_metrics['rec'])\n",
    "    f1_list.append(best_metrics['f1'])\n",
    "\n",
    "    print(f\"Fold {fold}: Threshold={best_metrics['threshold']:.2f}, \"\n",
    "          f\"Accuracy={best_metrics['acc']:.4f}, Precision={best_metrics['prec']:.4f}, \"\n",
    "          f\"Recall={best_metrics['rec']:.4f}, F1={best_metrics['f1']:.4f}\")\n",
    "\n",
    "# --- Summary ---\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "model_name = 'Stacking-XGB+EEC'\n",
    "model_desc = 'Hybrid-Stacking-XGB-EasyEnsemble-MetaLR'\n",
    "\n",
    "print(\"\\n--- Model Summary ---\")\n",
    "print(f\"{'Name':<30}: {model_name}\")\n",
    "print(f\"{'Description':<30}: {model_desc}\")\n",
    "print(f\"{'Accuracy':<30}: {mean_acc:.4f}\")\n",
    "print(f\"{'Precision':<30}: {mean_prec:.4f}\")\n",
    "print(f\"{'Recall':<30}: {mean_rec:.4f}\")\n",
    "print(f\"{'F1 Score':<30}: {mean_f1:.4f}\")\n",
    "\n",
    "# Save to CSV\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "new_row = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "new_row.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "28521274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.6621, Precision=0.2826, Recall=0.4483, F1=0.3467\n",
      "Fold 2: Accuracy=0.7310, Precision=0.3684, Recall=0.4828, F1=0.4179\n",
      "Fold 3: Accuracy=0.6207, Precision=0.2903, Recall=0.6207, F1=0.3956\n",
      "Fold 4: Accuracy=0.6207, Precision=0.2951, Recall=0.6000, F1=0.3956\n",
      "Fold 5: Accuracy=0.5556, Precision=0.2222, Recall=0.4828, F1=0.3043\n",
      "\n",
      "--- Ensemble Model Summary ---\n",
      "Name                          : Stacking-CatBoost+LGBM+SVC\n",
      "Description                   : BayesTuned Base, Logistic Meta, 5Fold Stratified\n",
      "Accuracy                      : 0.6380\n",
      "Precision                     : 0.2917\n",
      "Recall                        : 0.5269\n",
      "F1 Score                      : 0.3720\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ------------------ Data Setup ------------------\n",
    "X = df_clean.drop(columns=['Risk Flag', 'Predicted Risk Flag'])\n",
    "y = df_clean['Risk Flag'].astype(int)\n",
    "\n",
    "# ------------------ Class Weights for CatBoost ------------------\n",
    "class_weights_array = compute_class_weight(class_weight='balanced', classes=np.unique(y), y=y)\n",
    "catboost_weights = {int(cls): weight for cls, weight in zip(np.unique(y), class_weights_array)}\n",
    "\n",
    "# ------------------ Preprocessor ------------------\n",
    "cat_cols = X.select_dtypes(include='object').columns.tolist()\n",
    "num_cols = X.select_dtypes(include=np.number).columns.tolist()\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n",
    "    (\"num\", StandardScaler(), num_cols)\n",
    "])\n",
    "\n",
    "# ------------------ Base Estimators + BayesSearchCV ------------------\n",
    "\n",
    "# CatBoost\n",
    "catboost = CatBoostClassifier(verbose=0, class_weights=catboost_weights)\n",
    "catboost_search = BayesSearchCV(\n",
    "    catboost,\n",
    "    search_spaces={\n",
    "        'depth': Integer(3, 8),\n",
    "        'learning_rate': Real(0.01, 0.3, prior='log-uniform'),\n",
    "        'iterations': Integer(100, 300)\n",
    "    },\n",
    "    n_iter=10,\n",
    "    cv=3,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# LightGBM\n",
    "lgbm = LGBMClassifier(class_weight='balanced')\n",
    "lgbm_search = BayesSearchCV(\n",
    "    lgbm,\n",
    "    search_spaces={\n",
    "        'num_leaves': Integer(20, 60),\n",
    "        'learning_rate': Real(0.01, 0.3, prior='log-uniform'),\n",
    "        'n_estimators': Integer(100, 300)\n",
    "    },\n",
    "    n_iter=10,\n",
    "    cv=3,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# RBF-SVC\n",
    "svc = SVC(probability=True, kernel='rbf', class_weight='balanced')\n",
    "svc_search = BayesSearchCV(\n",
    "    svc,\n",
    "    search_spaces={\n",
    "        'C': Real(0.1, 100, prior='log-uniform'),\n",
    "        'gamma': Real(1e-4, 1e-1, prior='log-uniform')\n",
    "    },\n",
    "    n_iter=10,\n",
    "    cv=3,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# ------------------ Stacking Classifier ------------------\n",
    "\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('catboost', catboost_search),\n",
    "        ('lgbm', lgbm_search),\n",
    "        ('svc', svc_search)\n",
    "    ],\n",
    "    final_estimator=LogisticRegression(class_weight='balanced'),\n",
    "    passthrough=True,\n",
    "    cv=3,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Full pipeline\n",
    "model = Pipeline([\n",
    "    (\"pre\", preprocessor),\n",
    "    (\"stack\", stacking_clf)\n",
    "])\n",
    "\n",
    "# ------------------ CV Evaluation ------------------\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# ------------------ Final Metrics ------------------\n",
    "\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "model_name = 'Stacking-CatBoost+LGBM+SVC'\n",
    "model_desc = 'BayesTuned Base, Logistic Meta, 5Fold Stratified'\n",
    "\n",
    "print(\"\\n--- Ensemble Model Summary ---\")\n",
    "print(f\"{'Name':<30}: {model_name}\")\n",
    "print(f\"{'Description':<30}: {model_desc}\")\n",
    "print(f\"{'Accuracy':<30}: {mean_acc:.4f}\")\n",
    "print(f\"{'Precision':<30}: {mean_prec:.4f}\")\n",
    "print(f\"{'Recall':<30}: {mean_rec:.4f}\")\n",
    "print(f\"{'F1 Score':<30}: {mean_f1:.4f}\")\n",
    "\n",
    "# Save to CSV\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "new_row = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "new_row.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1d9dfce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.6828, Precision=0.2927, Recall=0.4138, F1=0.3429\n",
      "Fold 2: Accuracy=0.7655, Precision=0.4194, Recall=0.4483, F1=0.4333\n",
      "Fold 3: Accuracy=0.7034, Precision=0.3654, Recall=0.6552, F1=0.4691\n",
      "Fold 4: Accuracy=0.7379, Precision=0.4259, Recall=0.7667, F1=0.5476\n",
      "Fold 5: Accuracy=0.6528, Precision=0.2766, Recall=0.4483, F1=0.3421\n",
      "\n",
      "--- Model Summary ---\n",
      "Name                          : EasyEnsembleClassifier\n",
      "Description                   : DropLowVar+DropHighVIF+Ensemble+Undersample+5Fold\n",
      "Accuracy                      : 0.7085\n",
      "Precision                     : 0.3560\n",
      "Recall                        : 0.5464\n",
      "F1 Score                      : 0.4270\n",
      "\n",
      "CSV Row Format:\n",
      "EasyEnsembleClassifier,DropLowVar+DropHighVIF+Ensemble+Undersample+5Fold,0.7085,0.3560,0.5464,0.4270\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from imblearn.ensemble import EasyEnsembleClassifier\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ========== Dataset ==========\n",
    "# Copy clean DataFrame\n",
    "current_df = df_clean.copy()\n",
    "\n",
    "# Separate features and target\n",
    "X = current_df.drop(columns=['Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# Identify column types\n",
    "categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "numeric_cols = X.select_dtypes(include=['number']).columns.tolist()\n",
    "\n",
    "# ========== Feature Selection ==========\n",
    "\n",
    "# Step 1: Drop low-variance numeric features\n",
    "selector = VarianceThreshold(threshold=0.01)\n",
    "X_numeric = X[numeric_cols]\n",
    "X_var = selector.fit_transform(X_numeric)\n",
    "kept_low_var_cols = X_numeric.columns[selector.get_support()].tolist()\n",
    "\n",
    "# Step 2: Drop high-VIF features (threshold > 10)\n",
    "def calculate_vif(df):\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data[\"feature\"] = df.columns\n",
    "    vif_data[\"VIF\"] = [variance_inflation_factor(df.values, i) for i in range(df.shape[1])]\n",
    "    return vif_data\n",
    "\n",
    "X_vif = X[kept_low_var_cols].copy()\n",
    "while True:\n",
    "    vif = calculate_vif(X_vif)\n",
    "    max_vif = vif['VIF'].max()\n",
    "    if max_vif > 10:\n",
    "        drop_feat = vif.sort_values('VIF', ascending=False).iloc[0]['feature']\n",
    "        X_vif.drop(columns=[drop_feat], inplace=True)\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# Final selected numeric columns\n",
    "selected_numeric_cols = X_vif.columns.tolist()\n",
    "\n",
    "# Keep only selected features for modeling\n",
    "X = pd.concat([X[selected_numeric_cols], X[categorical_cols]], axis=1)\n",
    "\n",
    "# ========== Preprocessing Pipeline ==========\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols),\n",
    "    ('num', StandardScaler(), selected_numeric_cols)\n",
    "])\n",
    "\n",
    "# Classifier\n",
    "clf = EasyEnsembleClassifier(\n",
    "    n_estimators=10,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Full pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', clf)\n",
    "])\n",
    "\n",
    "# ========== Cross-Validation ==========\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "accuracy_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_val)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# ========== Aggregate Metrics ==========\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# Metadata\n",
    "model_name = 'EasyEnsembleClassifier'\n",
    "model_desc = 'DropLowVar+DropHighVIF+Ensemble+Undersample+5Fold'\n",
    "\n",
    "print(\"\\n--- Model Summary ---\")\n",
    "print(f\"{'Name':<30}: {model_name}\")\n",
    "print(f\"{'Description':<30}: {model_desc}\")\n",
    "print(f\"{'Accuracy':<30}: {mean_acc:.4f}\")\n",
    "print(f\"{'Precision':<30}: {mean_prec:.4f}\")\n",
    "print(f\"{'Recall':<30}: {mean_rec:.4f}\")\n",
    "print(f\"{'F1 Score':<30}: {mean_f1:.4f}\")\n",
    "\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# ========== Save to CSV ==========\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "new_row = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "new_row.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e76a0b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy=0.6828, Precision=0.2927, Recall=0.4138, F1=0.3429\n",
      "Fold 2: Accuracy=0.7724, Precision=0.4333, Recall=0.4483, F1=0.4407\n",
      "Fold 3: Accuracy=0.7103, Precision=0.3725, Recall=0.6552, F1=0.4750\n",
      "Fold 4: Accuracy=0.7310, Precision=0.4118, Recall=0.7000, F1=0.5185\n",
      "Fold 5: Accuracy=0.6667, Precision=0.2889, Recall=0.4483, F1=0.3514\n",
      "\n",
      "--- Model Summary ---\n",
      "Name                          : EasyEnsembleClassifier\n",
      "Description                   : LowVar+HighVIF+MI(top25)+5Fold\n",
      "Accuracy                      : 0.7126\n",
      "Precision                     : 0.3598\n",
      "Recall                        : 0.5331\n",
      "F1 Score                      : 0.4257\n",
      "\n",
      "CSV Row Format:\n",
      "EasyEnsembleClassifier,LowVar+HighVIF+MI(top25)+5Fold,0.7126,0.3598,0.5331,0.4257\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import VarianceThreshold, mutual_info_classif\n",
    "from imblearn.ensemble import EasyEnsembleClassifier\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ========== Dataset ==========\n",
    "# Copy clean DataFrame\n",
    "current_df = df_clean.copy()\n",
    "\n",
    "# Separate features and target\n",
    "X = current_df.drop(columns=['Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# Identify column types\n",
    "categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "numeric_cols = X.select_dtypes(include=['number']).columns.tolist()\n",
    "\n",
    "# ========== Step 1: Drop low-variance + high-VIF ==========\n",
    "\n",
    "# Drop low-variance numeric features\n",
    "selector = VarianceThreshold(threshold=0.01)\n",
    "X_numeric = X[numeric_cols]\n",
    "X_var = selector.fit_transform(X_numeric)\n",
    "kept_low_var_cols = X_numeric.columns[selector.get_support()].tolist()\n",
    "\n",
    "# Drop high-VIF features\n",
    "def calculate_vif(df):\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data[\"feature\"] = df.columns\n",
    "    vif_data[\"VIF\"] = [variance_inflation_factor(df.values, i) for i in range(df.shape[1])]\n",
    "    return vif_data\n",
    "\n",
    "X_vif = X[kept_low_var_cols].copy()\n",
    "while True:\n",
    "    vif = calculate_vif(X_vif)\n",
    "    max_vif = vif['VIF'].max()\n",
    "    if max_vif > 10:\n",
    "        drop_feat = vif.sort_values('VIF', ascending=False).iloc[0]['feature']\n",
    "        X_vif.drop(columns=[drop_feat], inplace=True)\n",
    "    else:\n",
    "        break\n",
    "\n",
    "selected_numeric_cols = X_vif.columns.tolist()\n",
    "\n",
    "# ========== Step 2: Select top 25 features using mutual_info_classif ==========\n",
    "\n",
    "# Temporarily preprocess categorical features\n",
    "ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "X_cat_encoded = pd.DataFrame(\n",
    "    ohe.fit_transform(X[categorical_cols]),\n",
    "    columns=ohe.get_feature_names_out(categorical_cols),\n",
    "    index=X.index\n",
    ")\n",
    "\n",
    "# Combine selected numeric and encoded categorical\n",
    "X_combined = pd.concat([X[selected_numeric_cols], X_cat_encoded], axis=1)\n",
    "\n",
    "# Compute mutual info\n",
    "mi_scores = mutual_info_classif(X_combined, y, random_state=42)\n",
    "mi_series = pd.Series(mi_scores, index=X_combined.columns)\n",
    "top_25_features = mi_series.sort_values(ascending=False).head(25).index.tolist()\n",
    "\n",
    "# Final selected feature set\n",
    "X_final = X_combined[top_25_features]\n",
    "\n",
    "# Identify final selected numeric and one-hot features\n",
    "final_numeric = [col for col in top_25_features if col in selected_numeric_cols]\n",
    "final_onehot = [col for col in top_25_features if col not in selected_numeric_cols]\n",
    "\n",
    "# ========== Preprocessing Pipeline ==========\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', StandardScaler(), final_numeric)\n",
    "], remainder='drop')\n",
    "\n",
    "# Custom passthrough transformer for selected OHE columns\n",
    "class SelectOHEColumns(TransformerMixin):\n",
    "    def __init__(self, ohe_df, selected_cols):\n",
    "        self.ohe_df = ohe_df\n",
    "        self.selected_cols = selected_cols\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return self.ohe_df.loc[X.index, self.selected_cols].values\n",
    "\n",
    "# Combined transformer\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "final_transformer = FeatureUnion([\n",
    "    (\"numeric\", Pipeline([\n",
    "        (\"select\", 'passthrough'),\n",
    "        (\"scale\", StandardScaler())\n",
    "    ])),\n",
    "    (\"onehot\", SelectOHEColumns(X_cat_encoded, final_onehot))\n",
    "])\n",
    "\n",
    "# ========== Modeling ==========\n",
    "clf = EasyEnsembleClassifier(n_estimators=10, random_state=42, n_jobs=-1)\n",
    "pipeline = Pipeline([\n",
    "    ('features', final_transformer),\n",
    "    ('classifier', clf)\n",
    "])\n",
    "\n",
    "# ========== Cross-Validation ==========\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "accuracy_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X_final, y), 1):\n",
    "    X_train, X_val = X_final.iloc[train_idx], X_final.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_val)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# ========== Aggregate Metrics ==========\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "\n",
    "# Metadata\n",
    "model_name = 'EasyEnsembleClassifier'\n",
    "model_desc = 'LowVar+HighVIF+MI(top25)+5Fold'\n",
    "\n",
    "print(\"\\n--- Model Summary ---\")\n",
    "print(f\"{'Name':<30}: {model_name}\")\n",
    "print(f\"{'Description':<30}: {model_desc}\")\n",
    "print(f\"{'Accuracy':<30}: {mean_acc:.4f}\")\n",
    "print(f\"{'Precision':<30}: {mean_prec:.4f}\")\n",
    "print(f\"{'Recall':<30}: {mean_rec:.4f}\")\n",
    "print(f\"{'F1 Score':<30}: {mean_f1:.4f}\")\n",
    "\n",
    "print(\"\\nCSV Row Format:\")\n",
    "print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "# ========== Save to CSV ==========\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "new_row = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4)\n",
    "}])\n",
    "new_row.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a69b4bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== EasyEnsembleClassifier ====\n",
      "Fold 1: Acc=0.6828, Prec=0.2927, Rec=0.4138, F1=0.3429\n",
      "Fold 2: Acc=0.7724, Prec=0.4333, Rec=0.4483, F1=0.4407\n",
      "Fold 3: Acc=0.7103, Prec=0.3725, Rec=0.6552, F1=0.4750\n",
      "Fold 4: Acc=0.7310, Prec=0.4118, Rec=0.7000, F1=0.5185\n",
      "Fold 5: Acc=0.6667, Prec=0.2889, Rec=0.4483, F1=0.3514\n",
      "--- Aggregate ---\n",
      "Accuracy:  0.7126\n",
      "Precision: 0.3598\n",
      "Recall:    0.5331\n",
      "F1 Score:  0.4257\n",
      "\n",
      "CSV Row Format:\n",
      "EasyEnsembleClassifier,LowVar+HighVIF+MI(top25)+5Fold,0.7126,0.3598,0.5331,0.4257\n",
      "\n",
      "==== BalancedBaggingClassifier_LGBM ====\n",
      "Fold 1: Acc=0.6483, Prec=0.2500, Rec=0.3793, F1=0.3014\n",
      "Fold 2: Acc=0.7103, Prec=0.3333, Rec=0.4483, F1=0.3824\n",
      "Fold 3: Acc=0.7103, Prec=0.3774, Rec=0.6897, F1=0.4878\n",
      "Fold 4: Acc=0.6690, Prec=0.3500, Rec=0.7000, F1=0.4667\n",
      "Fold 5: Acc=0.6181, Prec=0.2679, Rec=0.5172, F1=0.3529\n",
      "--- Aggregate ---\n",
      "Accuracy:  0.6712\n",
      "Precision: 0.3157\n",
      "Recall:    0.5469\n",
      "F1 Score:  0.3982\n",
      "\n",
      "CSV Row Format:\n",
      "BalancedBaggingClassifier_LGBM,LowVar+HighVIF+MI(top25)+5Fold,0.6712,0.3157,0.5469,0.3982\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_selection import VarianceThreshold, mutual_info_classif\n",
    "from imblearn.ensemble import EasyEnsembleClassifier, BalancedBaggingClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ========== Dataset ==========\n",
    "df = df_clean.copy()\n",
    "X = df.drop(columns=['Risk Flag', 'Predicted Risk Flag'])\n",
    "y = df['Risk Flag'].astype(int)\n",
    "\n",
    "categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "numeric_cols = X.select_dtypes(include=['number']).columns.tolist()\n",
    "\n",
    "# ========== Step 1: Drop Low-Variance + High-VIF ==========\n",
    "selector = VarianceThreshold(threshold=0.01)\n",
    "X_numeric = X[numeric_cols]\n",
    "X_var = selector.fit_transform(X_numeric)\n",
    "kept_low_var_cols = X_numeric.columns[selector.get_support()].tolist()\n",
    "\n",
    "def calculate_vif(df):\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data[\"feature\"] = df.columns\n",
    "    vif_data[\"VIF\"] = [variance_inflation_factor(df.values, i) for i in range(df.shape[1])]\n",
    "    return vif_data\n",
    "\n",
    "X_vif = X[kept_low_var_cols].copy()\n",
    "while True:\n",
    "    vif = calculate_vif(X_vif)\n",
    "    if vif['VIF'].max() > 10:\n",
    "        to_drop = vif.sort_values('VIF', ascending=False).iloc[0]['feature']\n",
    "        X_vif.drop(columns=[to_drop], inplace=True)\n",
    "    else:\n",
    "        break\n",
    "\n",
    "selected_numeric_cols = X_vif.columns.tolist()\n",
    "\n",
    "# ========== Step 2: Top 25 via mutual_info_classif ==========\n",
    "ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "X_cat_encoded = pd.DataFrame(\n",
    "    ohe.fit_transform(X[categorical_cols]),\n",
    "    columns=ohe.get_feature_names_out(categorical_cols),\n",
    "    index=X.index\n",
    ")\n",
    "\n",
    "X_combined = pd.concat([X[selected_numeric_cols], X_cat_encoded], axis=1)\n",
    "\n",
    "mi_scores = mutual_info_classif(X_combined, y, random_state=42)\n",
    "mi_series = pd.Series(mi_scores, index=X_combined.columns)\n",
    "top_25_features = mi_series.sort_values(ascending=False).head(25).index.tolist()\n",
    "\n",
    "X_final = X_combined[top_25_features]\n",
    "final_numeric = [col for col in top_25_features if col in selected_numeric_cols]\n",
    "final_onehot = [col for col in top_25_features if col not in selected_numeric_cols]\n",
    "\n",
    "# ========== Transformer for Categorical Columns ==========\n",
    "class SelectOHEColumns(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, encoded_df, selected_cols):\n",
    "        self.encoded_df = encoded_df\n",
    "        self.selected_cols = selected_cols\n",
    "    def fit(self, X, y=None): return self\n",
    "    def transform(self, X): return self.encoded_df.loc[X.index, self.selected_cols].values\n",
    "\n",
    "# ========== Feature Union ==========\n",
    "final_transformer = FeatureUnion([\n",
    "    (\"numeric\", Pipeline([\n",
    "        (\"scale\", StandardScaler())\n",
    "    ])),\n",
    "    (\"onehot\", SelectOHEColumns(X_cat_encoded, final_onehot))\n",
    "])\n",
    "\n",
    "# ========== Models ==========\n",
    "models = {\n",
    "    'EasyEnsembleClassifier': EasyEnsembleClassifier(\n",
    "        n_estimators=10,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    'BalancedBaggingClassifier_LGBM': BalancedBaggingClassifier(\n",
    "        estimator=LGBMClassifier(\n",
    "            n_estimators=100,\n",
    "            learning_rate=0.05,\n",
    "            class_weight='balanced',\n",
    "            random_state=42\n",
    "        ),\n",
    "        n_estimators=10,\n",
    "        sampling_strategy='auto',\n",
    "        replacement=False,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "}\n",
    "\n",
    "# ========== Cross-Validation + Logging ==========\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "rows = []\n",
    "\n",
    "for model_name, clf in models.items():\n",
    "    print(f\"\\n==== {model_name} ====\")\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('features', final_transformer),\n",
    "        ('clf', clf)\n",
    "    ])\n",
    "\n",
    "    acc_list, prec_list, rec_list, f1_list = [], [], [], []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(cv.split(X_final, y), 1):\n",
    "        X_train, X_val = X_final.iloc[train_idx], X_final.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        y_pred = pipeline.predict(X_val)\n",
    "\n",
    "        acc = accuracy_score(y_val, y_pred)\n",
    "        prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "        rec = recall_score(y_val, y_pred)\n",
    "        f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "        acc_list.append(acc)\n",
    "        prec_list.append(prec)\n",
    "        rec_list.append(rec)\n",
    "        f1_list.append(f1)\n",
    "\n",
    "        print(f\"Fold {fold}: Acc={acc:.4f}, Prec={prec:.4f}, Rec={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "    mean_acc = np.mean(acc_list)\n",
    "    mean_prec = np.mean(prec_list)\n",
    "    mean_rec = np.mean(rec_list)\n",
    "    mean_f1 = np.mean(f1_list)\n",
    "\n",
    "    print(\"--- Aggregate ---\")\n",
    "    print(f\"Accuracy:  {mean_acc:.4f}\")\n",
    "    print(f\"Precision: {mean_prec:.4f}\")\n",
    "    print(f\"Recall:    {mean_rec:.4f}\")\n",
    "    print(f\"F1 Score:  {mean_f1:.4f}\")\n",
    "\n",
    "    model_desc = 'LowVar+HighVIF+MI(top25)+5Fold'\n",
    "    print(\"\\nCSV Row Format:\")\n",
    "    print(f\"{model_name},{model_desc},{mean_acc:.4f},{mean_prec:.4f},{mean_rec:.4f},{mean_f1:.4f}\")\n",
    "\n",
    "    rows.append({\n",
    "        'Name': model_name,\n",
    "        'Desc': model_desc,\n",
    "        'Accuracy': round(mean_acc, 4),\n",
    "        'Precision': round(mean_prec, 4),\n",
    "        'Recall': round(mean_rec, 4),\n",
    "        'F1 Score': round(mean_f1, 4)\n",
    "    })\n",
    "\n",
    "# ========== Save All Results ==========\n",
    "df_result = pd.DataFrame(rows)\n",
    "df_result.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76908192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Best Threshold=0.40, Acc=0.4276, Prec=0.2500, Rec=0.9310, F1=0.3942\n",
      "Fold 2: Best Threshold=0.50, Acc=0.6966, Prec=0.3469, Rec=0.5862, F1=0.4359\n",
      "Fold 3: Best Threshold=0.50, Acc=0.6000, Prec=0.2899, Rec=0.6897, F1=0.4082\n",
      "Fold 4: Best Threshold=0.50, Acc=0.6552, Prec=0.3571, Rec=0.8333, F1=0.5000\n",
      "Fold 5: Best Threshold=0.50, Acc=0.5833, Prec=0.2754, Rec=0.6552, F1=0.3878\n",
      "\n",
      "--- Model Summary ---\n",
      "Name                          : EasyEnsembleClassifier+ThresholdTuning\n",
      "Description                   : EEC-ThresholdTuning-5Fold\n",
      "Avg Accuracy                  : 0.5925\n",
      "Avg Precision                 : 0.3039\n",
      "Avg Recall                    : 0.7391\n",
      "Avg F1 Score                  : 0.4252\n",
      "Avg Best Threshold            : 0.48\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from imblearn.ensemble import EasyEnsembleClassifier\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ========== Input ==========\n",
    "current_df = df_clean.copy()  # Assumes cleaned DataFrame already exists\n",
    "X = current_df.drop(columns=['Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# ========== CV Setup ==========\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "thresholds = np.linspace(0.1, 0.5, 5)\n",
    "\n",
    "# ========== Preprocessing ==========\n",
    "categorical_features = X.select_dtypes(include=['object']).columns\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# ========== Model Components ==========\n",
    "feature_selector = SelectFromModel(estimator=RandomForestClassifier(random_state=42), max_features=20)\n",
    "base_model = EasyEnsembleClassifier(random_state=42, n_estimators=10)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('feature_selection', feature_selector),\n",
    "    ('classifier', base_model)\n",
    "])\n",
    "\n",
    "# ========== Metrics ==========\n",
    "accuracy_list, precision_list, recall_list, f1_list, threshold_list = [], [], [], [], []\n",
    "\n",
    "# ========== Cross-Validation ==========\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_probs = pipeline.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    best = {'thresh': None, 'acc': 0, 'prec': 0, 'rec': 0, 'f1': 0}\n",
    "\n",
    "    for thresh in thresholds:\n",
    "        y_pred = (y_probs >= thresh).astype(int)\n",
    "        acc = accuracy_score(y_val, y_pred)\n",
    "        prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "        rec = recall_score(y_val, y_pred)\n",
    "        f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "        if f1 > best['f1']:\n",
    "            best = {'thresh': thresh, 'acc': acc, 'prec': prec, 'rec': rec, 'f1': f1}\n",
    "\n",
    "    accuracy_list.append(best['acc'])\n",
    "    precision_list.append(best['prec'])\n",
    "    recall_list.append(best['rec'])\n",
    "    f1_list.append(best['f1'])\n",
    "    threshold_list.append(best['thresh'])\n",
    "\n",
    "    print(f\"Fold {fold}: Best Threshold={best['thresh']:.2f}, Acc={best['acc']:.4f}, \"\n",
    "          f\"Prec={best['prec']:.4f}, Rec={best['rec']:.4f}, F1={best['f1']:.4f}\")\n",
    "\n",
    "# ========== Summary ==========\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "mean_thresh = np.mean(threshold_list)\n",
    "\n",
    "model_name = 'EasyEnsembleClassifier+ThresholdTuning'\n",
    "model_desc = 'EEC-ThresholdTuning-5Fold'\n",
    "\n",
    "print(\"\\n--- Model Summary ---\")\n",
    "print(f\"{'Name':<30}: {model_name}\")\n",
    "print(f\"{'Description':<30}: {model_desc}\")\n",
    "print(f\"{'Avg Accuracy':<30}: {mean_acc:.4f}\")\n",
    "print(f\"{'Avg Precision':<30}: {mean_prec:.4f}\")\n",
    "print(f\"{'Avg Recall':<30}: {mean_rec:.4f}\")\n",
    "print(f\"{'Avg F1 Score':<30}: {mean_f1:.4f}\")\n",
    "print(f\"{'Avg Best Threshold':<30}: {mean_thresh:.2f}\")\n",
    "\n",
    "# ========== Save CSV ==========\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "new_row = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4),\n",
    "    'Threshold': round(mean_thresh, 2)\n",
    "}])\n",
    "\n",
    "new_row.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "396b0366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Best Threshold=0.38, Acc=0.7103, Prec=0.2903, Rec=0.3103, F1=0.3000\n",
      "Fold 2: Best Threshold=0.34, Acc=0.7517, Prec=0.3704, Rec=0.3448, F1=0.3571\n",
      "Fold 3: Best Threshold=0.62, Acc=0.7793, Prec=0.4400, Rec=0.3793, F1=0.4074\n",
      "Fold 4: Best Threshold=0.30, Acc=0.6690, Prec=0.2857, Rec=0.4000, F1=0.3333\n",
      "Fold 5: Best Threshold=0.32, Acc=0.6667, Prec=0.3208, Rec=0.5862, F1=0.4146\n",
      "\n",
      "--- Model Summary ---\n",
      "Name                          : XGBoost-SMOTE-FineTuned-ThresholdSweep\n",
      "Description                   : XGB+SMOTE+FineTuned+ThreshSweep(0.30–0.70)\n",
      "Avg Accuracy                  : 0.7154\n",
      "Avg Precision                 : 0.3414\n",
      "Avg Recall                    : 0.4041\n",
      "Avg F1 Score                  : 0.3625\n",
      "Avg Best Threshold            : 0.39\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ========== Input ==========\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# ========== Drop High VIF / Low Variance Columns (if known) ==========\n",
    "# Optionally prefilter X here based on known analysis\n",
    "# e.g., X = X.drop(columns=high_vif_cols)\n",
    "\n",
    "# ========== CV Setup ==========\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "thresholds = np.arange(0.30, 0.71, 0.02)  # Finer sweep range\n",
    "\n",
    "# ========== Preprocessing ==========\n",
    "categorical_features = X.select_dtypes(include=['object']).columns\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', StandardScaler(), numeric_features),\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "])\n",
    "\n",
    "# ========== Model Components ==========\n",
    "feature_selector = SelectFromModel(estimator=RandomForestClassifier(random_state=42), max_features=20)\n",
    "smote = SMOTE(random_state=42)\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "pipeline = ImbPipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('smote', smote),\n",
    "    ('feature_selection', feature_selector),\n",
    "    ('classifier', xgb_model)\n",
    "])\n",
    "\n",
    "# ========== Metrics ==========\n",
    "accuracy_list, precision_list, recall_list, f1_list, threshold_list = [], [], [], [], []\n",
    "\n",
    "# ========== Cross-Validation ==========\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_probs = pipeline.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    best = {'thresh': None, 'acc': 0, 'prec': 0, 'rec': 0, 'f1': 0}\n",
    "\n",
    "    for thresh in thresholds:\n",
    "        y_pred = (y_probs >= thresh).astype(int)\n",
    "        acc = accuracy_score(y_val, y_pred)\n",
    "        prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "        rec = recall_score(y_val, y_pred)\n",
    "        f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "        if rec >= 0.85 and prec >= 0.5:  # Your hard target\n",
    "            if f1 > best['f1']:\n",
    "                best = {'thresh': thresh, 'acc': acc, 'prec': prec, 'rec': rec, 'f1': f1}\n",
    "\n",
    "    # If no threshold met both conditions, pick best F1 instead\n",
    "    if best['thresh'] is None:\n",
    "        for thresh in thresholds:\n",
    "            y_pred = (y_probs >= thresh).astype(int)\n",
    "            acc = accuracy_score(y_val, y_pred)\n",
    "            prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "            rec = recall_score(y_val, y_pred)\n",
    "            f1 = f1_score(y_val, y_pred)\n",
    "            if f1 > best['f1']:\n",
    "                best = {'thresh': thresh, 'acc': acc, 'prec': prec, 'rec': rec, 'f1': f1}\n",
    "\n",
    "    accuracy_list.append(best['acc'])\n",
    "    precision_list.append(best['prec'])\n",
    "    recall_list.append(best['rec'])\n",
    "    f1_list.append(best['f1'])\n",
    "    threshold_list.append(best['thresh'])\n",
    "\n",
    "    print(f\"Fold {fold}: Best Threshold={best['thresh']:.2f}, Acc={best['acc']:.4f}, \"\n",
    "          f\"Prec={best['prec']:.4f}, Rec={best['rec']:.4f}, F1={best['f1']:.4f}\")\n",
    "\n",
    "# ========== Summary ==========\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "mean_thresh = np.mean(threshold_list)\n",
    "\n",
    "model_name = 'XGBoost-SMOTE-FineTuned-ThresholdSweep'\n",
    "model_desc = 'XGB+SMOTE+FineTuned+ThreshSweep(0.30–0.70)'\n",
    "\n",
    "print(\"\\n--- Model Summary ---\")\n",
    "print(f\"{'Name':<30}: {model_name}\")\n",
    "print(f\"{'Description':<30}: {model_desc}\")\n",
    "print(f\"{'Avg Accuracy':<30}: {mean_acc:.4f}\")\n",
    "print(f\"{'Avg Precision':<30}: {mean_prec:.4f}\")\n",
    "print(f\"{'Avg Recall':<30}: {mean_rec:.4f}\")\n",
    "print(f\"{'Avg F1 Score':<30}: {mean_f1:.4f}\")\n",
    "print(f\"{'Avg Best Threshold':<30}: {mean_thresh:.2f}\")\n",
    "\n",
    "# ========== Save CSV ==========\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "new_row = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4),\n",
    "    'Threshold': round(mean_thresh, 2)\n",
    "}])\n",
    "\n",
    "new_row.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "245685d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Best Threshold=0.15, Acc=0.6483, Prec=0.3167, Rec=0.6552, F1=0.4270\n",
      "Fold 2: Best Threshold=0.05, Acc=0.5517, Prec=0.2907, Rec=0.8621, F1=0.4348\n",
      "Fold 3: Best Threshold=0.50, Acc=0.7793, Prec=0.4595, Rec=0.5862, F1=0.5152\n",
      "Fold 4: Best Threshold=0.20, Acc=0.6552, Prec=0.3529, Rec=0.8000, F1=0.4898\n",
      "Fold 5: Best Threshold=0.10, Acc=0.5208, Prec=0.2727, Rec=0.8276, F1=0.4103\n",
      "\n",
      "--- Model Summary ---\n",
      "Name                          : XGBoost-HitAndTry-ThresholdSweep\n",
      "Description                   : XGB+SMOTE+WideThreshSweep+NoVIFDrop\n",
      "Avg Accuracy                  : 0.6311\n",
      "Avg Precision                 : 0.3385\n",
      "Avg Recall                    : 0.7462\n",
      "Avg F1 Score                  : 0.4554\n",
      "Avg Best Threshold            : 0.20\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ========== Input ==========\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# ========== CV Setup ==========\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "thresholds = np.linspace(0.05, 0.6, 12)  # More granular hit & try\n",
    "\n",
    "# ========== Preprocessing ==========\n",
    "categorical_features = X.select_dtypes(include=['object']).columns\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', StandardScaler(), numeric_features),\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "])\n",
    "\n",
    "# ========== Model Components ==========\n",
    "feature_selector = SelectFromModel(estimator=RandomForestClassifier(random_state=42), max_features=25)\n",
    "smote = SMOTE(random_state=42)\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=400,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.03,\n",
    "    subsample=0.7,\n",
    "    colsample_bytree=0.7,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "pipeline = ImbPipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('smote', smote),\n",
    "    ('feature_selection', feature_selector),\n",
    "    ('classifier', xgb_model)\n",
    "])\n",
    "\n",
    "# ========== Metrics ==========\n",
    "accuracy_list, precision_list, recall_list, f1_list, threshold_list = [], [], [], [], []\n",
    "\n",
    "# ========== Cross-Validation ==========\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_probs = pipeline.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    best = {'thresh': None, 'acc': 0, 'prec': 0, 'rec': 0, 'f1': 0}\n",
    "\n",
    "    for thresh in thresholds:\n",
    "        y_pred = (y_probs >= thresh).astype(int)\n",
    "        acc = accuracy_score(y_val, y_pred)\n",
    "        prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "        rec = recall_score(y_val, y_pred)\n",
    "        f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "        if f1 > best['f1']:\n",
    "            best = {'thresh': thresh, 'acc': acc, 'prec': prec, 'rec': rec, 'f1': f1}\n",
    "\n",
    "    accuracy_list.append(best['acc'])\n",
    "    precision_list.append(best['prec'])\n",
    "    recall_list.append(best['rec'])\n",
    "    f1_list.append(best['f1'])\n",
    "    threshold_list.append(best['thresh'])\n",
    "\n",
    "    print(f\"Fold {fold}: Best Threshold={best['thresh']:.2f}, Acc={best['acc']:.4f}, \"\n",
    "          f\"Prec={best['prec']:.4f}, Rec={best['rec']:.4f}, F1={best['f1']:.4f}\")\n",
    "\n",
    "# ========== Summary ==========\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "mean_thresh = np.mean(threshold_list)\n",
    "\n",
    "model_name = 'XGBoost-HitAndTry-ThresholdSweep'\n",
    "model_desc = 'XGB+SMOTE+WideThreshSweep+NoVIFDrop'\n",
    "\n",
    "print(\"\\n--- Model Summary ---\")\n",
    "print(f\"{'Name':<30}: {model_name}\")\n",
    "print(f\"{'Description':<30}: {model_desc}\")\n",
    "print(f\"{'Avg Accuracy':<30}: {mean_acc:.4f}\")\n",
    "print(f\"{'Avg Precision':<30}: {mean_prec:.4f}\")\n",
    "print(f\"{'Avg Recall':<30}: {mean_rec:.4f}\")\n",
    "print(f\"{'Avg F1 Score':<30}: {mean_f1:.4f}\")\n",
    "print(f\"{'Avg Best Threshold':<30}: {mean_thresh:.2f}\")\n",
    "\n",
    "# ========== Save CSV ==========\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "new_row = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4),\n",
    "    'Threshold': round(mean_thresh, 2)\n",
    "}])\n",
    "\n",
    "new_row.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a240ee03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Best Threshold=0.30, Acc=0.5793, Prec=0.3049, Rec=0.8621, F1=0.4505\n",
      "Fold 2: Best Threshold=0.30, Acc=0.6483, Prec=0.3333, Rec=0.7586, F1=0.4632\n",
      "Fold 3: Best Threshold=0.55, Acc=0.6828, Prec=0.3396, Rec=0.6207, F1=0.4390\n",
      "Fold 4: Best Threshold=0.50, Acc=0.6897, Prec=0.3770, Rec=0.7667, F1=0.5055\n",
      "Fold 5: Best Threshold=0.55, Acc=0.6806, Prec=0.3191, Rec=0.5172, F1=0.3947\n",
      "\n",
      "--- Model Summary ---\n",
      "Name                          : BaggingDT+Balanced+Top20+ThreshTuned\n",
      "Description                   : BaggingDT+Top20MI+ThreshSweep(0.05–0.6)\n",
      "Avg Accuracy                  : 0.6561\n",
      "Avg Precision                 : 0.3348\n",
      "Avg Recall                    : 0.7051\n",
      "Avg F1 Score                  : 0.4506\n",
      "Avg Best Threshold            : 0.44\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from imblearn.ensemble import EasyEnsembleClassifier\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ========== Input ==========\n",
    "current_df = df_clean.copy()\n",
    "X = current_df.drop(columns=['Risk Flag'])\n",
    "y = current_df['Risk Flag'].astype(int)\n",
    "\n",
    "# ========== Top 20 Features via MI ==========\n",
    "cat_cols = X.select_dtypes(include='object').columns\n",
    "num_cols = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "X_enc = pd.get_dummies(X, columns=cat_cols)\n",
    "mi_scores = mutual_info_classif(X_enc, y, discrete_features='auto', random_state=42)\n",
    "mi_df = pd.Series(mi_scores, index=X_enc.columns).sort_values(ascending=False)\n",
    "top20_features = mi_df.head(20).index.tolist()\n",
    "X = X_enc[top20_features]\n",
    "\n",
    "# ========== CV Setup ==========\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "thresholds = np.linspace(0.05, 0.6, 12)\n",
    "\n",
    "# ========== Preprocessing ==========\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('scale', StandardScaler(), top20_features)\n",
    "])\n",
    "\n",
    "# ========== Model ==========\n",
    "model = BalancedBaggingClassifier(\n",
    "    estimator=DecisionTreeClassifier(max_depth=6, random_state=42),\n",
    "    n_estimators=10,\n",
    "    sampling_strategy='auto',\n",
    "    replacement=False,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "pipeline = ImbPipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', model)\n",
    "])\n",
    "\n",
    "# ========== Metrics ==========\n",
    "accuracy_list, precision_list, recall_list, f1_list, threshold_list = [], [], [], [], []\n",
    "\n",
    "# ========== Cross-Validation ==========\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_probs = pipeline.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    best = {'thresh': None, 'acc': 0, 'prec': 0, 'rec': 0, 'f1': 0}\n",
    "\n",
    "    for thresh in thresholds:\n",
    "        y_pred = (y_probs >= thresh).astype(int)\n",
    "        acc = accuracy_score(y_val, y_pred)\n",
    "        prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "        rec = recall_score(y_val, y_pred)\n",
    "        f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "        if f1 > best['f1']:\n",
    "            best = {'thresh': thresh, 'acc': acc, 'prec': prec, 'rec': rec, 'f1': f1}\n",
    "\n",
    "    accuracy_list.append(best['acc'])\n",
    "    precision_list.append(best['prec'])\n",
    "    recall_list.append(best['rec'])\n",
    "    f1_list.append(best['f1'])\n",
    "    threshold_list.append(best['thresh'])\n",
    "\n",
    "    print(f\"Fold {fold}: Best Threshold={best['thresh']:.2f}, Acc={best['acc']:.4f}, \"\n",
    "          f\"Prec={best['prec']:.4f}, Rec={best['rec']:.4f}, F1={best['f1']:.4f}\")\n",
    "\n",
    "# ========== Summary ==========\n",
    "mean_acc = np.mean(accuracy_list)\n",
    "mean_prec = np.mean(precision_list)\n",
    "mean_rec = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "mean_thresh = np.mean(threshold_list)\n",
    "\n",
    "model_name = 'BaggingDT+Balanced+Top20+ThreshTuned'\n",
    "model_desc = 'BaggingDT+Top20MI+ThreshSweep(0.05–0.6)'\n",
    "\n",
    "print(\"\\n--- Model Summary ---\")\n",
    "print(f\"{'Name':<30}: {model_name}\")\n",
    "print(f\"{'Description':<30}: {model_desc}\")\n",
    "print(f\"{'Avg Accuracy':<30}: {mean_acc:.4f}\")\n",
    "print(f\"{'Avg Precision':<30}: {mean_prec:.4f}\")\n",
    "print(f\"{'Avg Recall':<30}: {mean_rec:.4f}\")\n",
    "print(f\"{'Avg F1 Score':<30}: {mean_f1:.4f}\")\n",
    "print(f\"{'Avg Best Threshold':<30}: {mean_thresh:.2f}\")\n",
    "\n",
    "# ========== Save CSV ==========\n",
    "csv_file = \"risk_model_metrics.csv\"\n",
    "new_row = pd.DataFrame([{\n",
    "    'Name': model_name,\n",
    "    'Desc': model_desc,\n",
    "    'Accuracy': round(mean_acc, 4),\n",
    "    'Precision': round(mean_prec, 4),\n",
    "    'Recall': round(mean_rec, 4),\n",
    "    'F1 Score': round(mean_f1, 4),\n",
    "    'Threshold': round(mean_thresh, 2)\n",
    "}])\n",
    "\n",
    "new_row.to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca274224",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
